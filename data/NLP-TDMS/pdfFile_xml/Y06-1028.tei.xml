<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vietnamese Word Segmentation with CRFs and SVMs: An Investigation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cam-Tu</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Technology</orgName>
								<orgName type="institution">National University</orgName>
								<address>
									<settlement>Hanoi</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung-Kien</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Hieu</forename><surname>Phan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Technology</orgName>
								<orgName type="institution">National University</orgName>
								<address>
									<settlement>Hanoi</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le-Minh</forename><surname>Nguyen</surname></persName>
							<email>nguyenml@jaist.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Thuy</forename><surname>Ha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Technology</orgName>
								<orgName type="institution">National University</orgName>
								<address>
									<settlement>Hanoi</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vietnamese Word Segmentation with CRFs and SVMs: An Investigation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Word segmentation</term>
					<term>segmenting and labeling sequence data</term>
					<term>conditional random fields</term>
					<term>support vector machines</term>
					<term>maximum matching</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Word segmentation for Vietnamese, like for most Asian languages, is an important task which has a significant impact on higher language processing levels. However, it has received little attention of the community due to the lack of a common annotated corpus for evaluation and comparison. Also, most previous studies focused on unsupervised-statistical approaches or combined too many techniques. Consequently, their accuracies are not as high as expected. This paper reports a careful investigation of using conditional random fields (CRFs) and support vector machines (SVMs)-two of the most successful statistical learning methods in NLP and pattern recognition-for solving the task. We first build a moderate annotated corpus using different sources of materials. For a careful evaluation, different CRF and SVM models using different feature settings were trained and their results are compared and contrasted with each other. In addition, we discuss several important points about the accuracy, computational cost, corpus size and other aspects that might influence the overall quality of Vietnamese word segmentation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word segmentation is one of the fundamental preprocessing steps in NLP for building higher applications. It is even more important and challenging in Asian languages, such as Chinese, Japanese, and Korea, because there is no white space between two consecutive words. Vietnamese language faces a similar problem due to the fact that a word may contain more than one separated syllables, and therefore the white space is not always the word separator.</p><p>In recent years, word boundary detection for Vietnamese has received more attention from the community and there have been several statistical and machine learning methods applied to the task. However, most of the current methods either suffer from unsatisfactory results <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> (with accuracy of 91% or lower) or must combine many techniques in a multi-level processing to obtain good results <ref type="bibr" target="#b2">[3]</ref>. In addition, their works were done without comparison to any baseline or study of the quality of the corpus (e.g., the out-of-vocabulary rate, the number of date/time and numbers). Also, there is still no common standard annotated corpus for evaluation and comparison.</p><p>In this paper, we present a thorough investigation of using two powerful statistical learning methods, CRFs and SVMs, to perform the task. To do so, we first build an annotated corpus of about 8000 sentences with word boundary marked. Although the corpus is not large enough to cover a broad range of Vietnamese vocabularies, it contains documents from different domains to reduce the imbalance in word distribution. Then, CRF and SVM models are trained on the corpus using various feature configurations and their performances are compared and contrasted with each other to determine the impact of feature selection as well as the generalization power of CRFs and SVMs on the segmentation accuracy. CRF and SVM models are also compared with a baseline (maximum matching from a Vietnamese dictionary) to see the extent to which machine learning techniques can help to improve the accuracy in comparison with the simple heuristics-based matching approach. All in all, our main motivations behind this work can be summed up as follows:</p><p>• CRFs and SVMs have recently been seen as two of the most successful statistical learning models in NLP and pattern classification. While SVM together with appropriate kernels is well-known thanks to its optimal discriminating hyper-plane in very high-dimensional feature spaces, CRF is particularly designed for problems of labeling and segmenting sequence data because of its global normalization and trade-off among state variables of sequence data. In addition, both SVMs and CRFs follow the discriminative learning approach and have a big flexibility to encode a variety of features from the input data to enhance their the prediction capability. Recently, both SVMs and CRFs have been applied to a wide range of labeling and segmenting tasks in NLP like POS tagging, chunking, named entity recognition, and information extraction, and have achieved state-of-the-art results. Therefore, we do hope that CRFs and SVMs can achieve similar successes in segmenting Vietnamese.</p><p>• Feature selection is a core step in both CRFs-based and SVMs-based approaches. The important issue</p><p>is that which types of feature should be used and how they influence the accuracy of the system. Note that chosen features should be useful to the word segmentation task and appropriate to Vietnamese. Because Vietnamese word segmentation is still an open task, a careful estimation of feature types especially ones bearing characteristics of Vietnamese will set up a foundation for future research on Vietnamese word segmentation. The remaining part of the paper is organized as follows. Section 2 briefly discusses word formation in Vietnamese. Section 3 describes quickly the two learning models CRFs and SVMs for labeling and segmenting sequence data. Section 4 mainly presents the framework of using CRFs and SVMs for Vietnamese word segmentation. Corpus building, feature selection, result comparison and analysis will be presented in this section. Finally, some conclusions will be given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Vietnamese Word Formation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vietnamese Syllable</head><p>Vietnamese syllables are elementary units that have one way of pronunciation. In documents, they are usually delimited by white-space. Being the elementary units, Vietnamese syllables are not undivided elements but a structure <ref type="bibr" target="#b5">[6]</ref>. <ref type="table" target="#tab_0">Table 1</ref> depicts the general structure of Vietnamese syllable Generally speaking, each Vietnamese syllable has all five parts: first consonant, secondary vowel, main vowel, last consonant and a tone mark. For instance, the syllable "tuần" (week) has a tone mark (grave accent), a first consonant (t), a secondary vowel (u), a main vowel (â) and a last consonant (n). However, except for main vowel that is required for all syllables, the other parts may be not present in some cases. For example, the syllable "anh" (brother) has no tone mark, no secondary vowel and no first consonant. In other case, the syllable "hoa" (flower) has a secondary vowel (o) but no last consonant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Vietnamese Word</head><p>A word in Vietnamese may consist of one or more syllables which are combined in different ways. Based on the way of constructing words from syllables, we can classify them into three categories: single words, complex words and reduplicative words.</p><p>• Simple Words: a single word has only one syllable that implies a specific meaning. For example: tôi(I), bạn(you), nhà(house), ...</p><p>• Complex Words are words that consist of more than one syllable. The syllables in a complex word are combined based on semantic relationships, that is either coordinated (bơi lội-swim) or "principle and accessory" (đường sắt -railway).</p><p>• A word is considered as a reduplicative one if its syllables have phonic components reduplicated.</p><p>Reduplicative words are usually used for scene or sound descriptions, thus they usually used in literary texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">New Words in Vietnamese</head><p>New words are those that are out-of-vocabulary or not present in a particular dictionary or training corpus. In our system, we consider 3 types of new words: abbreviations, named entities, and foreign words.</p><p>• Abbreviations are usually all-capitalized, for example: CAND (Công An Nhân Dân -people's police).</p><p>• Named entities are proper nouns indicating person, location, organization, date-time and so on. In Vietnamese, personal or organizational names often have first letter capitalized, for instance: "Hồ Chí Minh" or "Hải Hà" in phrase "Công ty Hải Hà" (Hải Hà firm). The other named entities such as number, percentage, date-time, etc. can also be captured by some specific regular expressions.</p><p>• Foreign words used in Vietnamese are usually Latinized. Each foreign word has only one syllable that does not often conform to the structure of Vietnamese syllable described in section 2.1. By observing types of new words in documents, we later introduce some kinds of useful features in order to detect them in order to increase the accuracy of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sequential Labeling with CRFs and SVMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conditional Random Fields</head><p>In this paper, CRFs are referred to as an undirected linear-chain of model states, i.e., a conditionallytrained finite state machine (FSMs) that obey the first-order Markov property.</p><p>Let o = (o 1 , o 2 , …, o T ) be some observed data sequence. Let S be a set of FSM states, each of which is associated with a label L l∈ . Let s = (s 1 , s 2 ,…, s T ) be some state sequence, CRFs <ref type="bibr" target="#b3">[4]</ref> define the conditional probability of a state sequence given an observation sequence as</p><formula xml:id="formula_0">⎥ ⎦ ⎤ ⎢ ⎣ ⎡ = ∑∑ = − T t k t t k k t s s f Z p 1 1 ) , , , ( exp ) ( 1 ) | ( o o o s λ θ .</formula><p>(</p><p>Where is normalization summing over all label sequences. f k denotes a feature function in the language of maximum entropy modeling and and a context predicate, i.e., the binary function x k (o,t) that captures a particular property of the observation sequence o at time position t. For example, the current label is B_PER and the current word is "Nguyễn". A transition feature (3) presents sequential dependencies by combining the label l'of the previous state s t-1 and the label l of the current state s t , such as the previous label l'=B_PER and the current label is l=I_PER.</p><formula xml:id="formula_2">∑ ∑∑ ⎟ ⎠ ⎞ ⎜ ⎝ ⎛ = = − T t k t t k k s t s s f Z 1 1 ' ) , , ' , ' ( exp ) ( o o λ k λ is</formula><p>Training CRFs is commonly performed by maximizing the likelihood function with respect to the training data using advanced convex optimization techniques like L-BFGS. And inference in CRFs, i.e., searching the most likely output label sequence of an input observation sequence, can be done using Viterbi algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Support Vector Machine</head><p>Suppose that we have a set of training samples D = <ref type="figure" target="#fig_1">(x 1 , y 1 ), …, (x l , y l</ref> ) (x i ∈ R n , y i {+1, -1}) where 1. Not only the linear classification, SVMs also can carry out the nonlinear ones by introducing kernel functions that embed the data into a feature space where the nonlinear pattern now appears linear. Though, we omit the details here, the key aspect of kernel functions is that they preserve the pairwise inerproducts while relaxing the constraints of coordinates of the embedded points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>≥</head><p>Basically, SVMs are binary classifier, thus we must extend SVMs to multi-class classifier in order to classify three or more classes. The pairwise classifier is one of the most popular methods to extend the binary classification task to that of K classes. Though, we leave the details to <ref type="bibr" target="#b11">[12]</ref>, the idea of pairwise classification is to build K.(K-1)/2 classifiers considering all pairs of classes, and final decision is given by their weighted voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Vietnamese Word Segmentation with CRFs and SVMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus Building</head><p>Building a robust and accurate word segmentation system for Vietnamese using machine learning approaches is more complex in comparison with building such a system in other languages due to the fact that there is no standard corpus publicly available. For this work, we have to build a corpus of 305 newspaper articles from many websites and in various domains. Although the corpus is not large enough to cover a broad range of Vietnamese words, it contains documents from multiple domains with the hope that this will reduce the imbalance in word distribution. This corpus is now available online <ref type="bibr" target="#b0">1</ref> .</p><p>In addition to the corpus, we also collect other resources that are used as lexicons or domainknowledge for our system: a Vietnamese dictionary, a list of 2000 personal names 2 , and a list of 707 names of locations 3 in Vietnam. These can be seen as external dictionaries and will be used for looking up in our CRF and SVM models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Problem Representation</head><p>We cast the segmentation problem as a sequential tagging task: Vietnamese syllable that begins a word is marked with B_W (Begin of a Word), the syllable that is inside a word is marked with I_W (Inside of a Word), and the other things like comma, dot marks are tagged with O (Outside of a word). The problem of detecting word boundaries in a sentence is modeled as the problem of labeling syllables in that sentence with three above labels.</p><p>Performance of both the CRFs-based and SVMs-based segmentation systems depends on how well we do feature selection. In the following section, we will discuss more about the strategies of feature selection for both CRFs and SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Selection</head><p>As mentioned earlier, there are two kinds of feature functions used in linear-CRFs: edge features which obey to the first-Markov property, and per-state features which are generated by combining information (context predicate) available surrounding current position in the observation sequence with the current label. Based on the same idea, we also integrate 2 kinds of features into SVM model. They are static features and dynamic features. While SVM model decide dynamic features in tagging process by considering the two previous labels, static features are very similar to per-state features in CRF model in the sense that we also take into account context predicates at the current observation.</p><p>After studying specific characteristics of Vietnamese, we propose five types of context predicate templates from which various features will be generated correspondingly.   <ref type="table" target="#tab_3">Table 3</ref> summarizes the context predicate templates used in our models. Note that, two numbers inside the brackets next to each context predicate template indicate the window surrounding current position in which we explore context information. For examples, In_LacViet_Dictionary (-2, 2) means that we make a particular conjunction of adjacent syllables in the sliding window from the second previous to the second next syllables and check if that conjunction forms a word in the dictionary. Also, because the number of more-than-4-syllables words is quite low, we take into account only conjunctions of up-to-three adjacent syllables. Similarly, by Syllable_Conjunction (-2, 2), we considers all the 1-gram, 2-gram and 3-gram of syllables in the window of size 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Setup</head><p>Our experiments with CRFs and SVMs were conducted using two tools: FlexCRFs -a C/C++ implementation of CRFs, and Yamcha -a C/C++ implementation of SVMs for labeling and segmenting sequence data. For CRF models, we use first-order Markov dependency, and for SVM models we use the second degree of polynomial kernel. CRFs with SC + VSD 4</p><p>CRFs with SC+VSD+ Dict 5</p><p>CRFs with SC+ VSD+ Dict + ERS 6</p><p>CRFs with SC+ VSD + Dict + ERS + Misc 7</p><p>SVMs with SC 8</p><p>SVMs with SC+VSD 9</p><p>SVMs with SC+ VSD+ Dict</p><p>For evaluating in each experiment, we used 5-fold cross-validation test. In other words, we randomly divide the corpus into five partitions; in each fold we take one partition as the testing set and all the others for training. Additionally, for the purpose of evaluating the performance of new word detection process, the OOV (out-of-vocabulary) rate is measured for 5 folds in the corpus and the average result among 5 folds is about 11.6%. This OOV rate is quite high in comparison with some popular corpora for Chinese word segmentation such as the corpora of Beijing University (6.9%), Hong Kong City U (7.1%) and Academia Sinica (2.2%) <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results and Discussion</head><p>One of the most noticeable advantages of CRFs is the flexibility of integrating various kinds of features from the training data, thus we design 5 separate experiments for CRFs -the later is richer of features than the earlier -to estimate the effect of feature types on the system performance. For SVMs-based segmentation, we conduct an experiment with the strategy of feature selection described in the section 4.2. Though this work is an investigation of using CRFs and SVMs for Vietnamese Word Segmentation, we still need a baseline for all experiments and we have used Maximum Matching for this purpose. The summary of the design for our experiments is showed in <ref type="table" target="#tab_4">Table 4</ref> The average precision, recall, F1-measure of 5-fold CV tests from 9 experiments are summarized in <ref type="table" target="#tab_5">Table 5</ref>. <ref type="figure" target="#fig_1">Figure 1</ref> depicts the performance comparison among CRF models using different feature settings (Maximum Matching as a baseline). Also, the performance comparison between SVM and the CRF models (with two similar feature settings) is shown in <ref type="figure">Figure 2</ref>.</p><p>From <ref type="table" target="#tab_5">Table 5</ref> and <ref type="figure" target="#fig_1">Figure 1</ref>, several observations could be made. First, even with the simplest feature setting, CRFs can outperform Maximum Matching significantly. This is because the large number of new words appears in the data and partly shows that our corpus has high out-of-vocabulary rate. Second, the richer feature setting is, the better results CRFs model can achieve. The CRF model with richest feature setting yields the highest performance (average F 1 of 94.05%) in comparison with the other settings (average F 1 of 93.98%, 93.90%, 90.41% and 90.14%). Third, the impact of different feature types on the performance of CRFs model is different. As we can see in the figure, the Dict and SC feature types have the largest effect on the performance of the system. While the Misc feature type only has a little effect. This is due to several reasons: (1) Vietnamese word boundary depends more on identity of its syllable than their features like capitalization or that it is the first syllable in a sentence or not. (2) Though regular expressions can detect number, date/time quite well, the number of date/time and number expressions is much smaller than the number of words in the corpus.  <ref type="table" target="#tab_5">Table 5</ref> and <ref type="figure">Figure 2</ref> show us some interesting information. Although VSD feature enhances the CRF model a little bit, it does not have positive effect on the SVM model. This shows that inappropriate features may cause noisy in the model and result in worse performance. Another observation is that with the similar feature settings, the SVM model is better than the similar CRF model. Moreover, SVM model with (SC+VSD+Dict) even performs better than the CRF model with the richest feature setting (the average F 1 of 94.05%). To further study the two methods, we later compare computational time of SVMs and CRFs and see that with the similar feature setting, SVM model is slower than CRF model. For example: with the feature setting SC+VSD+Dict, the SVM model took 4 hours to complete the training process for 1 fold but the CRF model took only 2 hours for the same task. However, if comparing this SVM model to CRF model with richest feature setting (SC+VSD+Dict+ERS+Misc), we see they need nearly the same computational time while the SVM model is a little bit better than the CRF model in performance. This shows that SVM-based learning is a potential approach to the problem of Vietnamese segmentation. With good feature selection, it gives a little bit better performance than CRFs in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have presented a thorough investigation of using CRFs and SVMs for Vietnamese word boundary detection. The key contributions of our work is three-fold: (1) building an annotated corpus for evaluation; (2) training different CRF and SVM features according to different feature configurations; and then compare and contrast their results; and (3) draw some interesting conclusions that we observed from the experimental results.</p><p>Due to the computational burden of SVMs and the time limitation, the complete experiments for SVMs (of all feature settings) will be done in the near future. Also, in future work we need to evaluate how segmentation accuracy depends on the corpus size.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>x</head><label></label><figDesc>i is a feature vector of the i-th sample represented by an n dimensional vector, y i is the class (positive(+1) or negative(-1)) label of the i-th sample. l is the number of training samples. The main ideas behind SVMs is to separate positive and negative samples by a hyperplane expressed as (w.x) + b = 0. SVMs [11] find the separating hyperplane which maximizes its margin. In other words, this problem becomes equivalent to solving the following optimization problem: ∈ Maximize: M=2/||w|| Subject to: y i [(w.x i ) + b]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 http:</head><label>1</label><figDesc>//www.jaist.ac.jp/~hieuxuan/vnwordseg/data 2 From http://www.vietnamgiapha.com/ 3 From http://vi.wikipedia.org/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Structure of Vietnamese Syllable</head><label>1</label><figDesc></figDesc><table>TONE MARK 
Rhyme 
First Consonant 
Secondary 
Consonant 

Main 
Vowel 

Last 
Consonant 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>a learned weight associated with feature f k . Each f k is either a per-state or a transition feature.δ . A per-state feature (2) combines the label l of current state s t</head><label>learned</label><figDesc></figDesc><table>) 
, 
( 
) 
, 
( 
) 
, 
, 
( 

) 
( 

t 
x 
l 
s 
t 
s 
f 

k 
t 
t 

state 
per 
k 

o 
o 

δ 

= 

− 

. 
(2) 

) 
, 
( 
) 
, 
( 
) 
, 
, 
( 

1 
1 

) 
( 

l 
s 
l 
s 
t 
s 
s 
f 

t 
t 
t 
t 

transition 
k 

δ 
δ − 

− 

= 

. 
(3) Where δ denotes the Kronecker-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 . Statistics of our annotated corpus for Vietnamese word segmentation</head><label>2</label><figDesc></figDesc><table>No 
Domain 
Number of Documents 
1 
Economics 
90 
2 
Information Technology 
59 
3 
Education 
38 
4 
Vehicle 
35 
5 
Sports 
28 
6 
Law 
31 
7 
Culture-Society 
24 
Total 305 newspaper articles (about 7800 sentences) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Context predicate temlates for CRFs and SVMs. Here, a valid Vietnamese syllable must conform to the structure described in section 2; Is_Marks will check current observation is a full stop, comma or some kinds of marks in the sentence or not; Is_Regular_Expression tries to capture expressions describing date/time (long date/ short date), numbers or tokens that is a mix of characters and numbers, etc.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>Sumary of our experiment design. Here, SC stands for Syllable Conjunction, Misc: Miscellaneous, Dict: 
Dictionary, ERS: External Resources, VSD: Vietnamese Syllable Detection 

ID 
Feature settings for experiments 
1 
Maximum Matching (looking up a Vietnamese dictionary) 
2 
CRFs with SC 
3 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>The average precision, recall, and F1-measure of 5-fold cross-validation tests of Maximum Matching, 
CRFs and SVMs 

Method (feature settings) 
Pre (%) Re (%) 
F 1 
Maximum Matching 
87.65 
78.59 
82.82 
CRFs (SC) 
89.98 
90.30 
90.14 
CRFs (SC+VSD) 
90.24 
90.58 
90.41 
CRFs (SC+VSD+Dict) 
93.67 
94.12 
93.90 
CRFs (SC + VSD + ERS) 
93.71 
94.26 
93.98 
CRFs (SC + VSD + ERS + Misc) 
93.76 
94.28 
94.05 
SVMs (SC) 
90.60 
91.45 
91.02 
SVMs (SC + VSD) 
90.21 
90.87 
90.54 
SVMs (SC + VSD + Dict) 
94.00 
94.45 
94.23 

74 

76 

78 

80 

82 

84 

86 

88 

90 

92 

94 

96 

M 
a x im 

u m 

M 
a t c h in 

g 
S C 

S C 

+ 
V S 

D 

S C 

+ 
V S D 

+ 

D 
ic 
t 

S C 

+ 
V S D 

+ D 

ic 
t + E 

R S 

S C 
+ V S D 

+ D 

ic 
t + E R 

S 
+ M 
i s c 

F-measure 

Fold1 Fold2 Fold3 
Fold4 Fold5 

Fig. 1. Performance comparison among CRF models using different feature settings 
(Maximum Matching as the baseline) 

5.78 

6.08 

5.88 

5.65 
5.48 

5.88 

6.33 
6.35 

6.16 

5.79 

5 

5.2 

5.4 

5.6 

5.8 

6 

6.2 

6.4 

6.6 

Fold1 
Fold2 
Fold3 
Fold4 
Fold5 

Error rate 

SVMs 

CRFs 

Fig. 2. Performance comparison between CRFs (SC + VSD + Dict) and SVMs on 5-fold CV test 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A method for word segmentation in Vietnamese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Corpus Linguistics</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Word segmentation for Vietnamese text categorization: an online corpus approach. Research, Innovation and Vision for the Future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 4th International Conference on Computer Sciences</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Toan</surname></persName>
		</author>
		<title level="m">Vietnamese Word Segmentation. The 6 th Natural Language Processing Pacific Rim Symposium</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="749" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 18th International Conference on Machine Learning</title>
		<meeting><address><addrLine>Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Hoang</surname></persName>
		</author>
		<title level="m">Foundations of linguistics and Vietnamese</title>
		<imprint>
			<publisher>Education Publisher</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="142" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Internet and Genetics Algorithm-based Text Classification for Documents in Vietnamese. Research, Innovation and Vision for the Future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hoang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3th International Conference on Computer Sciences</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A: Chinese Segmentation and New Word Detection using Conditional Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 20th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rabiner: A tutorial on hidden markov models and selected applications in speech recognition</title>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shallow parsing with Conditional Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Language Technology</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Chunking with Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Second Meeting of the North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
