<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative Adversarial Network for Abstractive Text Summarization *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linqing</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Alberta Machine Intelligence Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
							<email>min.yang1129@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">MOE Key Laboratory of Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Zhu</surname></persName>
							<email>jzhu@m.scnu.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">South China Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">MOE Key Laboratory of Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Generative Adversarial Network for Abstractive Text Summarization *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose an adversarial process for abstrac-tive text summarization, in which we simultaneously train a generative model G and a discriminative model D. In particular , we build the generator G as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization. We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary. Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset. Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Abstractive text summarization is the task of generating a short and concise summary that captures the salient ideas of the source text. The generated summaries potentially contain new phrases and sentences that may not appear in the source text. In the past decades, a flurry of studies have been conducted on abstractive text summarization ( <ref type="bibr" target="#b2">Nallapati et al. 2016;</ref><ref type="bibr" target="#b4">See, Liu, and Manning 2017;</ref><ref type="bibr" target="#b3">Paulus, Xiong, and Socher 2017)</ref>. Despite the remarkable progress of previous studies, abstractive summarization is still challenged by (i) Neural sequence-to-sequence models tend to generate trivial and generic summary, often involving high-frequency phrases; (ii) The generated summaries have limited grammaticality and readability; (iii) In most previous work the standard sequence-to-sequence models are trained to predict the next word in summary using the maximumlikelihood estimation (MLE) objective function. However, this strategy has two major shortcomings. First, the evaluation metric is different from the training loss. Second, the input of the decoder in each time step is often from the true summary during the training. Nevertheless, in the testing phase, the input of the next time step is the previous word * The work was partially supported by CAS Pioneer Hundred <ref type="table">Talents Program and</ref>  To address the above challenge, in this paper, we propose an adversarial framework to jointly train a generative model G and a discriminative model D. Specifically, the generator G takes the original text as input and generate the summary. We use reinforcement learning (i.e., policy gradient) to optimize G for a highly rewarded summary. Thus, it effectively bypasses exposure bias and non-differentiable task metrics issues. We implement the discriminator D as a text classifier that learns to classify the generated summaries as machine or human generated. The generator G and the discriminator D are optimized with a minimax two-player game. The discriminator D tries to distinguish the ground truth summaries from the generated summaries by the generator G, while the training procedure of generator G is to maximize the probability of D making a mistake. Thus, this adversarial process can eventually adjust G to generate plausible and high-quality abstractive summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our model</head><p>Similar to the standard training strategy ( <ref type="bibr">Goodfellow et al. 2014</ref>), we simultaneously train two models in an adversarial manner: a generative model G and a discriminative model D. We first pre-train the generative model by generating summaries given the source text. Then we pre-train the discriminator by providing positive examples from the humangenerated summaries and the negative examples produced from the pre-trained generator. After the pre-training, the generator and discriminator are trained alternatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative Model</head><p>The generator takes the source text x = {w 1 , w 2 , ..., w n } as input and predicts the summaryˆysummaryˆ summaryˆy = { ˆ y 1 , ˆ y 2 , ..., ˆ y m }. Here, the n is the length of the source text x and m is the length of the predicted summary. We use a bi-directional LSTM encoder to convert the input text x into a sequence of hidden states h = {h 1 , . . . , h n }. Following (See, Liu, and Manning 2017), on time step t, an attention-based LSTM decoder is then used to compute the hidden state s t of the decoder and a context vector c t . The reader can refer to the supplement of this paper (or (See, Liu, and Manning 2017)) for the implementation details. The parameters of the generator G are collectively represented by θ. The context vector c t is concatenated with the decoder state s t and fed through a fully <ref type="bibr">-18)</ref> connected layer and a softmax layer to produce the probability of predicting word from target vocabulary at each time step t:</p><note type="other">The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI</note><formula xml:id="formula_0">P vocab ( ˆ yt) = sof tmax(V 񮽙 (V [st, ct] + b) + b 񮽙 )</formula><p>where V 񮽙 , V , b, b 񮽙 are learnable parameters. Similar to the work of (See, Liu, and Manning 2017), we incorporate a switching pointer-generator network to use either word generator from fixed vocabulary or pointer copying rare or unseen from the input sequence. Finally, we can get the final probability P ( ˆ y t ) of each tokenˆytokenˆ tokenˆy t in the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discriminative Model</head><p>The discriminator is a binary classifier and aims at distinguishing the input sequence as originally generated by humans or synthesized by machines. We encode the input sequence with a CNN as it shows great effectiveness in text classification <ref type="bibr" target="#b2">(Kim 2014</ref>). We use multiple filters with varying window sizes to obtain different features and then apply a max-over-time pooling operation over the features. These pooled features are passed to a fully connected softmax layer whose output is the probability of being original.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Updating model parameters</head><p>In the adversarial process, using the discriminator as a reward function can further improve the generator iteratively by dynamically updating the discriminator. Once we obtain more realistic and high-quality summaries generated by generator G, we re-train the discriminator as:</p><formula xml:id="formula_1">min φ −E Y ∼p data [logD φ (Y )] − E Y ∼G θ [log(1 − D φ (Y ))]</formula><p>When the discriminator D is obtained and fixed, we are ready to update the generator G. The loss function of our generator G consists two parts: the loss computed by policy gradient (denoted by J pg ) and the maximum-likelihood loss (denoted by J ml ). Formally, the objective function of G is J = βJ pg + (1 − β)J ml , where β is the scaling factor to balance the magnitude difference between J pg and J ml . According to the policy gradient theorem <ref type="bibr" target="#b5">(Sutton et al. 2000)</ref>, we compute the gradient of J pg w.r.t. the parameters θ:</p><formula xml:id="formula_2">񮽙 θ Jpg = 1 T T 񮽙 t=1 񮽙 y t R G θ D ((Y1:t−1, X), yt) · 񮽙 θ (G θ (yt|Y1:t−1, X)) = 1 T T 񮽙 t=1 E y t ∈G θ [R G θ D ((Y1:t−1, X), yt)񮽙 θ log p(yt|Y1:t−1, X)]</formula><p>where</p><formula xml:id="formula_3">R G θ D ((Y 1:t−1 , X), y t )</formula><p>is the action-value function, and we have</p><formula xml:id="formula_4">R G θ D ((Y 1:t−1 , X), y t ) = D φ (Y 1:T ),</formula><p>T is the length of the text. We update the parameters using stochastic gradient descent, Y 1:t is the generated summary up to time step t, X is the source text to be condensed.  We firstly compare our model with the pre-trained generator. After adversarial training, ROUGE-1, ROUGE-2, ROUGE-L increase by 1.10, 0.84 and 1.00 absolute points respectively. In addition, our model exhibits competitive Rouge scores with the state-of-the-art methods. Specifically, our approach achieves the best ROUGE-1 and ROUGE-2 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>We also perform human evaluation to evaluate the readability and quality of summaries. We randomly select 50 test examples from the dataset. For each example, two human evaluators are asked to rank each summary generated by all 5 models based on their readability, where 1 indicates the lowest level of readability while 5 indicates the highest level. As we can observe from <ref type="table" target="#tab_2">Table 1</ref>, our model contributes significantly to improving the readability of summaries.</p><p>To evaluate the proposed model qualitatively, we also report the generated summaries in supplementary files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we proposed an adversarial process for abstractive text summarization. Experimental results showed that our model could generate more abstractive, readable and diverse summaries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 : Quantitative evaluation results</head><label>1</label><figDesc></figDesc><table>Experimental Results. We compare our approach with 
three methods, including the abstractive model (ABS) (Nal-
lapati et al. 2016), the pointer-generator coverage networks 
(PGC) (See, Liu, and Manning 2017), and the abstrac-
tive deep reinforced model (DeepRL) (Paulus, Xiong, and 
Socher 2017) (ML+RL version). 
</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abstractive text summarization using sequence-to-sequence rnns and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<idno>arXiv:1602.06023</idno>
	</analytic>
	<monogr>
		<title level="m">Convolutional neural networks for sentence classification</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.04304</idno>
		<title level="m">A deep reinforced model for abstractive summarization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04368</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
