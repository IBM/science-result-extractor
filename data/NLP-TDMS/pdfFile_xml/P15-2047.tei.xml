<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-06T23:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Dependency-Based Neural Network for Relation Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<email>lisujian@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<settlement>Troy</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<email>mingzhou@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<email>wanghf@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="laboratory" key="lab2">MOE</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Dependency-Based Neural Network for Relation Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="285" to="290"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Previous research on relation classification has verified the effectiveness of using dependency shortest paths or subtrees. In this paper, we further explore how to make full use of the combination of these dependency information. We first propose a new structure, termed augmented dependency path (ADP), which is composed of the shortest dependency path between two entities and the subtrees attached to the shortest path. To exploit the semantic representation behind the ADP structure, we develop dependency-based neural networks (DepNN): a recursive neural network designed to model the subtrees, and a convolutional neural network to capture the most important features on the shortest path. Experiments on the SemEval-2010 dataset show that our proposed method achieves state-of-art results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation classification aims to classify the semantic relations between two entities in a sentence. It plays a vital role in robust knowledge extraction from unstructured texts and serves as an intermediate step in a variety of natural language processing applications. Most existing approaches follow the machine learning based framework and focus on designing effective features to obtain better classification performance.</p><p>The effectiveness of using dependency relations between entities for relation classification has been reported in previous approaches <ref type="bibr" target="#b0">(Bach and Badaskar, 2007)</ref>. For example, <ref type="bibr" target="#b13">Suchanek et al. (2006)</ref> carefully selected a set of features from tokenization and dependency parsing, and extended some of them to generate high order features * Contribution during internship at <ref type="bibr">Microsoft Research.</ref> in different ways. <ref type="bibr" target="#b3">Culotta and Sorensen (2004)</ref> designed a dependency tree kernel and attached more information including Part-of-Speech tag, chunking tag of each node in the tree. Interestingly, <ref type="bibr" target="#b1">Bunescu and Mooney (2005)</ref> provided an important insight that the shortest path between two entities in a dependency graph concentrates most of the information for identifying the relation between them. <ref type="bibr" target="#b0">Nguyen et al. (2007)</ref> developed these ideas by analyzing multiple subtrees with the guidance of pre-extracted keywords. Previous work showed that the most useful dependency information in relation classification includes the shortest dependency path and dependency subtrees. These two kinds of information serve different functions and their collaboration can boost the performance of relation classification (see Section 2 for detailed examples). However, how to uniformly and efficiently combine these two components is still an open problem. In this paper, we propose a novel structure named Augmented Dependency Path (ADP) which attaches dependency subtrees to words on a shortest dependency path and focus on exploring the semantic representation behind the ADP structure.</p><p>Recently, deep learning techniques have been widely used in exploring semantic representations behind complex structures. This provides us an opportunity to model the ADP structure in a neural network framework. Thus, we propose a dependency-based framework where two neural networks are used to model shortest dependency paths and dependency subtrees separately. One convolutional neural network (CNN) is applied over the shortest dependency path, because CNN is suitable for capturing the most useful features in a flat structure. A recursive neural network (RN-N) is used for extracting semantic representations from the dependency subtrees, since RNN is good at modeling hierarchical structures. To connect these two networks, each word on the shortest A thief who tried to steal the truck broke the ignition with screwdriver. On the Sabbath the priests broke the commandment with priestly work.  path is combined with a representation generated from its subtree, strengthening the semantic representation of the shortest path. In this way, the augmented dependency path is represented as a continuous semantic vector which can be further used for relation classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition and Motivation</head><p>The task of relation classification can be defined as follows. Given a sentence S with a pair of entities e 1 and e 2 annotated, the task is to identify the semantic relation between e 1 and e 2 in accordance with a set of predefined relation classes (e.g., Content-Container, Cause-Effect). For example, in <ref type="figure" target="#fig_2">Figure 2</ref>, the relation between two entities e 1 =thief and e 2 =screwdriver is InstrumentAgency. <ref type="bibr" target="#b1">Bunescu and Mooney (2005)</ref> first used shortest dependency paths between two entities to capture the predicate-argument sequences (e.g., "thief←broke→screwdriver" in <ref type="figure" target="#fig_2">Figure 2</ref>), which provide strong evidence for relation classification. As we observe, the shortest paths contain more information and the subtrees attached to each node on the shortest path are not exploited enough. For example, <ref type="figure" target="#fig_2">Figure 2a</ref> and 2b show two instances which have similar shortest dependency paths but belong to different relation classes. Methods only using the path will fail in this case. However, we can distinguish these two paths by virtue of the attached subtrees such as "dobj→commandment" and "dobj→ignition". Based on many observations like this, we propose the idea that combines the subtrees and the shortest path to form a more precise structure for classifying relations. This combined structure is called "augmented dependency path (ADP)", as illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>Next, our goal is to capture the semantic representation of the ADP structure between two entities. We first adopt a recursive neural network to model each word according to its attached dependency subtree. Based on the semantic information of each word, we design a convolutional neural network to obtain salient semantic features on the shortest dependency path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dependency-Based Neural Networks</head><p>In this section, we will introduce how we use neural network techniques and dependency information to explore the semantic connection between two entities. We dub our architecture of modeling ADP structures as dependency-based neural networks (DepNN). <ref type="figure" target="#fig_3">Figure 3</ref> illustrates DepNN with a concrete example. First, we associate each word w and dependency relation r with a vector representation x w , x r ∈ R dim . For each word w on the shortest dependency path, we develop an RNN from its leaf words up to the root to generate a subtree embedding c w and concatenate c w with x w to serve as the final representation of w. Next, a CNN is designed to model the shortest dependency path based on the representation of its words and relations. Finally our framework can efficiently represent the semantic connection between two entities with consideration of more comprehensive dependency information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modeling Dependency Subtree</head><p>The goal of modeling dependency subtrees is to find an appropriate representation for the words on the shortest path. We assume that each word w can be interpreted by itself and its children on the dependency subtree. Then, for each word w on the subtree, its word embedding x w ∈ R dim and subtree representation c w ∈ R dimc are concatenated to form its final representation p w ∈ R dim+dimc . For a word that does not have a subtree, we set its subtree representation as c LEAF . The subtree representation of a word is derived through transforming the representations of its children words. During the bottom-up construction of the subtree, each word is associated with a dependency relation such as dobj as in <ref type="figure" target="#fig_3">Figure 3</ref>. For each dependency relation r, we set a transformation matrix W r ∈ R dimc×(dim+dimc) which is learned during training. Then we can get,</p><formula xml:id="formula_0">c w = f ( q∈Children(w) W R (w,q) · p q + b) (1) p q = [x q , c q ]<label>(2)</label></formula><p>where R (w,q) denotes the dependency relation between word w and its child word q. This process continues recursively up to the root word on the shortest path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling Shortest Dependency Path</head><p>To classify the semantic relation between two entities, we further explore the semantic representation behind their shortest dependency path, which can be seen as a sequence of words and dependency relations as the bold-font part in <ref type="figure" target="#fig_2">Figure 2</ref>. As the convolutional neural network (CNN) is good at capturing the salient features from a sequence of objects, we design a CNN to tackle the shortest dependency path. A CNN contains a convolution operation over a window of object representations, followed by a pooling operation. As we know, a word w on the shortest path is associated with the representation p w through modeling the subtree. For a dependency relation r on the shortest path, we set its representation as a vector x r ∈ R dim . As a sliding window is applied on the sequence, we set the window size as k. For example, when k = 3, the sliding windows of a shortest dependency path with n words are: {[r s w 1 r 1 ], [r 1 w 2 r 2 ], . . . , [r n−1 w n r e ]} where r s and r e are used to denote the beginning and end of a shortest dependency path between two entities.</p><p>We concatenate k neighboring words (or dependency relations) representations into a new vector. Assume X i ∈ R dim·k+dimc·nw as the concatenated representation of the i-th window, where n w is the number of words in one window. A convolution operation involves a filter W 1 ∈ R l×(dim·k+dimc·nw) , which operates on X i to produce a new feature vector L i with l dimensions,</p><formula xml:id="formula_1">L i = W 1 X i (3)</formula><p>where the bias term is ignored for simplicity. Then W 1 is applied to each possible window in the shortest dependency path to produce a feature map:</p><formula xml:id="formula_2">[L 0 , L 1 , L 2 , · · · ].</formula><p>Next, we adopt the widely-used max-over-time pooling operation <ref type="bibr" target="#b2">(Collobert et al., 2011</ref>), which can retain the most important features, to obtain the final representation L from the feature map. That is,</p><formula xml:id="formula_3">L = max(L 0 , L 1 , L 2 , . . . ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning</head><p>Like other relation classification systems, we also incorporate some lexical level features such as named entity tags and WordNet hypernyms, which prove useful to this task. We concatenate them with the ADP representation L to produce a combined vector M . We then pass M to a fully connected sof tmax layer whose output is the probability distribution y over relation labels.</p><formula xml:id="formula_4">M = [L, LEX]<label>(4)</label></formula><formula xml:id="formula_5">y = sof tmax(W 2 M + b 2 )<label>(5)</label></formula><p>Then, the optimization objective is to minimize the cross-entropy error between the ground-truth label vector and the sof tmax output. Parameters are learned using the back-propagation method <ref type="bibr" target="#b10">(Rumelhart et al., 1988</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare DepNN against multiple baselines on <ref type="bibr" target="#b4">SemEval-2010</ref><ref type="bibr">dataset (Hendrickx et al., 2010</ref>.</p><p>The training set includes 8000 sentences, and the test set includes 2717 sentences. There are 9 relation types, and each type has two directions. Instances which don't fall in any of these classes are labeled as Other. The official evaluation metric is the macro-averaged F1-score (excluding Other) and the direction is considered. We use dependency trees generated by the Stanford Parser ( <ref type="bibr" target="#b6">Klein and Manning, 2003</ref>) with the collapsed option.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Contributions of different components</head><p>We first show the contributions from different components of DepNN. Two different kinds of word embeddings for initialization are used in the experiments. One is the 50-d embeddings provided by SENNA <ref type="figure" target="#fig_1">(Collobert et al., 2011</ref>). The second is the 200-d embeddings used in ( <ref type="bibr" target="#b15">Yu et al., 2014</ref>), trained on Gigaword with word2vec 1 . All the hyperparameters are set with 5-fold crossvalidation.  We start with a baseline model using a CNN with only the words on the shortest path. We then add dependency relations and attached subtrees. The results indicate that both parts are effective for relation classification. The rich linguistic information embedded in the dependency relations and subtrees can on one hand, help distinguish different functions of the same word, and on the other hand infer an unseen word's role in the sentence. Finally, the lexical features are added and DepNN achieves state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with Baselines</head><p>In this subsection, we compare DepNN with several baseline relation classification approaches. Here, DepNN and the baselines are all based on the 200-d embeddings trained on Gigaword due to the larger corpus and higher dimensions.</p><p>SVM ( <ref type="bibr" target="#b9">Rink and Harabagiu, 2010)</ref>: This is the top performed system in <ref type="bibr" target="#b4">SemEval-2010</ref>   DT-RNN ( <ref type="bibr" target="#b12">Socher et al., 2014</ref>) : This is an RNN for modeling dependency trees. It combines node's word embedding with its children through a linear combination but not a subtree embedding. We adapt the augmented dependency path into a dependency subtree and apply DT-RNN.</p><p>As shown in <ref type="table">Table 2</ref>, DepNN achieves the best result (83.6) using NER features. WordNet features can also improve the performance of DepN-N, but not as obvious as NER. <ref type="bibr" target="#b15">Yu et al. (2014)</ref> had similar observations, since the larger number of WordNet tags may cause overfitting. SVM achieves a comparable result, though the quality of feature engineering highly relies on human experience and external NLP resources. MV-RNN models the constituent parse trees with a recursive procedure and its F1-score is about 1.8 percent lower than DepNN. Meanwhile, MVR-NN is very slow to train, since each word is associated with a matrix. Both CNN and FCM use features from the whole sentence and achieve similar performance. DT-RNN is the worst of all baselines, though it also considers the information from shortest dependency paths and attached subtrees. As we analyze, shortest dependency paths and subtrees play different roles in relation classification. However, we can see that DT-RNN does not distinguish the modeling processes of shortest paths and subtrees. This phenomenon is also seen in a kernel-based method <ref type="bibr" target="#b14">(Wang, 2008)</ref>, where the tree kernel performs worse than the shortest path kernel. We also look into the DepNN model and find it can identify different patterns of words and the dependency relations. For example, in the Instrument-Agency relation, the word "using" and the dependency relation "prep with" are found playing a major role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose to classify relations between entities by modeling the augmented dependency path in a neural network framework. We present a novel approach, DepNN, to taking advantages of both convolutional neural network and recursive neural network to model this structure. Experiment results demonstrate that DepNN achieves state-of-the-art performance.</p><p>of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 2335-2344, Dublin, Ireland, August. Dublin City University and Association for Computational Linguistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>290</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sentences and their dependency trees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Augmented dependency paths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of Dependency-based Neural Networks.</figDesc><graphic url="image-2.png" coords="3,113.26,177.07,176.26,72.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 :</head><label>2</label><figDesc>Results on SemEval-2010 dataset with Gigaword embeddings. MV-RNN (Socher et al., 2012): This model finds the path between the two entities in the con- stituent parse tree and then learns the distributed representation of its highest node with a matrix for each word to make the compositions specific. CNN: Zeng et al. (2014) build a convolutional model over the tokens of a sentence to learn the sentence level feature vector. It uses a special position vector that indicates the relative distances of current input word to two marked entities. FCM (Yu et al., 2014): FCM decomposes the sentence into substructures and extracts features for each of them, forming substructure embed- dings. These embeddings are combined by sum- pooling and input into a sof tmax classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Performance of DepNN with different 
components. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>.</head><label></label><figDesc></figDesc><table>It utilizes 
many external corpora to extract features from the 
sentence to build an SVM classifier. 

1 https://code.google.com/p/word2vec/ 

Model 
Additional Features 
F1 

SVM 
POS, PropBank, morphological 
82.2 
WordNet, TextRunner, FrameNet 
dependency parse, etc. 
MV-RNN POS, NER, WordNet 
81.8 2 
CNN 
WordNet 
82.7 
FCM 
NER 
83.0 
DT-RNN 
NER 
73.1 

DepNN 
WordNet 
83.0 
NER 
83.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> MV-RNN achieves a higher F1-score (82.7) on SENNA embeddings reported in the original paper.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank all the anonymous reviewers for their insightful comments. This work was partially sup- </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A survey on relation extraction. Language Technologies Institute</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Shortest Path Dependency Kernel for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dependency Tree Kernels for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="423" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Sebastian Pad ok, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multi-Way Classification of Semantic Relations Between Pairs of Nominals</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Relation extraction from wikipedia using subtree mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Dat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">1414</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">AAAI Press</title>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Utd: Classifying semantic relations by combining lexical and semantic resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Rink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="256" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning representations by backpropagating errors. Cognitive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Grounded compositional semantics for finding and describing images with sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combining linguistic and statistical analysis to extract relations from web documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Ifrim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="712" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A re-examination of dependency path kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="841" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Factor-based compositional embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Learning Semantics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
