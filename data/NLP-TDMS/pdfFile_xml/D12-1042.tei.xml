<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-instance Multi-label Learning for Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2012-07">July 2012. 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
							<email>mihais@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Center</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SRI International</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Center</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SRI International</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
							<email>nallapat@ai.sri.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
							<email>manning@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Center</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SRI International</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-instance Multi-label Learning for Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
						<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning <address><addrLine>Jeju Island, Korea</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="12" to="14"/>
							<date type="published" when="2012-07">July 2012. 2012</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Distant supervision for relation extraction (RE)-gathering training data by aligning a database of facts with text-is an efficient approach to scale RE to thousands of different relations. However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown. For example, a sentence containing Balzac and France may express BornIn or Died, an unknown relation, or no relation at all. Because of this, traditional supervised learning, which assumes that each example is explicitly mapped to a label, is not appropriate. We propose a novel approach to multi-instance multi-label learning for RE, which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables. Our model performs competitively on two difficult domains.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information extraction (IE), defined as the task of extracting structured information (e.g., events, binary relations, etc.) from free text, has received renewed interest in the "big data" era, when petabytes of natural-language text containing thousands of different structure types are readily available. However, traditional supervised methods are unlikely to scale in this context, as training data is either limited or nonexistent for most of these structures. One of the most promising approaches to IE that addresses this limitation is distant supervision, which generates training data automatically by aligning a database of facts with text <ref type="bibr" target="#b3">(Craven and Kumlien, 1999;</ref><ref type="bibr" target="#b2">Bunescu and Mooney, 2007)</ref>.</p><p>In this paper we focus on distant supervision for relation extraction (RE), a subproblem of IE that addresses the extraction of labeled relations between two named entities. <ref type="figure" target="#fig_0">Figure 1</ref> shows a simple example for a RE domain with two labels. Distant supervision introduces two modeling challenges, which we highlight in the table. The first challenge is that some training examples obtained through this heuristic are not valid, e.g., the last sentence in <ref type="figure" target="#fig_0">Fig- ure 1</ref> is not a correct example for any of the known labels for the tuple. The percentage of such false positives can be quite high. For example, <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> report up to 31% of false positives in a corpus that matches Freebase relations with New York Times articles. The second challenge is that the same pair of entities may have multiple labels and it is unclear which label is instantiated by any textual mention of the given tuple. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, the tuple (Barack Obama, United States) has two valid labels: BornIn and EmployedBy, each (latently) instantiated in different sentences. In the Riedel corpus, 7.5% of the entity tuples in the training partition have more than one label.</p><p>We summarize this multi-instance multi-label (MIML) learning problem in <ref type="figure" target="#fig_1">Figure 2</ref>. In this paper we propose a novel graphical model, which we called MIML-RE, that targets MIML learning for relation extraction. Our work makes the following contributions:</p><p>(a) To our knowledge, MIML-RE is the first RE approach that jointly models both multiple instances (by modeling the latent labels assigned to instances) and multiple labels (by providing a simple method to capture dependencies between labels). For example, our model learns that certain labels tend to be generated jointly while others cannot be jointly assigned to the same tuple.</p><p>(b) We show that MIML-RE performs competitively on two difficult domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Distant supervision for IE was introduced by <ref type="bibr" target="#b3">Craven and Kumlien (1999)</ref>, who focused on the extraction of binary relations between proteins and cells/tissues/diseases/drugs using the Yeast Protein Database as a source of distant supervision. Since then, the approach grew in popularity ( <ref type="bibr" target="#b2">Bunescu and Mooney, 2007;</ref><ref type="bibr" target="#b0">Bellare and McCallum, 2007;</ref><ref type="bibr">Wu and Weld, 2007;</ref><ref type="bibr" target="#b8">Mintz et al., 2009;</ref><ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b5">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b9">Nguyen and Moschitti, 2011;</ref><ref type="bibr" target="#b11">Sun et al., 2011;</ref><ref type="bibr" target="#b12">Surdeanu et al., 2011a</ref>). However, most of these approaches make one or more approximations in learning. For example, most proposals heuristically transform distant supervision to traditional supervised learning (i.e., singleinstance single-label) <ref type="bibr" target="#b0">(Bellare and McCallum, 2007;</ref><ref type="bibr">Wu and Weld, 2007;</ref><ref type="bibr" target="#b8">Mintz et al., 2009;</ref><ref type="bibr" target="#b9">Nguyen and Moschitti, 2011;</ref><ref type="bibr" target="#b11">Sun et al., 2011;</ref><ref type="bibr" target="#b12">Surdeanu et al., 2011a)</ref>. <ref type="bibr" target="#b2">Bunescu and Mooney (2007)</ref> and <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> model distant supervision for relation extraction as a multi-instance single-label problem, which allows multiple mentions for the same tuple but disallows more than one label per object. Our work is closest to <ref type="bibr" target="#b5">Hoffmann et al. (2011)</ref>. They address the same problem we do (binary relation extraction) with a MIML model, but they make two approximations. First, they use a deterministic model that aggregates latent instance labels into a set of labels for the corresponding tuple by OR-ing the classification results. We use instead an objectlevel classifier that is trained jointly with the classifier that assigns latent labels to instances and can capture dependencies between labels. Second, they use a Perceptron-style additive parameter update approach, whereas we train in a Bayesian framework. We show in Section 5 that these approximations generally have a negative impact on performance.</p><p>MIML learning has been used in fields other than natural language processing. For example, <ref type="bibr" target="#b14">Zhou and Zhang (2007)</ref> use MIML for scene classification. In this problem, each image may be assigned multiple labels corresponding to the different scenes captured. Furthermore, each image contains a set of patches, which forms the bag of instances assigned to the given object (image). Zhou and Zhang propose two algorithms that reduce the MIML problem to a more traditional supervised learning task. In one algorithm, for example, they convert the task to a multi-instance single-label problem by creating a separate bag for each label. Due to this, the proposed approach cannot model inter-label dependencies. Moreover, the authors make a series of approximations, e.g., they assume that each instance in a bag shares the bag's overall label. We instead model all these issues explicitly in our approach.</p><p>In general, our approach belongs to the category of models that learn in the presence of incomplete or incorrect labels. There has been interest among machine learning researchers in the general problem of noisy data, especially in the area of instance-based learning. <ref type="bibr" target="#b1">Brodley and Friedl (1999)</ref> summarize past approaches and present a simple, all-purpose method to filter out incorrect data before training. While potentially applicable to our problem, this approach is completely general and cannot incorporate our domain-specific knowledge about how the noisy data is generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distant Supervision for Relation Extraction</head><p>Here we focus on distant supervision for the extraction of relations between two entities. We define a relation as the construct r(e 1 , e 2 ), where r is the relation name, e.g., BornIn in <ref type="figure" target="#fig_0">Figure 1</ref>, and e 1 and e 2 are two entity names, e.g., Barack Obama and United States. Note that there are entity tuples (e 1 , e 2 ) that participate in multiple relations, r 1 , . . . , r i . In other words, the tuple (e 1 , e 2 ) is the object illustrated in <ref type="figure" target="#fig_1">Figure 2</ref> and the different relation names are the labels. We define an entity mention as a sequence of text tokens that matches the corresponding entity name in some text, and relation mention (for a given relation r(e 1 , e 2 )) as a pair of entity mentions of e 1 and e 2 in the same sentence. Relation mentions thus correspond to the instances in <ref type="figure" target="#fig_1">Figure 2</ref>. <ref type="bibr">1</ref> As the latter definition indicates, we focus on the extraction of relations expressed in a single sentence. Furthermore, we assume that entity mentions are extracted by a different process, such as a named entity recognizer.</p><p>We define the task of relation extraction as a function that takes as input a document collection (C), a set of entity mentions extracted from C (E), a set of known relation labels (L) and an extraction model, and outputs a set of relations (R) such that any of the relations extracted is supported by at least one sentence in C. To train the extraction model, we use a database of relations (D) that are instantiated at least once in C. Using distant supervision, D is aligned with sentences in C, producing relation mentions for all relations in D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>Our model assumes that each relation mention involving an entity pair has exactly one label, but allows the pair to exhibit multiple labels across different mentions. Since we do not know the actual relation label of a mention in the distantly supervised setting, we model it using a latent variable z that can take one of the k pre-specified relation labels as well as an additional NIL label, if no relation is expressed by the corresponding mention. We model the multiple relation labels an entity pair can assume <ref type="bibr">1</ref> For this reason, we use relation mention and relation instance interchangeably in this paper.  We unrolled the y plate to emphasize that it is a collection of binary classifiers (one per relation label), whereas the z classifier is multi-class. Each z and y j classifier has an additional prior parameter, which is omitted here for clarity.</p><p>using a multi-label classifier that takes as input the latent relation types of the all the mentions involving that pair. The two-layer hierarchical model is shown graphically in <ref type="figure" target="#fig_3">Figure 3</ref>, and is described more formally below. The model includes one multi-class classifier (for z) and a set of binary classifiers (for each y j ). The z classifier assigns latent labels from L to individual relation mentions or NIL if no relation is expressed by the mention. Each y j classifier decides if relation j holds for the given entity tuple, using the mention-level classifications as input. Specifically, in the figure:</p><p>• n is the number of distinct entity tuples in D;</p><p>• M i is the set of mentions for the ith entity pair;</p><p>• x is a sentence and z is the latent relation classification for that sentence;</p><p>• w z is the weight vector for the multi-class mention-level classifier;</p><p>• k is the number of known relation labels in L;</p><p>• y j is the top-level classification decision for the entity pair as to whether the jth relation holds;</p><p>• w j is the weight vector for the binary top-level classifier for the jth relation.</p><p>Additionally, we define P i (N i ) as the set of all known positive (negative) relation labels for the ith entity tuple. In this paper, we construct N i as L \ P i , but, in general, other scenarios are possible. For example, both Sun et al. (2011) and <ref type="bibr" target="#b12">Surdeanu et al. (2011a)</ref> proposed models where N i for the ith tuple (e 1 , e 2 ) is defined as:</p><formula xml:id="formula_0">{r j | r j (e 1 , e k ) ∈ D, e k = e 2 , r j / ∈ P i }, which is a subset of L \ P i .</formula><p>That is, entity e 2 is considered a negative example for relation r j (in the context of entity e 1 ) only if r j exists in the training data with a different value.</p><p>The addition of the object-level layer (for y) is an important contribution of this work. This layer can capture information that cannot be modeled by the mention-level classifier. For example, it can learn that two relation labels (e.g., BornIn and SpouseOf) cannot be generated jointly for the same entity tuple. So, if the z classifier outputs both these labels for different mentions of the same tuple, the y layer can cancel one of them. Furthermore, the y classifiers can learn when two labels tend to appear jointly, e.g., CapitalOf and Contained between two locations, and use this occurrence as positive reinforcement for these labels. We discuss the features that implement these ideas in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training</head><p>We train the proposed model using hard discriminative Expectation Maximization (EM). In the Expectation (E) step we assign latent mention labels using the current model (i.e., the mention and relation level classifiers). In the Maximization (M) step we retrain the model to maximize the log likelihood of the data using the current latent assignments.</p><p>In the equations that follow, we refer to w 1 , . . . , w k collectively as w y for compactness. The vector z i contains the latent mention-level classifications for the ith entity pair, while y i represents the corresponding set of gold-standard labels (that is, y (r) i = 1 if r ∈ P i , and y (r) i = 0 for r ∈ N i .) Using these notations, the log-likelihood of the data is given by:</p><formula xml:id="formula_1">LL(w y , w z ) = n i=1 log p(y i |x i , w y , w z ) = n i=1 log z i p(y i , z i |x i , w y , w z )</formula><p>The joint probability in the inner summation can be broken up into simpler parts:</p><formula xml:id="formula_2">p(y i , z i |x i , w y , w z ) = p(z i |x i , w z )p(y i |z i , w y ) = m∈M i p(z (m) i |x (m) i , w z ) r∈P i ∪N i p(y (r) i |z i , w (r) y )</formula><p>where the last step follows from conditional independence. Thus the log-likelihood for this problem is not convex (it includes a sum of products). However, we can still use EM, but the optimization focuses on maximizing the lower bound of the loglikelihood, i.e., we maximize the above joint probability for each entity pair in the database. Rewriting this probability in log space, we obtain:</p><formula xml:id="formula_3">log p(y i , z i |x i , w y , w z )<label>(1)</label></formula><formula xml:id="formula_4">= m∈M i log p(z (m) i |x (m) i , w z )+ r∈P i ∪N i log p(y (r) i |z i , w<label>(r)</label></formula><p>y )</p><p>The algorithm proceeds as follows. E-step: In this step we infer the mention-level classifications z i for each entity tuple, given all its mentions, the gold labels y i , and current model, i.e., w z and w y weights. Formally, we seek to find:</p><formula xml:id="formula_5">z i * = arg max z p(z|y i , x i , w y , w z )</formula><p>However it is computationally intractable to consider all vectors z as there is an exponential number of possible assignments, so we approximate and consider each mention separately. Concretely,</p><formula xml:id="formula_6">p(z (m) i |y i , x i , w y , w z ) ∝ p(y i , z (m) i |x i , w y , w z ) ≈ p(z (m) i |x (m) i , w z )p(y i |z i , w y ) = p(z (m) i |x (m) i , w z ) r∈P i ∪N i p(y (r) i |z i , w (r) y )</formula><p>where z i contains the previously inferred mention labels for group i, with the exception of component m whose label is replaced by z . So for i = 1, . . . , n, and for each m ∈ M i we calculate:</p><formula xml:id="formula_7">z (m) * i = arg max z p(z|x (m) i , w z )×<label>(2)</label></formula><formula xml:id="formula_8">r∈P i ∪N i p(y (r) i |z i , w (r) y )</formula><p>Intuitively, the above equation indicates that mention labels are chosen to maximize: (a) the probabilities assigned by the mention-level model; (b) the probability that the correct relation labels are assigned to the corresponding tuple; and (c) the probability that the labels known to be incorrect are not assigned to the tuple. For example, if a particular mention label receives a high mention-level probability but it is known to be a negative label for that tuple, it will receive a low overall score.</p><p>M-step: In this step we find w y , w z that maximize the lower bound of the log-likelihood, i.e., the probability in equation <ref type="formula" target="#formula_3">(1)</ref>, given the current assignments for z i . From equation <ref type="formula" target="#formula_3">(1)</ref> it is clear that this can be maximized separately with respect to w y and w z . Intuitively, this step amounts to learning the weights for the mention-level classifier (w z ) and the weights for each of the k top-level classifiers (w y ). The updates are given by:</p><formula xml:id="formula_9">w * z = arg max w n i=1 m∈M i log p(z (m) * i |x (m) i , w) (3) w (r) * y = arg max w 1≤i≤n s.t. r∈P i ∪N i log p(y (r) i |z * i , w)<label>(4)</label></formula><p>Note that these are standard updates for logistic regression. We obtained these weights using k + 1 logistic classifiers: one multi-class classifier for w z and k binary classifiers for each relation label r ∈ L. We implemented all using the L2-regularized logistic regression from the publicly-downloadable Stanford CoreNLP package. <ref type="bibr">2</ref> The main difference between the classifiers is how features are generated: the mention-level classifier computes its features based on x i , whereas the relation-level classifiers generate features based on the current assignments for z i and the corresponding relation label r. We discuss the actual features used in our experiments in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inference</head><p>Given an entity tuple, we obtain its relation labels as follows. We first classify its mentions:</p><formula xml:id="formula_10">z (m) * i = arg max z p(z|x (m) i , w z )<label>(5)</label></formula><p>2 nlp.stanford.edu/software/corenlp.shtml then decide on the final relation labels using the toplevel classifiers:</p><formula xml:id="formula_11">y (r) * i = arg max y∈{0,1} p(y|z * i , w (r) y )<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>We discuss next several details that are crucial for the correct implementation of the above model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialization:</head><p>Since EM is not guaranteed to converge at the global maximum of the observed data likelihood, it is important to provide it with good starting values. In our context, the initial values are labels assigned to z i , which are required to compute equation <ref type="formula" target="#formula_7">(2)</ref> in the first iteration (z i ). We generate these values using a local logistic regression classifier that uses the same features as the mention-level classifier in the joint model but treats each relation mention independently. We train this classifier using "traditional" distant supervision: for each relation in the database D we assume that all the corresponding mentions are positive examples for the corresponding label ( <ref type="bibr" target="#b8">Mintz et al., 2009)</ref>. Note that this heuristic repeats relation mentions with different labels for the tuples that participate in multiple relations. For example, all the relation mentions in <ref type="figure" target="#fig_0">Figure 1</ref> will yield datums with both the EmployedBy and BornIn labels. Despite this limitation, we found that this is a better initialization heuristic than random assignment.</p><p>For the second part of equation <ref type="formula" target="#formula_7">(2)</ref>, we initialize the relation-level classifier with a model that replicates the at least one heuristic of <ref type="bibr" target="#b5">Hoffmann et al. (2011)</ref>. Each w (r) y model has a single feature with a high positive weight that is triggered when label r is assigned to any of the mentions in z * i .</p><p>Avoiding overfitting: A na¨ıvena¨ıve implementation of our approach leads to an unrealistic training scenario where the z classifier generates predictions (in equation (2)) for the same datums it has seen in training in the previous iteration. To avoid this overfitting problem we used cross validation: we divided the training tuples in K distinct folds and trained K different mention-level classifiers. Each classifier outputs p(z|x</p><p>i , w z ) for tuples in a given fold during the E-step (equation <ref type="formula" target="#formula_7">(2)</ref>) and is trained (equation <ref type="formula">(3)</ref>) using tuples from all other folds. i , w z ) in equation <ref type="formula" target="#formula_10">(5)</ref> as the average of the probabilities of the above set of mention classifiers:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>At testing time, we compute p(z|x</head><formula xml:id="formula_13">p(z|x (m) i , w z ) = K j=1 p(z|x (m) i , w j z ) K</formula><p>where w j z are the weights of the mention classifier responsible for fold j. We found that this simple bagging model performs slightly better in practice (a couple of tenths of a percent) than training a single mention classifier on the latent mention labels generated in the last training iteration.</p><p>Inference during training: During the inference process in the E-step, the algorithm incrementally "flips" mention labels based on equation <ref type="formula" target="#formula_7">(2)</ref>, for each group of mentions M i . Thus, z i changes as the algorithm progresses, which may impact the label assigned to the remaining mentions in that group. To avoid any potential bias introduced by the arbitrary order of mentions as seen in the data, we randomize each group M i before we inspect its mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>We evaluate our algorithm on two corpora. The first was developed by <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> by aligning Freebase 3 relations with the New York Times (NYT) corpus. They used the Stanford named entity recognizer ( <ref type="bibr" target="#b4">Finkel et al., 2005</ref>) to find entity mentions in text and constructed relation mentions only between entity mentions in the same sentence. <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> observes that evaluating on this corpus underestimates true extraction accuracy because Freebase is incomplete. Thus, some relations extracted during testing will be incorrectly marked as wrong, simply because Freebase has no information on them. To mitigate this issue, <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> and Hoffman et al. (2011) perform a second evaluation where they compute the accuracy of labels assigned to a set of relation mentions that they manually annotated. To avoid any potential annotation biases, we instead evaluate on a second corpus that has comprehensive annotations generated by experts for all test relations.</p><p>We constructed this second dataset using mainly resources distributed for the 2010 and 2011 KBP shared tasks ( <ref type="bibr" target="#b6">Ji et al., 2010;</ref><ref type="bibr" target="#b7">Ji et al., 2011</ref>). We generated training relations from the knowledge base provided by the task organizers, which is a subset of the English Wikipedia infoboxes from a 2008 snapshot. Similarly to the corpus of <ref type="bibr">Riedel et al.,</ref> these infoboxes contain open-domain relations between named entities, but with a different focus. For example, more than half of the relations in the evaluation data are alternate names of organizations or persons (e.g., org:alternate names) or relations associated with employment and membership (e.g., per:employee of) (Ji et al., 2011). We aligned these relations against a document collection that merges two distinct sources: (a) the collection provided by the shared task, which contains approximately 1.5 million documents from a variety of sources, including newswire, blogs and telephone conversation transcripts; and (b) a complete snapshot of the English Wikipedia from June 2010. During training, for each entity tuple (e 1 , e 2 ), we retrieved up to 50 sentences that contain both entity mentions. <ref type="bibr">4</ref> We used Stanford's CoreNLP package to find entity mentions in text and, similarly to <ref type="bibr" target="#b10">Riedel et al. (2010)</ref>, we construct relation mention candidates only between entity mentions in the same sentence. We analyzed a set of over 2,000 relation mentions and we found that 39% of the mentions where e 1 is an organization name and 36% of mentions where e 1 is a person name do not express the corresponding relation.</p><p>At evaluation time, the KBP shared task requires the extraction of all relations r(e 1 , e 2 ) given a query that contains only the first entity e 1 . To accommodate this setup, we adjusted our sentence extraction component to use just e 1 as the retrieval query and we kept up to 50 sentences that contain a mention of the input entity for each evaluation query. For tuning and testing we used the 200 queries from the 2010 and 2011 evaluations. We randomly selected 40 queries for development and used the remaining 160 for the formal evaluation.</p><p>To address the large number of negative examples in training, Riedel et al. subsampled them randomly with a retention probability of 10%. For the KBP corpus, we followed the same strategy, but we used # of gold # of gold % of gold entity tuples % of gold entity tuples <ref type="table" target="#tab_1">% of mentions that  relations  relations with more than one label  with multiple mentions in text  do not express  # of relation labels  in training in testing  in training  in training  their relation  Riedel  4,700  1,950  7.5%  46.4%  up to 31%  51  KBP  183,062  3,334  2.8%  65.1%  up to 39%  41   Table 1</ref>: Statistics about the two corpora used in this paper. Some of the numbers for the Riedel dataset is from ( <ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b5">Hoffmann et al., 2011</ref>).</p><p>a subsampling probability of 5% because this led to the best results in development for all models. <ref type="table">Table 1</ref> provides additional statistics about the two corpora. The table indicates that having multiple mentions for an entity tuple is a very common phenomenon in both corpora, and that having multiple labels per tuple is more common in the Riedel dataset than KBP (7.5% vs. 2.8%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Features</head><p>Our model requires two sets of features: one for the mention classifier (z) and one for the relation classifier (y). In the Riedel dataset, we used the same features as <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> and <ref type="bibr" target="#b5">Hoffmann et al. (2011)</ref> for the mention classifier. In the KBP dataset, we used a feature set that was developed in our previous work ( <ref type="bibr" target="#b13">Surdeanu et al., 2011b</ref>). These features can be grouped in three classes: (a) features that model the two entities, such as their head words; (b) features that model the syntactic context of the relation mention, such as the dependency path between the two entity mentions; and (c) features that model the surface context, such as the sequence of part of speech tags between the two entity mentions. We used these features for all the models evaluated on the KBP dataset. <ref type="bibr">5</ref> For the relation-level classifier, we developed two feature groups. The first models <ref type="bibr">Hoffmann et al.'</ref>s at least one heuristic using a single feature, which is set to true if at least one mention in z i has the label r, which is modeled by the current relation classifier. The second group models the dependencies between relation labels. This is implemented by a set of |L| − 1 features, where feature j is instantiated whenever the label modeled (r) is predicted jointly with another label r j (r j ∈ L, r j = r) in z i . These features learn both positive and negative reinforcements between labels. For example, if labels r 1 and r 2 tend to be generated jointly, the feature for the corresponding dependency will receive a positive weight in the models for r 1 and r 2 . Similarly, if r 1 and r 2 cannot be generated jointly, the model will assign a negative weight to feature 2 in r 1 's classifier and to feature 1 in r 2 's classifier. Note that this feature is asymmetric, i.e., feature 1 in r 2 's classifier may have a different value than feature 2 in r 1 's classifier, depending on the accuracy of the individual predictions for r 1 and r 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>We compare our approach against three models:</p><p>Mintz++ -This is the model used to initialize the mention-level classifier in our model. As discussed in Section 4.3, this model follows the "traditional" distant supervision heuristic, similarly to ( <ref type="bibr" target="#b8">Mintz et al., 2009</ref>). However, our implementation has several advantages over the original model: (a) we model each relation mention independently, whereas Mintz et al. collapsed all the mentions of the same entity tuple into a single datum; (b) we allow multi-label outputs for a given entity tuple at prediction time by OR-ing the predictions for the individual relation mentions corresponding to the tuple (similarly to (Hoffmann et al., 2011)) <ref type="bibr">6</ref> ; and (c) we use the simple bagging strategy described in Section 4.3 to combine multiple models. Empirically, we observed that these changes yield a significant improvement over the original proposal. For this reason, we consider this model a strong baseline on its own.</p><p>Riedel -This is the "at-least-once" model reported in ( <ref type="bibr" target="#b10">Riedel et al., 2010)</ref>, which had the best performance in that work. This approach models the task as a multi-instance single-label problem. Note that this is the only model shown here that does not allow multi-label outputs for an entity tuple.</p><p>Hoffmann -This is the "MultiR" model, which performed the best in ( <ref type="bibr" target="#b5">Hoffmann et al., 2011</ref>). This models RE as a MIML problem, but learns using a Perceptron algorithm and uses a deterministic "at least one" decision instead of a relation classifier. We used Hoffman's publicly released code <ref type="bibr">7</ref> for the experiments on the Riedel dataset and our own implementation for the KBP experiments. <ref type="bibr">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>We tuned all models using three-fold cross validation for the Riedel dataset and using the development queries for the KBP dataset. MIML-RE has two parameters that require tuning: the number of EM epochs (T ) and the number of folds for the mention classifiers (K). <ref type="bibr">9</ref> The values obtained after tuning are T = 15, K = 5 for the Riedel dataset and T = 8, K = 3 for KBP. Similarly, we tuned the number of epochs for the Hoffmann model on the KBP dataset, obtaining an optimal value of 20.</p><p>On the Riedel dataset we evaluate all models using standard precision and recall measures. For the KBP evaluation we used the official KBP scorer, 10 with two changes: (a) we score with the parameter anydoc set to true, which configures the scorer to accept relation mentions as correct regardless of their supporting document; and (b) we score only on the subset of gold relations that have at least one mention in our sentences. The first decision is necessary because the gold KBP answers contain supporting documents only from the corpus provided by the organizers but we retrieve candidate answers from multiple collections. The second is required because the focus of this work is not on sentence retrieval but on RE, which should be evaluated in isolation. <ref type="bibr">11</ref> Similarly to previous work, we report precision/recall curves in <ref type="figure" target="#fig_6">Figure 4</ref>. We evaluate two variants of MIML-RE: one that includes all the features for the y model, and another (MIML-RE At-Least-One) which has only the at least one feature. For all the Bayesian models implemented here, we sorted the predicted relations by the noisyor score of the top predictions for their mentions. Formally, we rank a relation r predicted for group i, i.e., r ∈ y * i , using:</p><formula xml:id="formula_14">noisyOr i (r) = 1 − m∈M i (1 − s (m) i (r)) where s (m) i (r) = p(r|x (m) i , wz) if r = z (m) * i</formula><p>or 0 otherwise. The noisy-or formula performs well for ranking because it integrates model confidence (the higher the probabilities, the higher the score) and redundancy (the more mentions are predicted with a label, the higher that label's score). Note that the above ranking score does not include the probability of the relation classifier (equation <ref type="formula" target="#formula_11">(6)</ref>) for MIML-RE. While we use equation <ref type="formula" target="#formula_11">(6)</ref> to generate y * i , we found that the corresponding probabilities are too coarse to provide a good ranking score. This is caused by the fact that our relation-level classifier works with a small number of (noisy) features. Lastly, for our implementation of the Hoffmann et al. model, we used their ranking heuristic (sorting predictions by the maximum extraction score for that relation). <ref type="figure" target="#fig_6">Figure 4</ref> indicates that MIML-RE generally outperforms the current state of the art. In the Riedel dataset, MIML-RE has higher overall recall than the Riedel et al. model, and, for the same recall point, MIML-RE's precision is between 2 and 15 points higher. For most of the curve, our model obtains better precision for the same recall point than the Hoffmann model, which currently has the best reported results on this dataset. The difference is as high as 5 precision points around the middle of the curve. The Hoffmann model performs better close to the extremities of the curve (low/high recall). Nevertheless, we argue that our model is more stable than Hoffmann's: MIML-RE yields a smoother precision/recall curve, without most of the depressions seen in the Hoffmann results. In the KBP dataset, MIML-RE performs consistently better than our implementation of Hoffmann's model, with higher precision values for the same recall point, and much higher overall recall. We believe that these differences are caused by our Bayesian framework, which provides a more formal implementation of the MIML problem. <ref type="figure" target="#fig_6">Figure 4</ref> also indicates that MIML-RE yields a consistent improvement over Mintz++ (with the exception of a few points in the low-recall portion of the KBP curves). The difference in precision for the same recall point is as high as 25 precision points in the Riedel dataset and up to 5 points in KBP. Overall, the best F1 score of MIML-RE is slightly over 1 point higher than the best F1 score of Mintz++ in the Riedel dataset and 3 points higher in KBP. Considering that Mintz++ is a strong baseline and we evaluate on two challenging domains, we consider these results proof that the correct modeling of the MIML scenario is beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Lastly, <ref type="figure" target="#fig_6">Figure 4</ref> shows that MIML-RE outperforms its variant without label-dependency features (MIML-RE At-Least-One) in the higherrecall part of the curve in the Riedel dataset. The improvement is approximately 1 F1 point throughout the last segment of the curve. The overall increase in F1 was found to be significant (p = 0.0296) in a one-sided, paired t-test over randomly sampled test data. We see a smaller improvement in KBP (concentrated around the middle of the curve), likely because the number of entity tuples with multiple labels in training is small (see <ref type="table">Table 1</ref>). Nevertheless, this exercise shows that, when dependencies between labels exist in a dataset, modeling them, which can be trivially done in MIML-RE, is useful.   In a similar vein, we tested the models previously described on a subset of the Riedel evaluation dataset that only includes groups with at least 10 mentions. This corpus contains approximately 2% of the groups from the original testing partition, out of which 90 tuples have at least one known label and 1410 groups serve as negative examples.</p><p>For conciseness, we do not include the entire precision/recall curves for this experiment, but summarize them in <ref type="table" target="#tab_1">Table 2</ref>, which lists the performance peak (highest F1 score) for each of the models investigated. The table shows that MIML-RE obtains the highest F1 score overall, 1.5 points higher than MIML-RE At-Least-One and 2.6 points higher than Mintz++. More importantly, for approximately the same recall point, MIML-RE obtains a precision that is over 8 percentage points higher than that of MIML-RE At-Least-One. A post-hoc inspection of the results indicates that, indeed, MIML-RE successfully eliminates undesired labels when two (or more) incompatible labels are jointly assigned to the same tuple. Take for example the tuple (Mexico City, Mexico), for which the correct relation is /location/administrative division/country. MIML-RE At-Least-One incorrectly predicts the additional /location/location/contains relation, while MIML-RE does not make this prediction because it recognizes that these two labels are incompatible in general: one location cannot both be within another location and contain it. Indeed, examining the weights assigned to label-dependency features in MIML-RE, we see that the model has assigned a large negative weight to the dependency feature between /location/location/contains and /location/administrative division/country for the /location/location/contains class. We also observe positive dependencies between labels. For example, MIML-RE learns that the relations /people/person/place lived and /people/person/place of birth tend to co-occur and assigns a positive weight to this dependency feature for the corresponding classes.</p><p>These results strongly suggest that when all aspects of the MIML scenario are present, our model can successfully capture them and make use of the additional structure to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we showed that distant supervision for RE, which generates training data by aligning a database of facts with text, poses a distinct multiinstance multi-label learning scenario. In this setting, each entity pair to be modeled typically has multiple instances in the text and may have multiple labels in the database. This is considerably different from traditional supervised learning, where each instance has a single, explicit label.</p><p>We argued that this MIML scenario should be formally addressed. We proposed, to our knowledge, the first approach that models all aspects of the MIML setting, i.e., the latent assignment of labels to instances and dependencies between labels assigned to the same entity pair.</p><p>We evaluated our model on two challenging domains and obtained state-of-the-art results on both. Our model performs well even when not all aspects of the MIML scenario are common, and as seen in the discussion, shows significant improvement when evaluated on entity pairs with many labels or mentions. When all aspects of the MIML scenario are present, our model is well-equipped to handle them.</p><p>The code and data used in the experiments reported in this paper are available at: http://nlp. stanford.edu/software/mimlre.shtml.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Training sentences generated through distant supervision for a database containing two facts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of multi-instance multi-label learning. To contrast, in traditional supervised learning there is one instance and one label per object. For relation extraction the object is a tuple of two named entities. Each mention of this tuple in text generates a different instance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: MIML model plate diagram. We unrolled the y plate to emphasize that it is a collection of binary classifiers (one per relation label), whereas the z classifier is multi-class. Each z and y j classifier has an additional prior parameter, which is omitted here for clarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results in the Riedel dataset (top) and the KBP dataset (bottom). The Hoffmann scores in the KBP dataset were generated using our implementation. The other Hoffmann and Riedel results were taken from their papers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>P</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results at the highest F1 point in the preci-
sion/recall curve on the dataset that contains groups with 
at least 10 mentions. 

</table></figure>

			<note place="foot" n="3"> freebase.com</note>

			<note place="foot" n="4"> Sentences were ranked using the similarity between their parent document and the query that concatenates the two entity names. We used the default Lucene similarity measure.</note>

			<note place="foot" n="5"> To avoid an excessive number of features in the KBP experiments, we removed features seen less than five times in training.</note>

			<note place="foot" n="6"> We also allow multiple labels per tuple at training time, in which case we replicate the corresponding datum for each label. However, this did not improve performance significantly compared to selecting a single label per datum during training.</note>

			<note place="foot" n="7"> cs.washington.edu/homes/raphaelh/mr/ 8 The decision to reimplement the Hoffmann model was a practical one, driven by incompatibilities between their implementation and our KBP framework. 9 We could also tune the prior parameters for both our model and Mintz++, but we found in early experiments that the default value of 1 yields the best scores for all priors. 10 nlp.cs.qc.cuny.edu/kbp/2011/scoring.html 11 Due to these changes, the scores reported in this paper are not directly comparable with the shared task scores.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge the support of Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no. FA8750-09-C-0181. Any opinions, findings, and conclusion or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the DARPA, AFRL, or the US government. We gratefully thank Raphael Hoffmann and Sebastian Riedel for sharing their code and data and for the many useful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning extractors from unlabeled text using relevant databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Information Extraction on the Web</title>
		<meeting>the Sixth International Workshop on Information Extraction on the Web</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying mislabeled training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Friedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<date type="published" when="1999" />
			<publisher>JAIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to extract relations from the web using minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Kumlien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology</title>
		<meeting>the Seventh International Conference on Intelligent Systems for Molecular Biology</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2010 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><forename type="middle">Ellis</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2011 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 47th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Daniel Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using distant supervision from external semantic repositories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truc</forename><surname>Vien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD &apos;10)</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD &apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">New York University 2011 system for KBP slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stanford&apos;s distantlysupervised slot-filling system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><forename type="middle">I</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Customizing an information extraction system to a new domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Gusev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the International Conference on Information and Knowledge Management (CIKM)<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Proceedings of the Workshop on Relational Models of Semantics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-instance multilabel learning with application to scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
