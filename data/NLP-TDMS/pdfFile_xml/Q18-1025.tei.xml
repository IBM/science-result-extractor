<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-06T23:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From Characters to Time Intervals: New Paradigms for Evaluation and Neural Parsing of Time Normalizations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Egoitz</forename><surname>Laparra</surname></persName>
							<email>laparra@email.arizona.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona Tucson</orgName>
								<address>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongfang</forename><surname>Xu</surname></persName>
							<email>dongfangxu9@email.arizona.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona Tucson</orgName>
								<address>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
							<email>bethard@email.arizona.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona Tucson</orgName>
								<address>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">From Characters to Time Intervals: New Paradigms for Evaluation and Neural Parsing of Time Normalizations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents the first model for time normalization trained on the SCATE corpus. In the SCATE schema, time expressions are annotated as a semantic composition of time entities. This novel schema favors machine learning approaches, as it can be viewed as a semantic parsing task. In this work, we propose a character level multi-output neural network that outperforms previous state-of-the-art built on the TimeML schema. To compare predictions of systems that follow both SCATE and TimeML, we present a new scoring metric for time intervals. We also apply this new metric to carry out a comparative analysis of the annotations of both schemes in the same corpus.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Time normalization is the task of translating natural language expressions of time to computer-readable forms. For example, the expression three days ago could be normalized to the formal representation 2017-08-28 in the ISO-8601 standard. As time normalization allows entities and events to be placed along a timeline, it is a crucial step for many information extraction tasks. Since the first shared tasks on time normalization <ref type="bibr" target="#b17">(Verhagen et al., 2007)</ref>, interest in the problem and the variety of applications have been growing. For example, <ref type="bibr" target="#b8">Lin et al. (2015)</ref> use normalized timestamps from electronic medical records to contribute to patient monitoring and detect potential causes of disease. <ref type="bibr" target="#b18">Vossen et al. (2016)</ref> identify multilingual occurrences of the same events in the news * These two authors contributed equally.</p><p>by, among other steps, normalizing time-expressions in different languages with the same ISO standard. <ref type="bibr">Fischer and Strötgen (2015)</ref> extract and normalize time-expressions from a large corpus of German fiction as the starting point of a deep study on trends and patterns of the use of dates in literature.</p><p>A key consideration for time normalization systems is what formal representation the time expressions should be normalized to. The most popular scheme for annotating normalized time expressions is ISO-TimeML ( <ref type="bibr" target="#b11">Pustejovsky et al., 2003a;</ref><ref type="bibr">Puste- jovsky et al., 2010</ref>), but it is unable to represent several important types of time expressions (e.g., a bounded set of intervals, like Saturdays since March 6) and it is not easily amenable to machine learning (the rule-based HeidelTime <ref type="bibr" target="#b14">(Strötgen et al., 2013</ref>) still yields state-of-the-art performance). <ref type="bibr" target="#b0">Bethard and Parker (2016)</ref> proposed an alternate scheme, Semantically Compositional Annotation of Time <ref type="bibr">Ex- pressions (SCATE)</ref>, in which times are annotated as compositional time entities <ref type="figure" target="#fig_0">(Figure 1)</ref>, and suggested that this should be more amenable to machine learning. However, while they constructed an annotated corpus, they did not train any automatic models on it.</p><p>We present the first machine-learning models trained on the SCATE corpus of time normalizations. We make several contributions in the process:</p><p>• We introduce a new evaluation metric for time normalization that can compare normalized times from different annotation schemes by measuring overlap of intervals on the timeline.</p><p>• We use the new metric to compare SCATE and TimeML annotations on the same corpus, and confirm that SCATE covers a wider variety of  time expressions.</p><p>• We develop a recurrent neural network for learning SCATE-style time normalization, and show that our model outperforms the state-of-the-art HeidelTime <ref type="bibr" target="#b14">(Strötgen et al., 2013</ref>).</p><p>• We show that our character-based multi-output neural network architecture outperforms both word-based and single-output models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>ISO-TimeML ( <ref type="bibr" target="#b11">Pustejovsky et al., 2003a;</ref>) is the most popular scheme for annotating time expressions. It annotates time expressions as phrases, and assigns an ISO 8601 normalization (e.g., 1990-08-15T13:37 or PT24H) as the VALUE attribute of the normalized form. ISO-TimeML is used in several corpora, including the TimeBank (Pustejovsky et al., 2003b), <ref type="bibr">WikiWars (Mazur and Dale, 2010)</ref>, <ref type="bibr">TimeN (Llorens et al., 2012)</ref>, and the TempEval shared tasks <ref type="bibr" target="#b17">(Verhagen et al., 2007;</ref><ref type="bibr" target="#b17">Verhagen et al., 2010;</ref><ref type="bibr" target="#b16">UzZaman et al., 2013)</ref>. However, the ISO-TimeML schema has a few drawbacks. First, times that align to more than a single calendar unit (day, week, month, etc.), such as Saturdays since March 6 (where multiple Saturdays are involved), cannot be described in the ISO 8601 format since they do not correspond to any prefix of YYYY-MM-DDTHH:MM:SS. Second, each time expression receives a single VALUE, regardless of the word span, the compositional semantics of the expression are not represented. For example, in the expressions since last week and since March 6, the semantics of since are identical -find the interval between the anchor time (last week or March 6) and now. But ISO-TimeML would have to annotate these two phrases independently, with no way to indicate the shared portion of their semantics. These drawbacks of ISO-TimeML, especially the lack of compositionality, make the development of machine learning models difficult. Thus, most prior work has taken a rule-based approach, looking up each token of a time expression in a normalization lexicon and then mapping this sequence of lexical entries to the normalized form <ref type="bibr" target="#b14">(Strötgen and Gertz, 2013;</ref><ref type="bibr" target="#b1">Bethard, 2013;</ref><ref type="bibr" target="#b7">Lee et al., 2014;</ref><ref type="bibr" target="#b14">Strötgen and Gertz, 2015)</ref>.</p><p>As an alternative to TimeML, and inspired by previous works, Schilder (2004) and <ref type="bibr">Han and Lavie (2004)</ref>, <ref type="bibr" target="#b0">Bethard and Parker (2016)</ref> proposed Semantically Compositional Annotation of Time Expressions (SCATE). In the SCATE schema, each time expression is annotated in terms of compositional time entity over intervals on the timeline. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, with every annotation corresponding to a formally defined time entity. For instance, the annotation on top of since corresponds to a BETWEEN operator that identifies an interval starting at the most recent March 6 and ending at the document creation time (DCT). The BETWEEN operator is formally defined as:</p><formula xml:id="formula_0">BETWEEN([t 1 , t 2 ) : INTERVAL, [t 3 , t 4 ) : INTERVAL) : INTERVAL = [t 2 , t 3 ).</formula><p>The SCATE schema can represent a wide variety of time expressions, and provides a formal definition of the semantics of each annotation. Unlike TimeML, SCATE uses a graph structure to capture compositional semantics and can represent time expressions that are not expressed with contiguous phrases. The schema also has the advantage that it can be viewed as a semantic parsing task and, consequently, is more suitable for machine-learning approaches. However, <ref type="bibr" target="#b0">Bethard and Parker (2016)</ref> present only a corpus; they do not present any models for semantic parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">An interval-based evaluation metric for normalized times</head><p>Before attempting to construct machine-learned models from the SCATE corpus, we were interested in evaluating <ref type="bibr" target="#b0">Bethard and Parker (2016)</ref>'s claim that the SCATE schema is able to represent a wider variety of time expressions than TimeML. To do so, we propose a new evaluation metric to compare time normalizations annotated in both the ISO 8601 format of TimeML and the time entity format of SCATE. This new evaluation interprets normalized annotations as intervals along the timeline and measures the overlap of the intervals.</p><p>TimeML TIMEX3 (time expression) annotations are converted to intervals following ISO 8601 semantics of their VALUE attribute. So, for example, 1989-03-05 is converted to the interval [1989-03-05T00:00:00, 1989-03-06T00:00:00), that is, the 24-hour period starting at the first second of the day on 1989-03-05 and ending just before the first second of the day on 1989-03-06. SCATE annotations are converted to intervals following the formal semantics of each entity, using the library provided by <ref type="bibr" target="#b0">Bethard and Parker (2016)</ref>. So, for example, <ref type="bibr">Next(Year(1985)</ref>, SimplePeriod(YEARS, 3)), the 3 years following 1985, is converted to <ref type="bibr">[1986-01-01T00:00, 1989</ref>-01-01T00:00). Note that there may be more than one interval associated with a single annotation, as in the Saturdays since March 6 example. Once all annotations have been converted into intervals along the timeline, we can measure how much the intervals of different annotations overlap.</p><p>Given two sets of intervals, we define the interval precision, P int , as the total length of the intervals in common between the two sets, divided by the total length of the intervals in the first set. Interval recall, R int is defined as the total length of the intervals in common between the two sets, divided by the total length of the intervals in the second set. Formally:</p><formula xml:id="formula_1">I S I H = {i ∩ j : i ∈ I S ∧ j ∈ I H } P int (I S , I H ) = i∈COMPACT(I S I H ) |i| i∈I S |i| R int (I S , I H ) = i∈COMPACT(I S I H ) |i| i∈∪I H |i|</formula><p>where I S and I H are sets of intervals, i ∩ j is possibly the empty interval in common between the intervals i and j, |i| is the length of the interval i, and COMPACT takes a set of intervals and merges any overlapping intervals. Given two sets of annotations (e.g., one each from two time normalization systems), we define the overall precision, P , as the average of interval precisions where each annotation from the first set is paired with all annotations that textually overlap it in the second set. Overall recall is defined as the average of interval recalls where each annotation from the second set is paired with all annotations that textually overlap it in the first set. Formally:</p><formula xml:id="formula_2">OI a (B) = b∈B:OVERLAPS(a,b) INTERVALS(b) P (S, H) = 1 |S| s∈S P int (INTERVALS(s), OI s (H)) R(S, H) = 1 |H| h∈H R int (INTERVALS(h), OI h (S))</formula><p>where S and H are sets of annotations, <ref type="bibr">INTERVALS(x)</ref> gives the time intervals associated with the annotation x, and OVERLAPS(a, b) decide whether the annotations a and b share at least one character of text in common.</p><p>It is important to note that these metrics can be applied only to time expressions that yield bounded intervals. Time expressions that refer to intervals with undefined boundaries are out of the scope, like in "it takes just a minute" or "I work every Saturday".  ) of which 580 yield bounded intervals, i.e. intervals with a specified start and ending (last Monday is bounded, while every month is not). We apply the interval-based evaluation metric introduced in Section 3 to the AQUAINT and TimeBank datasets, treating the TimeML annotations as the system (S) annotator and the SCATE annotations as the human (H) annotator. <ref type="table" target="#tab_2">Table 2</ref> shows that the SCATE annotations cover different time intervals than the TimeML annotations. In the first row, we see that TimeML has a recall of only 92% of the time intervals identified by SCATE in the AQUAINT corpus and of only 83% in the TimeBank corpus. We manually analyzed all places where TimeML and SCATE annotations differed and found that the SCATE interpretation was always the correct one.</p><p>For example, a common case where TimeML and SCATE annotations overlap, but are not identical, is time expressions preceded by a preposition like "since". The TimeML annotation for "Since 1985" (with a DCT of 1998-03-01T14:11) only covers the year, "1985", resulting in the time interval <ref type="bibr">[1985- 01-01T00:00,1986</ref>-01-01T00:00). The SCATE annotation represents the full expression and, consequently, produces the correct time interval <ref type="bibr">[1986-01- 01T00:00,1998-03-01T14:11)</ref>.</p><p>Another common case of disagreement is where TimeML failed to compose all pieces of a complex expression. The TimeML annotation for "10:35 a.m. (0735 GMT) Friday" annotates two separate intervals, the time and the day (and ignores "0735 GMT" entirely). The SCATE annotation recognizes this as a description of a single time interval, <ref type="bibr">[1998-08- 07T10:35, 1998-08-07T10:36)</ref>.</p><p>TimeML and SCATE annotations also differ in how references to particular past periods are interpreted. For example, TimeML assumes that "last year" and "a year ago" have identical semantics, referring to the most recent calendar year, e.g., if the DCT is 1998-03-04, then they both refer to the interval [1997-01-01T00:00,1998-01-01T00:00). SCATE has the same semantics for "last year", but recognizes that "a year ago" has different semantics: a period centered at one year prior to the DCT. Under SCATE, "a year ago" refers to the interval [1996-09-03T00:00,1997-09-03T00:00).</p><p>Beyond these differences in interpretation, we also observed that, while the SCATE corpus annotates time expressions anywhere in the document (including in metadata), the TimeBank TIMEX3 annotations are restricted to the main text of the documents. The second row of <ref type="table" target="#tab_2">Table 2</ref> shows the evaluation when comparing overall text in the document, not just the body text. Unsurprisingly, TimeML has a lower recall of the time intervals from the SCATE annotations under this evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Types of SCATE annotations</head><p>Studying the training and development portion of the dataset, we noticed that the SCATE annotations can be usefully divided into three categories: nonoperators, explicit operators, and implicit operators. We define non-operators as NUMBERs, PERIODs (e.g., three months), explicit intervals (e.g., <ref type="bibr">YEARs like 1989)</ref>, and repeating intervals (DAY-OF-WEEKs like Friday, MONTH-OF-YEARs like January, etc.). Non-operators are basically atomic; they can be in-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>346</head><p>Non-Op Exp-Op Imp- <ref type="table" target="#tab_2">Op Total  1497  305  219 2021  74%</ref> 15% 11% 100% terpreted without having to refer to other annotations. Operators are not atomic; they can only be interpreted with respect to other annotations they link to. For example, the THIS operator in <ref type="figure" target="#fig_0">Figure 1</ref> can only be interpreted by first interpreting the DAY-OF-WEEK non-operator and the BETWEEN operator that it links to. We split operators into two types: explicit and implicit. We define an operator as explicit if it does not overlap with any other annotation. This occurs, for example, when the time connective since evokes the BETWEEN operator in <ref type="figure" target="#fig_0">Figure 1</ref>. An operator is considered to be implicit if it overlaps with another annotation. This occurs, for example, with the LAST operator in <ref type="figure" target="#fig_0">Figure 1</ref>, where March implies last March, but there is no explicit signal in the text, and it must be inferred from context. We study how these annotation groups distribute in the AQUAINT and TimeBank documents. <ref type="table" target="#tab_3">Table 3</ref> shows that non-operators are much more frequent than operators (both explicit and implicit).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models</head><p>We decompose the normalization of time expressions into two subtasks: a) time entity identification which detects the spans of characters that belong to each time expression and labels them with their corresponding time entity; and b) time entity composition that links relevant entities together while respecting the entity type constraints imposed by the SCATE schema. These two tasks are run sequentially using the output of the former as input to the latter. Once identification and composition steps are completed we can use the final product, i.e. semantic compositional of time entities, to feed the SCATE interpreter 1 and encode time intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Time entity identification</head><p>Time entity identification is a type of sequence tagging task where each piece of a time expression is assigned a label that identifies the time entity that it evokes. We express such labels using the BIO tagging system, where B stands for the beginning of an annotation, I for the inside, and O for outside any annotation. Differing somewhat from standard sequence tagging tasks, the SCATE schema allows multiple annotations over the same span of text (e.g., "Saturdays" in <ref type="figure" target="#fig_0">Figure 1</ref> is both a DAY-OF-WEEK and a THIS), so entity identification models must be able to handle such multi-label classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Neural architectures</head><p>Recurrent neural networks (RNN) are the stateof-the-art on sequence tagging tasks ( <ref type="bibr" target="#b5">Lample et al., 2016a;</ref><ref type="bibr">Graves et al., 2013;</ref><ref type="bibr" target="#b11">Plank et al., 2016</ref>) thanks to their ability to maintain a memory of the sequence as they read it and make predictions conditioned on long distance features, so we also adopt them here. We introduce three RNN architectures that share a similar internal structure, but differ in how they represent the output. They convert the input into features that feed an embedding layer. The embedded feature vectors are then fed into two stacked bidirectional Gated Recurrent Units (GRUs), and the second GRU followed by an activation function, outputs one BIO tag for each input. We select GRU for our models as they can outperform another popular recurrent unit LSTM (Long Short Term Memory), in terms of parameter updates and convergence in CPU time with the same number of parameters ( <ref type="bibr" target="#b4">Chung et al., 2014</ref>).</p><p>Our 1-Sigmoid model <ref type="figure" target="#fig_1">(Figure 2</ref>) approaches the task as a multi-label classification problem, with a set of sigmoids for each output that allow zero or more BIO labels to be predicted simultaneously. This is the standard way of encoding multi-label classification problems for neural networks, but in our experiments, we found that these models perform poorly since they can overproduce labels for each input, e.g., 03 could be labeled with both DAY-OF-MONTH and MONTH-OF-YEAR at the same time.</p><p>Our 2-Softmax model <ref type="figure" target="#fig_2">(Figure 3</ref>) splits the output space of labels into two sets: non-operators and operators (as defined in Section 4.2). It is very unlikely that any piece of text will be annotated with more than one non-operator or with more than one operator, 2 though it is common for text to be anno-   tated with one non-operator and one operator (see <ref type="figure" target="#fig_0">Figure 1)</ref>. As a result, we can use two softmaxes, one for non-operators and one for operators, and the 2-Softmax model thus can produce 0, 1, or 2 labels per input. We share input and embedding layers, but associate a separate set of stacked Bi-GRUs with each output category, as shown in 3 In preliminary experiments, we tried sharing GRU layers as well, but this generally resulted in worse performance. in Section 4.2). We expect this to help the model since the learning task is very different for these two cases: with explicit operators, the model just has to memorize which phrases evoke which operators, while with implicit operators, the model has to learn to infer an operator from context (verb tense, etc.). We use three softmaxes, one each for non-operators, explicit operators, and implicit operators, and, as with 2-Softmax, we share input and embedding layers, but associate a separate set of stacked Bi-GRUs with each output category. The model looks similar to <ref type="figure" target="#fig_2">Figure 3</ref>, but with three output groups instead of two.</p><p>We feed three features as input to the RNNs:</p><p>Text: The input word itself for the word-by-word model, or a the single input character for the character-by-character model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unicode character categories:</head><p>The category of each character as defined by the Unicode standard. <ref type="bibr">4</ref> This encodes information like the presence of uppercase (Lu) or lowercase (Ll) letters, punctuation (Po), digits (Nd), etc. For the word-by-word model, we concatenate the character categories of all characters in the word (e.g., May becomes LULLLL).</p><p>Part-of-speech: The part-of-speech as determined by the Stanford POS tagger ( <ref type="bibr" target="#b15">Toutanova et al., 2003</ref>).</p><p>We expect this to be useful for, e.g., finding verb tense to help distinguish between implicit LAST and NEXT operators. For the character-by-character model, we repeat the word-level part-of-speech tag for each character in the word, and characters with no part-ofspeech (e.g., spaces) get no tag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Input: words vs. characters</head><p>Identifying SCATE-style time entity is a sequence tagging task, similar to named entity recognition (NER), so we take inspiration from recent work in neural architectures for NER. The first neural NER models followed the prior (non-neural) work in approaching NER as a word classification problem, applying architectures such as sliding-window feedforward neural networks ( <ref type="bibr" target="#b12">Qi et al., 2009</ref>), convolutional neural networks (CNNs) with conditional random field (CRF) layers <ref type="bibr" target="#b4">(Collobert et al., 2011</ref>), and LSTM with CRF layers and hand-crafted features <ref type="bibr">(Huang et al., 2015)</ref>. More recently, character-level neural networks have also been proposed for NER, including several which combine a CNN or LSTM for learning character-based representations of words with an LSTM or LSTM-CRF for word-by-word labeling ( <ref type="bibr" target="#b3">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b6">Lample et al., 2016b;</ref><ref type="bibr" target="#b10">Ma and Hovy, 2016)</ref>, as well as character-by-character sequence-to-sequence networks ( <ref type="bibr" target="#b4">Gillick et al., 2016;</ref><ref type="bibr">Kuru et al., 2016)</ref>.</p><p>Based on these works, we consider two forms of input processing for our RNNs: word-by-word vs. character-by-character. Several aspects of the time normalization problem make the character-based approach especially appealing. First, many time phrases involve numbers that must be interpreted semantically (e.g., a good model should learn that months cannot be a number higher than 12), and digit-bydigit processing of numbers allows such interpretations, while treating each number as a word would result in a sparse, intractable learning problem. Second, word-based models assume that we know how to tokenize the text into words, but at times present challenging formats such as overnight, where over evokes a LAST operator and night is a PART-OF-DAY. Finally, character-based models can ameliorate outof-vocabulary (OOV) words, which are a common problem when training sparse datasets. (Hybrid wordcharacter models, such as the LSTM-CNNs-CRF ( <ref type="bibr" target="#b10">Ma and Hovy, 2016)</ref> can address this last problem, but not the previous two.)</p><p>For our word-based model, we apply the NLTK Tokenizer ( <ref type="bibr" target="#b2">Bird et al., 2009</ref>) to each sentence. We further tokenize with the regular expression "\d+|[ˆ\d\W]+|\S" to break apart alphanumeric expressions like 1620EDT. However, the tokenizer is unable to break-apart expressions such as 19980206 and overnight. For our character-based model, no tokenization is applied and every character (including whitespace characters) is fed as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Time entity composition</head><p>Once the entities of the time-expressions are identified, they must be composed in order to obtain their semantic interpretation. This step of the analysis consists of two parts: linking the entities that make up a time-expression together and completing the entities' properties with the proper values. For both cases, we set a simple set of rules that follow the constraints imposed by the SCATE schema 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Time entity linking</head><p>Algorithm 1 shows the process followed to obtain the links between the time entities. First, we define an empty stack that will store the entities belonging to the same time expression. Then, we iterate over the list of entities of a document sorted by their starting character offsets (SORTBYSTART). For each of these entities (entity 1 ) and for each entity in the stack (entity 2 ), we check if the guidelines specify a possible link (LINKISVALID) between the types of entity 1 and entity 2 . If such a link is possible, and Algorithm 1 Linking time entities stack = ∅ for entity 1 in SORTBYSTART(entities) do if START(entity 1 ) -END(stack) &gt; 10 then stack = ∅ end if for entity 2 in stack do if LINKISVALID(entity 1 , entity 2 ) then CREATELINK(entity 1 , entity 2 ) end if end for PUSH(stack, entity 1 ) end for it has not already been filled by another annotation, we greedily make the link (CREATELINK). When the distance in the number of characters between the entity and the end of the stack is bigger than 10, we assume that the entities do not belong to the time expression. Thus, we empty the stack. <ref type="bibr">6</ref> For example, our time entity identification model gets the YEAR, MONTH-OF-YEAR and DAY-OF-MONTH for the time-expression 1992-12-23. Our time entity composition algorithm then iterates over these entities. At the beginning the stack is empty, it just pushes the entity 1992 (YEAR) into the stack. For the entity 12 (MONTH-OF-YEAR) it checks if the guidelines define a possible link between this entity type and the one currently in the stack (YEAR). In this case, the guidelines establish that a YEAR can have a SUB-INTERVAL link to a SEASON-OF-YEAR, a MONTH-OF-YEAR or WEEK-OF-YEAR. Thus, the algorithm creates a SUB-INTERVAL link between 1992 and 12. The entity 12 is then pushed into the stack. This process is repeated for the entity 23 (DAY-OF-MONTH) checking if there was a possible link to the entities in the stack <ref type="bibr">(1992,</ref><ref type="bibr">12)</ref>. The guidelines define a possible SUB-INTERVAL link between MONTH-OF-YEAR and DAY-OF-MONTH, so a link is created here as well. Now, suppose that the following time entity in the list is several words ahead of 23 so the character distance between both entities is larger than 10. If that is the case the stack is empty and the process starts again to compose a new time expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Property completion</head><p>The last step is to associate each time entity of a time-expression with a set of properties that include information needed for its interpretation. Our system decides the value of these properties as follows:</p><p>TYPE: The SCATE schema defines that some entities can only have specific values. For example, a SEASON-OF-YEAR can only be SPRING, SUMMER, FALL or WINTER, a MONTH-OF-YEAR can only be JANUARY, FEBRUARY, MARCH, etc. To complete this property we take the text span of the time entity and normalize it to the values accepted in the schema. For example, if the span of a MONTH-OF-YEAR entity was the numeric value 01 we would normalize it to JANUARY, if its span was Sep. we would normalize it to SEPTEMBER, and so on.</p><p>VALUE: This property contains the value of a numerical entity, like DAY-OF-MONTH or HOUR-OF-DAY.To complete it, we just take the text span of the entity and convert it to an integer. If it is written in words instead of digits (e.g., nineteen instead of 19), we apply a simple grammar 7 to convert to an integer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEMANTICS:</head><p>In news-style texts, it is common that expressions like last Friday, when the DCT is a Friday, refer to the day as the DCT instead of the previous occurrence (as it would in more standard usage of last). SCATE indicates this with the SEMANTICS property, where the value INTERVAL-INCLUDED indicates that the current interval is included when calculating the last or next occurrence. For the rest of the cases the value INTERVAL-NOT-INCLUDED is used. In our system, when a LAST operator is found, if it is linked to a DAY-OF-WEEK (e.g. Friday) that matches the DCT, we set the value of this property to INTERVAL-INCLUDED.</p><p>INTERVAL-TYPE: Operators like NEXT or LAST need an interval as reference in order to be interpreted. Normally, this reference is the DCT. For example, next week refers to the week following the DCT, and in such a case the value of the property INTERVAL-TYPE for the operator NEXT would be DOCTIME. However, sometimes the operator is linked to an interval that serves as reference by itself, for example, "by the year 2000". In this cases the value of the INTERVAL-TYPE is LINK. Our system sets the value of this property to LINK if the operator is linked to a YEAR and DOCTIME otherwise. This is a very coarse heuristic; finding the proper anchor for a time expression is a challenging open problem for which future research is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Automatically generated training data</head><p>Every document in the dataset starts with a document creation time. These time expressions are quite particular; they occur in isolation and not within the context of a sentence and they always yield a bounded interval. Thus their identification is a critical factor in an interval based evaluation metric. However, document times appear in many different formats: "Monday, July-24, 2017", "07/24/17 09:52 AM", "08-15-17 1337 PM", etc. Many of these formats are not covered in the training data, which is drawn from a small number of news sources, each of which uses only a single format. We therefore designed a time generator to randomly generate an extra 800 isolated training examples for a wide variety of such expression formats. The generator covers 33 different formats <ref type="bibr">8</ref> which include variants covering abbreviation, with/without delimiters, mixture of digits and strings, and different sequences of time units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We train and evaluate our models on the SCATE corpus described in Section 4. As a development dataset, 14 documents are taken as a random stratified sample from the TempEval 2013 (TimeBank + AQUAINT) portion shown in <ref type="table">Table 1</ref>, including broadcast news documents (1 ABC, 1 CNN, 1 PRI, 1 VOA), and newswire documents (5 AP, 1 NYT, 4 WSJ). We use the interval-based evaluation metric described in Section 3, but also report more traditional information extraction metrics (precision, recall, and F 1 ) for the time entity identification and composition steps. Let S be the set of items predicted by the system and H is the set of items produced by the humans, precision (P ), recall (R), and F 1 are defined as:</p><formula xml:id="formula_3">P (S, H) = |S ∩ H| |S| R(S, H) = |S ∩ H| |H| F 1 (S, H) = 2 · P (S, H) · R(S, H) P (S, H) + R(S, H) .</formula><p>For these calculations, each item is an annotation, and one annotation is considered equal to another if it has the same character span (offsets), type, and properties (with the definition applying recursively for properties that point to other annotations). To make the experiments with different neural architectures comparable, we tuned the parameters of all models to achieve the best performance on the development data. Due to space constraints, we only list here the hyper-parameters for our best Char 3-Softmax: the embedding size of the character-level text, word-level text, POS tag, and unicode character category features are 128, 300, 32 and 64, respectively. To avoid overfitting, we used dropout with probabilities 0.25, 0.15 and 0.15 for the 3 features, respectively; the sizes of the first and second layer GRU units are set as 256 and 150. We trained the model with RMSProp optimization on mini-batches of size 120, and followed standard recommendations to leave the optimizer hyperparameter settings at their default values. Each model is trained for at most 800 epochs, the longest training time for Char 3-Softmax model is around 22 hours using 2x NVIDIA Kepler K20X GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model selection</head><p>We compare the different time entity identification models described in Section 5.1, training them on the training data, and evaluating them on the development data. Among the epochs of each model, we select the epoch based on the output(s) which the model is good at predicting because based on its weakness, the model would yield unstable results in our preliminary experiments. For example, for 3-Softmax models, our selections rely on the performances of non-operators and implicit-operators. <ref type="table">Table 4</ref> shows the results of the development phase.</p><p>First, we find that the character-based models outperform the word-based models. <ref type="bibr">9</ref> For example, the best character-based model achieves the F 1 of 81.7 (Char 3-Softmax),which is significantly better than the best word-based model achieving the F 1 of only Model P R F1 Word 1-Sigmoid 60.2 52.0 55.8 Char 1-Sigmoid 54.0 59.0 56.4 Word 2-Softmax 58.7 63.9 61.2 Char 2-Softmax 74.8 72.4 73.6 Word 3-Softmax 68.3 64.9 66.6 Char 3-Softmax 88.2 76.1 81.7 Char 3-Softmax extra 80.6 73.4 76.8 <ref type="table">Table 4</ref>: Precision (P ), recall (R), and F 1 for the different neural network architectures on Time entity identification on the development data.</p><p>66.6 (p=0). <ref type="bibr">10</ref> Second, we find that Softmax models outperform Sigmoid models. For example, the Char 3-Softmax model achives the F 1 of 81.7, significantly better than 56.4 F 1 of the Char 1-Sigmoid model (p=0). Third, for both character-and wordbased models, we find that 3-Softmax significantly outperforms 2-Softmax: the Char 3-Softmax F 1 of 81.7 is better than the Char 2-Softmax F 1 of 73.6 (p=0) and the Word 3-Softmax F 1 of 66.6 is better than the Word 2-Softmax F 1 of 61.2 (p=0.0254). Additionally, we find that all models are better at identifying non-operators than operators and that the explicit operators are the hardest to solve. For example, the Char 3-Softmax model gets 92.4 F 1 for non-operators, 36.1 F 1 for explicit operators and 79.1 F 1 for implicit operators. Finally, we also train the best model, Char 3-Softmax, using the generated annotations described in Section 5.3 and achieve 76.8 F 1 (Char 3-Softmax extra), i.e., the model performs better without the extra data (p=0). This is probably a result of overfitting due to the small variety of time formats in the training and development data.</p><p>From this analysis on the development set, we select two variants of the Char 3-softmax architecture for evaluation on the test set: Char 3-Softmax and Char 3-Softmax extra. These models were then coupled with the rule-based linking system described in Section 5.2 to produce a complete SCATE-style parsing system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model evaluation</head><p>We evaluate both Char 3-Softmax and Char 3-Softmax extra on the test set for identification and <ref type="bibr">10</ref> We used a paired bootstrap resampling significance test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Char 3-Softmax</head><p>Char 3-Soft. extra</p><formula xml:id="formula_4">P R F 1 P R F 1 Non-Op 79.2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="63.2">70.3 87.4 73.4</head><p>Exp-Op 52.6 36.6 43.2 39.8 38.7 39.3 Imp-Op 53.3 47.1 50.0 65.4 50.0 56.7 Ident 70.0 54.5 61.3 69.4 55.3 61.5 Comp 59.7 46.5 52.3 57.7 46.0 51.2 <ref type="table">Table 5</ref>: Results on the test set for Time entity identification (Ident) and Time entity composition (Comp) steps. For the former we report the performances for each entity set: non-operators (Non-Op), explicit operators (Exp-Op) and implicit operators (Imp-Op).</p><p>Model  composition tasks. <ref type="table">Table 5</ref> shows the results. On the identification task, Char 3-Softmax extra is no worse than using the original dataset with the overall F 1 61.5 vs. 61.3 (p=0.5899), and using extra generated data the model is better at predicting nonoperators and implicit operators with higher precisions (p=0.0096), which is the key to produce correct bounded time intervals.</p><p>To compare our approach with the state-of-the-art, we run HeidelTime on the test documents and make use of the metric described in Section 3. This way, we can compare the intervals produced by both systems no matter the annotation schema. <ref type="table" target="#tab_6">Table 6</ref> shows that our model with additional randomly generated training data outperforms HeidelTime in terms of Precision, with a significant difference of 12.6 percentage points (p=0.011), while HeidelTime obtains a non-significant better performance in terms of Recall (p=0.1826). Overall, our model gets 3.3 more percentage points than HeidelTime in terms of F 1 (p=0.2485). Notice that, although the model trained without extra annotations is better in time entity composition (see <ref type="table">Table 5</ref>), it performs much worse at producing final intervals. This is caused by the fact <ref type="bibr">352</ref> Model P R F 1 HeidelTime 70.7 80.2 75.1 Char 3-Softmax 74.3 64.2 68.9 Char 3-Softmax extra 83.3 74.1 78.4 <ref type="table">Table 7</ref>: Precision (P ), recall (R), and F 1 on bounded intervals on the TimeML/SCATE perfect overlapping test data.</p><p>that this model fails to identify the non-operators that compound dates in unseen formats (see Section 5.3).</p><p>However, evaluating HeidelTime in the SCATE annotations may not be totally fair. HeidelTime was developed following the TimeML schema and, as we show in Section 4, SCATE covers a wider set of time expressions. For this reason, we perform an additional evaluation. First, we compare the annotations in the test set using our interval-based metric, similar to the comparison reported in <ref type="table" target="#tab_2">Table 2</ref>, and select those cases where TimeML and SCATE match perfectly. Then, we remove the rest of the cases from the test set. Consequently, we also remove the predictions given by the systems, both ours and HeidelTime, for those instances. Finally, we run the interval scorer using the new configuration. As can be seen in <ref type="table">Table 7</ref> all the models improve their performances. However, our model still performs better when it is trained with the extra annotations.</p><p>The SCATE interpreter that encodes the time intervals needs the compositional graph of a timeexpression to have all its elements correct. Thus, failing in the identification of any entity of a timeexpression results in totally uninterpretable graphs. For example, in the expression next year, if our model identifies year as a PERIOD instead of an INTER-VAL it cannot be linked to next because it violates the SCATE schema. The model can also fail in the recognition of some time-entities, like summer in the expression last summer. This identification errors are caused mainly by the sparse training data. As graphs containing these errors produce unsolvable logical formulae, the interpreter cannot produce intervals and hence the recall decreases. Within those intervals that are ultimately generated, the most common mistake is to confuse the LAST and NEXT operators, and as a result an incorrectly placed interval even with correctly identified non-operators. For example, if an October with an implicit NEXT operator is instead given a LAST operator, instead of referring to [2013-10-01T00:00, 2013-11-01T00:00), it will refer to [2012-10-01T00:00, 2012-11-01T00:00). Missing implicit operators is also the main source of errors for HeidelTime, which fails with complex compositional graphs. For example, that January day in 2011 is annotated by HeidelTime as two different intervals, corresponding respectively to January and 2011. As a consequence, HeidelTime predicts not one but two incorrect intervals, affecting its precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>As for the time entity identification task, the performance differences between development and test dataset could be attributed to the annotation distributions of the datasets. For example, there are 10 Season-Of-Year annotations in the test set while there are no such annotations in the development dataset; the relative frequencies of the annotations MinuteOf-Hour, Hour-Of-Day, Two-Digit-Year and TimeZone in the test set are much lower, and our models are good at predicting such annotations. Explicit operators are very lexically-dependent, e.g. LAST corresponds to one word from the set {last, latest, previously, recently, past, over, recent, earlier, the past, before}, and the majority of them appear once or twice in the training and development sets.</p><p>Our experiments verify the advantages of character-based-models in predicting SCATE annotations, which are in agreement with our explanations in Section 5.1.2: word-based-models tend to fail to distinguish numbers from digit-based time expressions. It's difficult for word-based-models to catch some patterns of time expressions, such as 24th and 25th, August and Aug., etc., while characterbased models are robust to such variance. We ran an experiment to see whether these benefits were unique to compositional annotations like those of SCATE, or more generally to simply recognizing time expressions. We used the TimeML annotations from AQUAINT and TimeBank (see <ref type="table">Table 1</ref>) to train two multi-class classifiers to identify TIMEX3 annotations. The models were similar to our Char 3-Softmax and Word 3-Softmax models, using the same parameter settings, but with a single softmax output layer to predict the four types of TIMEX3: DATE, TIME, DURATION, and SET. As shown in  on the test set the word-based model significantly outperforms the character-based model in terms of both time expressions (p=0.0428) and the subset of time expressions that contain digits (p=0.0007). These results suggest that the reason character-based models are more successful on the SCATE annotations is that SCATE breaks time expressions down into meaningful sub-components. For example, TimeML would simply call Monday, 1992-05-04 a DATE, and call 15:00:00 GMT Saturday a TIME. SCATE would identify four and five, respectively, different types of semantic entities in these expression; and each SCATE entity would be either all letters or all digits. In TimeML, the model is faced with difficult learning tasks, e.g., that sometimes a weekday name is part of a DATE and sometimes it is part of a TIME, while in SCATE, a weekday name is always a DAY-OF-WEEK.</p><p>On the other hand, running the entity composition step with gold entity identification achieves 72.6 in terms of F1. One of the main causes of errors in this step is the heuristic to complete the INTERVAL-TYPE property. As we explain in Section 5.2, we implement a too coarse set of rules for this case. Another source of errors is the distance of the 10 characters we use to decide if the time entities belong to the same time expression. This condition prevents the creation of some links, for example, the expression "Later" at the beginning of a sentence typically refers to another time interval in a previous sentence, so the distance between them is much longer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have presented the first model for time normalization trained on SCATE-style annotations. The model outperforms the rule-based state-of-the-art, proving that describing time expressions in terms of compositional time entities is suitable for machine learning approaches. This broadens the research in time normalization beyond the more restricted TimeML schema. We have shown that a character-based neural network architecture has advantages for the task over a word-based system, and that a multi-output network performs better than producing a single output. Furthermore, we have defined a new interval-based evaluation metric that allows us to perform a comparison between annotations based on both SCATE and TimeML schema, and found that SCATE provides a wider variety of time expressions. Finally, we have seen that the sparse training set available induces model overfitting and that the largest number of errors are committed in those cases that appear less frequently in the annotations. This is more significant in the case of explicit operators because they are very dependent on the lexicon. Improving performance on these cases is our main goal for future work. According to the results presented in this work, it seems that a solution would be to obtain a wider training set, so a promising research line is to extend our approach to automatically generate new annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Software</head><p>The code for the SCATE-style time normalization models introduced in this paper is available at https://github.com/clulab/timenorm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Annotation of the expression Saturdays since March 6 following the SCATE schema.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of the 1-Sigmoid model. The input is May 25. In SCATE-style annotation, May is a MONTH-OF-YEAR (a non-operator), with an implicit LAST (an operator) over the same span, and 25 is a DAY-OF-MONTH. At the feature layer, M is an uppercase letter (Lu), a and y are lowercase letters (Ll), space is a separator (Zs), and May is a proper noun (NNP).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Architecture of the 2-Softmax model. The input is May. The SCATE annotations and features are the same as in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>3 Our 3-Softmax further splits operators into explicit operators and implicit operators (again, as defined with another operator. For example, a NYT said in an editorial on Saturday, April 25, Saturday is labeled as [DAY-OF-WEEK, LAST, INTERSECTION] where the last two labels are operators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Comparison of TimeML and SCATE annotations.</head><label>2</label><figDesc></figDesc><table>New York Times, Cable News Network, and Voices 
of America. Table 1 shows the statistics of the data. 
Documents from the AQUAINT and TimeBank form 
the training and development dataset. The SCATE 
corpus contains 2604 time entities (individual com-
ponents of a time expression, such as every, month, 
last, Monday, etc.) annotated in the train+dev set 
(i.e. AQUAINT+TimeBank). These entities compose 
a total of 1038 time expressions (every month, last 
Monday, etc.</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Distribution of time entity annotations in 
AQUAINT+TimeBank. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Precision (P ), recall (R), and F 1 of our models 
on the test data producing bounded time intervals. For 
comparison, we include the results obtained by Heidel-
Time. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 ,</head><label>8</label><figDesc></figDesc><table>353 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 8 : Precision (P ), recall (R), and F 1 for character</head><label>8</label><figDesc></figDesc><table>-
</table></figure>

			<note place="foot" n="1"> https://github.com/clulab/timenorm</note>

			<note place="foot" n="2"> In the training data, only 4 of 1217 non-operators overlap with another non-operator, and only 6 of 406 operators overlap</note>

			<note place="foot" n="4"> See http://unicode.org/notes/tn36/</note>

			<note place="foot" n="5"> https://github.com/bethard/ anafora-annotations/blob/master/.schema/ timenorm-schema.xml</note>

			<note place="foot" n="6"> The distance threshold was selected based on the performance on the development dataset.</note>

			<note place="foot" n="7"> https://github.com/ghewgill/text2num</note>

			<note place="foot" n="8"> We use the common formats available in office suites, specifically, LibreOffice.</note>

			<note place="foot" n="9"> We briefly explored using pre-trained word embeddings to try to improve the performance of the Word 1-Sigmoid model, but it yielded a performance that was still worse than the character-based model, so we didn&apos;t explore it further.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Acknowledgements</head><p>We thank the anonymous reviewers as well as the action editor, Mona Diab, for helpful comments on an earlier draft of this paper. The work was funded by the THYME project (R01LM010090) from the National Library Of Medicine, and used computing resources supported by the National Science Foundation under Grant No. 1228509. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Library Of Medicine, National Institutes of Health, or National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A semantically compositional annotation scheme for time normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France, 5</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Bethard and Parker2016. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A synchronous context free grammar for time normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA, 10</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="821" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Named Entity Recognition with Bidirectional LSTM-CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Nichols2016] Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistic</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555v1</idno>
		<idno>abs/1508.01991</idno>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>Huang, Wei Xu, and Kai Yu</editor>
		<meeting><address><addrLine>Sydney, Australia; San Diego California, USA; Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004-03" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="911" to="921" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Context-dependent semantic parsing for time expressions</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland, 6</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1437" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Natalie S. Braggs, Andrew Cagan, Vivian S</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic identification of methotrexateinduced liver toxicity in patients with rheumatoid arthritis from the electronic medical record</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">C</forename><surname>Gainer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana</forename><forename type="middle">K</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation Conference</title>
		<editor>Llorens et al.2012] Hector Llorens, Leon Derczynski, Robert J. Gaizauskas, and Estela Saquete</editor>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3044" to="3051" />
		</imprint>
	</monogr>
	<note>TIMEN: An Open Temporal Expression Normalisation Resource. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">] Xuezhe</forename><surname>Hovy2016</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016)</title>
		<editor>Mazur and Dale2010] Pawet Mazur and Robert Dale</editor>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016)<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="913" to="922" />
		</imprint>
	</monogr>
	<note>Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav Goldberg ; James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Castaño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Saurí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<editor>Kiyong Lee, Harry Bunt, and Laurent Romary</editor>
		<meeting>the 7th International Conference on Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Berlin, Germany; Lancaster</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
	<note>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Valletta, Malta. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with word-class distribution learning</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1737" to="1740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting meaning from temporal nouns and temporal prepositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="298" />
			<date type="published" when="2004-03" />
		</imprint>
	</monogr>
	<note>Language Resources and Evaluation</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Heideltime: Tuning English and developing Spanish resources for TempEval-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Strötgen et al.2013] Jannik Strötgen, Julian Zell, and Michael Gertz</editor>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="15" to="19" />
		</imprint>
	</monogr>
	<note>Proceedings of the Seventh International Workshop on Semantic Evaluation, SemEval &apos;13</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature-rich part-of-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
	<note>NAACL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Uzzaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation<address><addrLine>Georgia, USA, 6</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 15: TempEval Temporal Relation Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Verhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 Task</title>
		<meeting><address><addrLine>Prague, Czech Republic; Uppsala, Sweden, 7</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
<note type="report_type">TempEval-2</note>
	<note>Proceedings of the 5th International Workshop on Semantic Evaluation. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">NewsReader: Using knowledge resources in a cross-lingual reading machine to generate more knowledge from massive streams of news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vossen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
	<note>Special Issue Knowledge-Based Systems</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
