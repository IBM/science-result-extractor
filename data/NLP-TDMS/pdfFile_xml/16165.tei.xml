<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T09:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">R 3 : Reinforced Ranker-Reader for Open-Domain Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information System</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
							<email>xiaoxiao.guo@ibm.com</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Foundations -Learning</orgName>
								<orgName type="institution" key="instit2">IBM Research AI. Yorktown Heights NY</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">JD.COM</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information System</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">R 3 : Reinforced Ranker-Reader for Open-Domain Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In recent years researchers have achieved considerable success applying neural network methods to question answering (QA). These approaches have achieved state of the art results in simplified closed-domain settings 1 such as the SQuAD (Rajpurkar et al. 2016) dataset, which provides a pre-selected passage, from which the answer to a given question may be extracted. More recently, researchers have begun to tackle open-domain QA, in which the model is given a question and access to a large corpus (e.g., wikipedia) instead of a pre-selected passage (Chen et al. 2017a). This setting is more complex as it requires large-scale search for relevant passages by an information retrieval component, combined with a reading comprehension model that &quot;reads&quot; the passages to generate an answer to the question. Performance in this setting lags well behind closed-domain performance. In this paper, we present a novel open-domain QA system called Reinforced Ranker-Reader (R 3), based on two algo-rithmic innovations. First, we propose a new pipeline for open-domain QA with a Ranker component, which learns to rank retrieved passages in terms of likelihood of extracting the ground-truth answer to a given question. Second, we propose a novel method that jointly trains the Ranker along with an answer-extraction Reader model, based on reinforcement learning. We report extensive experimental results showing that our method significantly improves on the state of the art for multiple open-domain QA datasets. 2</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Open-domain question answering (QA) is a key challenge in natural language processing. A successful open-domain QA system must be able to effectively retrieve and comprehend one or more knowledge sources to infer a correct answer. Knowledge sources can be knowledge bases ( <ref type="bibr" target="#b1">Berant et al. 2013;</ref><ref type="bibr" target="#b31">Yu et al. 2017</ref>) or structured or unstructured text passages ( <ref type="bibr" target="#b11">Ferrucci et al. 2010</ref>; Baudiš andŠediv`yandˇandŠediv`andŠediv`y 2015).</p><p>Q: What is the largest island in the Philippines? A: Luzon P1 Mindanao is the second largest and easternmost island in the Philippines. P2 As an island, Luzon is the Philippine's largest at 104,688 square kilometers, and is also the world's 17th largest island. P3 Manila, located on east central Luzon Island, is the national capital and largest city. answering the question, since it fails to capture the semantic distinction between "largest" and "second largest". Passage P3 contains the answer text ("Luzon") but does not semantically entail the correct answer ("Luzon is the largest island in the Philippines"). Training on passages such as P1 and P3 can degrade performance of the RC component. <ref type="bibr">4</ref> In this paper we propose a new approach which explicitly separates the tasks of predicting the likelihood that a passage provides the answer, and reading those passages to extract correct answers. Specifically we propose an end-toend framework consisting of two components: a Ranker and a Reader (i.e. RC model). The Ranker selects the passage most likely to entail the answer and passes it to the Reader, which reads and extracts from that passage. The Reader is trained using SGD/backprop to maximize the likelihood of the span containing the correct answer (if one exists). The Ranker is trained using REINFORCE <ref type="bibr" target="#b28">(Williams 1992</ref>) with a reward determined by how well the Reader extracts answers from the top-ranked passages. This optimizes the Ranker with an objective determined by end-performance on answer prediction, which provides a strong signal to distinguish passages lexically similar to but semantically different from the question.</p><p>We discuss the Ranker-Reader model in detail below but briefly, the Ranker and Reader are implemented as variants of Match-LSTM models ( <ref type="bibr" target="#b22">Wang and Jiang 2016)</ref>. These models were originally designed for solving the text entailment problem. For this task, different non-linear layers are added for selecting the passages or predicting the start and end positions of the answer in the passage.</p><p>We evaluate our model on five different datasets and achieve state-of-the-art results on four of the them. Our results also show the merits of employing a separate REINFORCE-trained ranking component over several challenging fully supervised baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Framework</head><p>Problem Definition We assume that we have available a factoid question q to be answered and a set of passages which may contain the ground-truth answer a g . Those passages 5 are the top N retrieved from a corpus by an IR model supplied with the question, for N a hyper-parameter. During training we are given only the (q, a g ) pairs, together with an IR model with index built on an open-domain corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Framework Overview</head><p>An overview of the RankerReader model is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. It shows two key components: a Ranker, which selects passages from which an answer can be extracted, and a Reader which extracts answers from supplied passages. Both the Ranker and Reader compare the question to each of the passages to generate passage representations based on how well they match the question. The Ranker uses these "matched" representations to select a single passage which is most likely to contain the answer. The selected passage is then processed by the Reader to extract an answer sequence. We train the reader using SGD/backprop and produce a reward to train the Ranker via REINFORCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R 3 : Reinforced Ranker-Reader</head><p>In this section, we first review the Match-LSTM (Wang and Jiang 2016) which provides input for both the Reader and Ranker. We then detail the Reader and Ranker components, and the procedure for joint training, including the objective function used for RL training.</p><p>Passage Representation Using Match-LSTM To effectively rank and read passages they must be matched to the question. This comparison is performed with a Match-LSTM, a state-of-the-art model for text entailment, shown on the right in <ref type="figure" target="#fig_1">Figure 1</ref>. Match-LSTMs use an attention mechanism to compute word similarities between the passage and question sequences. These are first encoded as matrices Q and P, respectively, by a Bidirectional LSTM (BiL-STM) with hidden dimension l. With Q words in question Q and P words in passage P we can write:</p><formula xml:id="formula_0">H p = BiLSTM(P), H q = BiLSTM(Q),<label>(1)</label></formula><p>where H p ∈ R l×P and H q ∈ R l×Q are the hidden states for the passage and the question. In order to improve computational efficiency without degrading performance, we simplify the attention mechanism of the original Match-LSTM by computing the attention weights G as follows:</p><formula xml:id="formula_1">G = SoftMax 񮽙 (W g H q + b g ⊗ e Q ) T H p 񮽙</formula><p>where W g ∈ R l×l and b g ∈ R l are the learnable parameters. The outer product (· ⊗ e Q ) repeats the column vector b g Q times to form an l × l matrix. The i-th column of G ∈ R Q×P represents the normalized attention weights over all the question words for the i-th word in passage. We can use this attention matrix G to form representations of the question for each word in passage:</p><formula xml:id="formula_2">H q = H q G<label>(2)</label></formula><p>Next, we produce the word matching representations M ∈ R 2l×P using H p and H q as follows:</p><formula xml:id="formula_3">M = ReLU ⎛ ⎜ ⎜ ⎝ W m ⎡ ⎢ ⎢ ⎣ H p H q H p 񮽙 H q H p − H q ⎤ ⎥ ⎥ ⎦ ⎞ ⎟ ⎟ ⎠ ,<label>(3)</label></formula><p>where W m ∈ R 2l×4l are learnable parameters;  Finally, we aggregate the word matching representations through another bi-directional LSTM:</p><formula xml:id="formula_4">H m = BiLSTM(M),<label>(4)</label></formula><p>where H m ∈ R l×P is the sequence matching representation between a passage and a question.</p><p>To produce the input for the Ranker and Reader described next, we apply Match-LSTMs to the question and each of the passages. To reduce model complexity, the Ranker and Reader share the same M but have separate parameters for the aggregation stage shown in Eqn.(4), resulting different H m , denoted as H Rank and H Read respectively.</p><p>Ranker Our Ranker selects passages for reading by the Reader. We train the Ranker using reinforcement learning, to output a policy or probability distribution over passages. First, we create a fixed-size vector representation for each passage from the matching representations H Rank i , i ∈ <ref type="bibr">[1, N]</ref>, using a standard max pooling operation. The result u i is a representation of the i-th passage. We then concatenate the individual passage representations and apply a non-linear transformation followed by a normalization to compute the passage probabilities γ. Specifically:</p><formula xml:id="formula_5">u i = MaxPooling(H Rank i ), C = Tanh (W c [u 1 ; u 2 ; ...; u N ] + b c ⊗ e N ) , γ = Softmax(w c C),<label>(5)</label></formula><p>where W c ∈ R l×l and b c , w c ∈ R l are the parameters to optimize; u i ∈ R l represents how the i th passage matches the question; C ∈ R l×N is a non-linear transformation of passage representations; and γ ∈ R N is a vector of the predicted probabilities that each passage entails the answer.</p><p>The action policy is then defined as follows:</p><formula xml:id="formula_6">π(τ |q; θ r ) = γ τ (6)</formula><p>where γ τ is the probability of selecting passage τ , computed in Eqn. <ref type="formula" target="#formula_5">(5)</ref>; θ r represents parameters to learn. In the rest of the paper we denote the policy π(τ |q) = π(τ |q; θ r ) for simplicity. In this way, the action is to sample a passage according to its policy π(τ |q) as the input of Reader.</p><p>Reader Our Reader extracts an answer span from the passage τ selected by the Ranker. As in previous work ( <ref type="bibr" target="#b24">Wang and Jiang 2017b;</ref><ref type="bibr" target="#b29">Xiong, Zhong, and Socher 2017;</ref><ref type="bibr">Seo et al. 2017;</ref><ref type="bibr" target="#b26">Wang et al. 2017</ref>), the Reader is used to predict the start and end positions of the answer phrase in the passage. First we process the output of Match-LSTMs on all the passages to produce the probability of the start position of the answer span β s :</p><formula xml:id="formula_7">F s = Tanh 񮽙 W s [H Read τ ; H Read neg 1 ; ...; H Read neg n ] + b s ⊗ e V 񮽙 , β s = Softmax (w s F s ) ,<label>(7)</label></formula><p>where neg n is the id of a sampled passage not containing ground-truth answer during training; V is the total number of words in these passages; e V is thus a V -dimension vector with ones; <ref type="bibr">[·; ·]</ref> is the column concatenation operation; W s ∈ R l×l and b s , w s ∈ R l are the parameters to optimize; β s ∈ R V is the probability of the start point of the span. We similarly compute the probability of the ending position, β e ∈ R V , using separate parameters W e , b e and w e . The loss function can then be expressed as follows:</p><formula xml:id="formula_8">L(a g |τ, q) = −log(β s a s τ ) − log(β e a e τ ),<label>(8)</label></formula><p>where a g is the ground-truth answer; τ is sampled according to Eqn. <ref type="formula">(6)</ref> For question q, sample K passages from the top N passages retrieved by IR model for training. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Randomly sample a positive passage τ ∼ π(τ |q) <ref type="bibr">7</ref>:</p><p>Extract the answer a rc through RC model 8:</p><p>Get reward r according to R(a g , a rc |τ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Updating Ranker (ranking model) through policy gradient r ∂ ∂Θ log(π(τ |q))</p><p>10:</p><p>Updating Reader (RC model) through supervised gradient ∂ ∂Θ L(a g |τ, q) 11: end for Our training objective is to minimize the following loss function</p><formula xml:id="formula_9">J(Θ) = −E τ ∼π(τ |q) [L(a g |τ, q)] ,<label>(9)</label></formula><p>where L is the loss of the Reader defined in Eqn. <ref type="formula" target="#formula_8">(8)</ref>; π(τ |q) is the action policy defined in Eqn.(6); and Θ are parameters to be learned. During training, action sampling is limited solely to passages containing the ground-truth answer, to guarantee Reader updating (line 10 in Algorithm 1) based on the sampled passages with supervised gradients. The gradient of J(Θ) with respect to Θ is:</p><formula xml:id="formula_10">∇ΘJ(Θ) = −∇Θ 񮽙 τ π(τ |q)L(a g |τ, q) = − 񮽙 τ 񮽙 L(a g |τ, q)∇Θπ(τ |q) + π(τ |q)∇ΘL(a g |τ, q) 񮽙 = −E τ ∼π(τ |q) 񮽙 L(a g |τ, q)∇Θ log(π(τ |q)) + ∇ΘL(a g |τ, q) 񮽙 ≈ −E τ ∼π(τ |q) 񮽙 R(a g , a rc |τ )∇Θ log(π(τ |q)) + ∇ΘL(a g |τ, q) 񮽙<label>(10)</label></formula><p>So in training, we first sample a passage τ according to the policy π(τ |q). Then the Reader updates its parameters given the passage τ using standard Backprop and the ranker updates its parameters via policy gradient using L(a|τ, q) as rewards. However, L(a|τ, q) is not bounded and introduces a large variance in gradients (similar to what was reported in <ref type="bibr" target="#b17">Mnih et al. 2014</ref>). To address this, we replace L(a|τ, q) with a bounded reward R(a g , a rc |τ ), which captures how well the answer extracted by the Reader matches the groundtruth answer. Specifically:</p><formula xml:id="formula_11">R(a g , a rc |τ ) = ⎧ ⎨ ⎩ 2, if a g == a rc f 1(a g , a rc ), else if a g ∩ a rc ! = ø −1, else<label>(11)</label></formula><p>where a g is the ground-truth answer; a rc is the answer extracted by Reader; f 1(·, ·) ∈ [0, 1] computes word-level F1 score between two sequences. F1 is used as reward when a g and a rc share some words but do not exactly match. We give a larger reward of 2 for exact match, and -1 reward for no overlap.</p><p>Prediction During testing, we combine the Ranker and Reader for answer extraction as follows:</p><formula xml:id="formula_12">Pr(a, τ) = Pr(a|τ ) Pr(τ ) = e −L(a|τ,q) π(τ |q),<label>(12)</label></formula><p>where Pr(a, τ) is the probability of extracting the answer a from passage τ . We select the answer with the largest Pr(a, τ) as the final prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>To evaluate our model we have chosen five challenging datasets under the open-domain QA setting and three public baseline models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We experiment with five different datasets whose statistics are shown in <ref type="table" target="#tab_3">Table 2</ref>. Quasar-T is a dataset for SR-QA, with question-answer pairs from various internet sources. Each question is compared to 100 sentence-level candidate passages, retrieved by their IR model from the ClueWeb09 data source, to extract the answer.</p><p>The other four datasets we consider are: SQuAD, the Stanford QA dataset, from which we take only the questionanswer pairs and discard the passages to form an opendomain QA setting (denoted as SQuAD OPEN ); WikiMovies which contains movie-related questions from the OMDb and MovieLens databases and where the questions can be answered using Wikipedia pages; CuratedTREC, based on TREC ( <ref type="bibr" target="#b21">Voorhees and Tice 2000)</ref> and designed for open-domain QA; and WebQuestion which is designed for knowledge-base QA with answers restricted to Freebase entities. For these four datasets under the open-domain QA setting, no candidate passages are provided so we build a similar sentence-level Search Index based on English Wikipedia, following <ref type="bibr" target="#b4">Chen et al. 2017a</ref>'s work. To provide a small yet sufficient search space for our model, we employ a traditional IR method to retrieve relevant passages from the whole of Wikipedia. We use the 2016-12-21 dump of English Wikipedia as our sole knowledge source, and build an inverted index with Lucene <ref type="bibr">8</ref> . We then take each input question as a query to search for top-200 articles, rank them with  </p><note type="other">#q(train) #q(test) #p(train) #p(test) Quasar-</note><formula xml:id="formula_13">N 񮽙 n=1 y n (log(y n ) − log(γ n )) ,<label>(13)</label></formula><p>which is the KL divergence between γ computed through Eqn.(5) and a probability vector y, where y i = 1/N p when the passage i contains the ground-truth answer, and y i = 0/N p otherwise. N p is the total number of passages which contain the ground-truth answer in the top-N passage list. <ref type="bibr">9</ref> We only compare to the results from the public papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>In order to increase the likelihood that question-related context will be contained in the retrieved passages for the training dataset, if the answer is unique, we combine the question with the answer to form the query for information retrieval.</p><p>For the testing dataset, we use only the question as a query and collect the top 50 passages for answer extraction. During training, our R 3 model is first initialized by pretraining the model using the Simple Ranker-Reader (R 2 ), to encourage convergence. As discussed earlier, the preprocessing and matching layers, Eqn. <ref type="figure" target="#fig_1">(1-3)</ref>, are shared by both Ranker and Reader. The number of LSTM layers in Eqn. <ref type="formula" target="#formula_4">(4)</ref> is set to 3 for the Reader and 1 for the Ranker.</p><p>Our model is optimized using Adamax ( <ref type="bibr" target="#b14">Kingma and Ba 2015)</ref>. We use fixed GloVe <ref type="bibr">(Pennington, Socher, and Man- ning 2014</ref>) word embeddings. We set l to 300, batch size to 30, learning rate to 0.002 and tune the dropout probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>In this section, we will show the performance of different models on five QA datasets and offer further analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Results</head><p>Our results are shown in <ref type="table" target="#tab_5">Table 3</ref>. We use F1 score and Exact Match (EM) evaluation metrics <ref type="bibr">10</ref> . We first observe that on Quasar-T, the Single Reader can exceed state-of-the-art performance. Moreover, unlike DrQA, our models are all trained using distant supervision and, without pre-training on the original SQuAD dataset <ref type="bibr">11</ref> , our Single Reader model still achieves better performance on the WikiMovie and CuratedTREC datasets.</p><p>Next we observe that the Reinforced Ranker-Reader (R 3 ) achieves the best performance on the Quasar-T, WikiMovies, and CuratedTREC datests and achieves significantly better performance than our internal baseline model Simple Ranker-Reader (SR 2 ) on all datasets except CuratedTREC. These results demonstrate the effectiveness of using RL to jointly train the Ranker and Reader both as compared to competing approaches and the non-RL RankerReader baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Further Analysis</head><p>In this subsection, we first present an analysis of the improvement of both Ranker and Reader trained with our method, and then discuss ideas for further improvement.</p><p>Quantitative Analysis First, we examine whether our RL approach could help the Ranker overcome the absence of any ground-truth ranking score. To control everything but the change in Ranker, we conduct two experiments combining the same Single Reader with two different Rankers trained from SR 2 and R 3 , respectively. <ref type="table" target="#tab_6">Table 4</ref> shows the results on the Quasar-T test dataset. Note that the Single <ref type="bibr">Seo et al. 2017)</ref> 28.5 25.9 --------DrQA ( <ref type="bibr" target="#b4">Chen et al. 2017a</ref>    <ref type="table">Table 5</ref>: Potential improvement on QA performance by improving the ranker. The performance is based on the Quasar-T test dataset. The TOP-3/5 performance is used to evaluate the further potential improvement by improving rankers (see the "Potential Improvement" section).</p><formula xml:id="formula_14">Quasar-T SQuADOPEN WikiMovies CuratedTREC WebQuestions F1 EM F1 EM F1 EM F1 EM F1 EM GA (Dhingra et al. 2017) 26.4 26.4 - - - - - - - - BiDAF (</formula><p>Reader combined with the Ranker trained from R 3 model achieves an EM 1.3 higher performance than combined with the Ranker from SR 2 which treats all passages containing ground-truth answer as positive cases. That means our proposed Ranker is better than the Ranker normally trained in the distant supervision setting. We also find that the performance of R 3 can still achieve an EM 1.0 higher than the Single Reader combined with the Ranker from R 3 through <ref type="table" target="#tab_6">Table 4</ref>. In this setting, the Ranker is the same, while the Reader is trained differently. We infer from this that our proposed methods R 3 can not only improve the Ranker but also the Reader.</p><p>Potential Improvement We offer a statistical analysis to approximate the upper bound achievable by only improving the ranking models. This is evaluated by computing the QA performance with the best passage among the top-k ranked passages. Specifically, for each question, we extract one answer from each of the top-50 passages retrieved from the IR system, and take the top-k answers with the highest scores according to Eqn.(12) from these. Based on the k answer candidates, we compute the TOP-k F1/EM by evaluating on the answer with highest F1/EM score for each question. This is equivalent to having an oracle ranker that assigns a +∞ score to the passage (from the passages providing top-k candidates) yielding the best answer candidate. <ref type="table">Table 5</ref> shows a clear gap between TOP-3/5 and TOP-1 QA performances (over 12-20%). According to our evaluation approach of TOP-k F1/EM and since the same SR model is used, this gap is solely due to the oracle ranker. Although our model is far from the oracle performance, it still provides a useful upper bound for improvement.</p><p>Ranker Performance Analysis Next we show the intermediate performance of our method on the ranking step. Since we do not have the ground-truth for the ranking task, we evaluate on pseudo labels: a passage is considered positive if it contains the ground-truth answer. Then a ranker's top-k output is considered accurate if any of the k passages contain the answer (i.e. top-k recall). Note that this way of evaluation on top-1 is consistent with the training objective of the ranker in SR 2 .</p><p>From the results in <ref type="table">Table 7</ref>, the Ranker from R 3 performs significantly better than the one from SR 2 on top-1 and top-3 performance, despite the fact that it is not directly trained to optimize this pseudo accuracy. Given the evaluation bias that favors the SR 2 , this indicates that our R 3 model could make Ranker training easier, compared to training on the objective in Eqn.13 with pseudo labels.</p><p>Starting from top-5, the Ranker from R 3 gives slightly lower recall. This is because the two Rankers have a similar ability to rank the potentially useful passages in the top-5, but the evaluation bias benefits the SR 2 Ranker. Overall, our R 3 could successfully rank the potentially more useful passages to the highest positions (top 1-3), improving the Q Apart from man what is New Zealand 's only native mammals A bats</p><p>Reinforced Ranker-Reader (R 3 ) Simple Ranker-Reader (SR 2 ) P1 New Zealand has no native land mammals apart from some rare bats .</p><p>New Zealand 's native species were sitting ducks ! P2 New Zealand 's native species were sitting ducks ! 1080 is a commonly used pesticide since it is very effective on mammals and New Zealand has no native land mammals apart from two species of bat . P3 -LSB-edit -RSB-Fauna Bats were the only mammals of New Zealand until the arrival of humans .</p><p>Previously it had been thought that bats were the only terrestrial mammals native to New Zealand . 40.3 51.3 54.5 <ref type="table">Table 7</ref>: The performance of Rankers (recall of the top-k ranked passages) on the Quasar-T test dataset. This evaluation is simply based on whether the ground-truth appears in the TOP-N passages. IR directly uses the ranking score from raw dataset.</p><p>overall QA performance. An example in <ref type="table" target="#tab_7">Table 6</ref> illustrates the importance of ranking. The passages on the left are from the R 3 Ranker and the ones on the right from the SR 2 Ranker. If SR 2 ranked P2 or P3 higher, it could also have extracted the right answer. In general, if passages that can entail the answer are ranked more accurately, both models could be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Open domain question answering dates back to as early as <ref type="bibr" target="#b12">(Green Jr et al. 1961</ref>) and was popularized with TREC-8 (Voorhees 1999). The task is to answer a question by exploiting resources such as documents (Voorhees 1999), webpages <ref type="bibr" target="#b15">(Kwok, Etzioni, and Weld 2001;</ref><ref type="bibr" target="#b3">Chen and Van Durme 2017)</ref> or structured knowledge bases <ref type="bibr" target="#b1">(Berant et al. 2013;</ref><ref type="bibr" target="#b2">Bordes et al. 2015;</ref><ref type="bibr" target="#b31">Yu et al. 2017</ref>). An early consensus since TREC-8 has produced an approach with three major components: question analysis, document retrieval and ranking, and answer extraction. Although question analysis is relatively mature, answer extraction and document ranking still represent significant challenges.</p><p>Very recently, IR plus machine reading comprehension (SR-QA) showed promise for open-domain QA, especially after datasets created specifically for the multiple-passage RC setting ( <ref type="bibr" target="#b18">Nguyen et al. 2016;</ref><ref type="bibr" target="#b4">Chen et al. 2017a;</ref><ref type="bibr" target="#b13">Joshi et al. 2017;</ref><ref type="bibr" target="#b10">Dunn et al. 2017;</ref><ref type="bibr" target="#b9">Dhingra, Mazaitis, and Cohen 2017)</ref>. These datasets deal with the end-to-end open-domain QA setting, where only question-answer pairs provide supervision. Similarly to previous work on open-domain QA, existing deep learning based solutions to the above datasets also rely on a document retrieval module to retrieve a list of passages for RC models to extract answers. Therefore, these approaches suffer from the limitation that the passage ranking scores are determined by n-gram matching (with tf-idf weighting), which is not ideal for QA.</p><p>Our ranker module in R 3 could help to alleviate the above problem, and RL is a natural fit to jointly train the ranker and reader since the passages do not have ground-truth labels. Our work is related to the idea of soft or hard attentions (usually with reinforcement learning) for hierarchical or coarse-to-fine decision sequences making in NLP, where the attentions themselves are latent variables. For example, Lei, Barzilay, and Jaakkola 2016 propose to first extract informative text fragments then feed them to text classification and question retrieval models. <ref type="bibr" target="#b6">Cheng and</ref><ref type="bibr" target="#b6">Lapata 2016 and</ref><ref type="bibr" target="#b7">Choi et al. 2017</ref> proposed coarse-to-fine frameworks with an additional sentence selection step before the original wordlevel prediction for text summarization and reading comprehension, respectively. To the best of our knowledge, we are the first apply this kind of framework to the open-domain question answering.</p><p>From the method-perspective, our work is most close to <ref type="bibr" target="#b7">Choi et al. 2017</ref>'s work in terms of the usage of REIN-FORCE. Our main aim is to deal with the lack of annotation in the passage selection step, which is a necessary intermediate step in open-domain QA. In comparison,  has as its main aim to speed up the RC model in the single passage setting. From the motivation-perspective, we are similar to Narasimhan, Yala, and Barzilay 2016's work. Both work aim to find passages easy and suitable for the QA or IE models to extract answers, in order to boost accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We have proposed and evaluated R 3 , a new open-domain QA framework which combines IR with a deep learning based Ranker and Reader. First the IR model retrieves the top-N passages conditioned on the question. Then the Ranker and Reader are trained jointly using reinforcement learning to directly optimize the expectation of extracting the groundtruth answer from the retrieved passages. Our framework achieves the best performance on several QA datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>񮽙 · · 񮽙 is the column concatenation of matrices; Element-wise operations (· 񮽙 ·) and (· − ·) are also used to represent word-level matching (Wang and Jiang 2017a; Chen et al. 2017b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of training our model, comprising a Ranker and a Reader based on Match-LSTM as shown on the right side. The Ranker selects a passage τ and the Reader predicts the start and end positions of the answer in τ . The reward for the Ranker depends on similarity of the extracted answer with the ground-truth answer a g . To accelerate Reader convergence, we also sample several negative passages without ground-truth answer.</figDesc><graphic url="image-1.png" coords="3,53.43,53.44,370.63,210.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>An open-domain QA training example. Q: question, 
A: answer, P: passages retrieved by an IR model and ordered 
by IR score. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>, and during training, we keep sampling until pas- sage τ contains a g ; β s a s τ and β e a e τ represent the probability of the start and end positions of a g in passage τ . Training We adopt joint training of Ranker and Reader as shown in Algorithm 1. Since the Ranker makes a hard selec</head><label></label><figDesc></figDesc><table>-
tion of the passage, it is trained using the REINFORCE algo-
rithm. The Reader is trained using standard SGD/backprop. 

Algorithm 1 Reinforced Ranker-Reader (R 3 ) 
1: Input: a g , q, passages from IR 
2: Output: Θ 
3: Initialize: Θ ← pre-trained Θ with a baseline method 6 
4: for each q in dataset do 

5: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics of the datasets. #q represents the number 
of questions. For the training dataset, we ignore the ques-
tions without any answer in all the retrieved passages. In 
the special case that there's only one answer for the ques-
tion, during training, we combine the question with the an-
swer as the query to improve IR recall. Otherwise we use 
only the question. #p represents the number of passages and 
14.8 / 100 means there are 14.8 passages containing the an-
swer on average out of the 100 passages. We use top50 pas-
sages retrieved by the IR model for testing. 

BM25, and split them into sentences. The sentences are then 
ranked by TF-IDF and the top-200 sentences for each ques-
tion retained. 

Baselines 

We consider three public baseline models 9 : GA (Dhingra 
et al. 2017; Dhingra, Mazaitis, and Cohen 2017), a gated-
attention reader for text comprehension; BiDAF (Seo et al. 
2017), a reader with bidirectional attention flow for machine 
comprehension; and DrQA (Chen et al. 2017a), a document 
reader for question answering. We also compare our model 
R 3 with two internal baselines: 

Single Reader (SR) This model is trained in the same 
way as Chen et al. 2017a and Dhingra, Mazaitis, and 
Cohen 2017. We find all the answer spans that exactly 
match the ground-truth answers from the retrieved passages 
and train the Reader using the objective of Eqn.(8). Here τ 
is randomly sampled from [1, N] instead of using Eqn.(6). 

Simple Ranker-Reader (SR 2 ) This Ranker-Reader 
model is trained by combining the two different objective 
functions for the Single Reader and the Ranker models 
together. In order to train the Ranker, we treat all the 
passages that contain the ground-truth answer as positive 
cases and use the following for the Ranker loss: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>34.2 .3 37.5 .2 29.1 .2 39.9 .1 38.8 .1 34.3 .6 28.4 .6 24.6 .3 17.1 .3</head><label></label><figDesc></figDesc><table>) 
-
-
-
28.4 
-
34.3 
-
25.7 
-
19.5 

Single Reader (SR) 
38.5 .2 
31.5 .2 
35.4 .2 
26.9 .2 
38.8 .1 
37.7 .1 
33.6 .6 
27.4 .4 
22.0 .2 
15.2 .3 
Simple Ranker-Reader (SR 2 ) 
38.8 .2 
31.9 .2 
35.8 .2 
27.2 .2 
39.3 .1 
38.1 .1 
33.4 .6 
27.7 .5 
22.5 .3 
15.6 .4 
Reinforced Ranker-Reader (R 3 ) 
40.9 .3 DrQA-MTL (Chen et al. 2017a) 
-
-
-
29.8 
-
36.5 
-
25.4 
-
20.7 
YodaQA (Baudiš andŠediv`yandˇandŠediv`andŠediv`y 2015) 
-
-
-
-
-
-
-
31.3 
-
39.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Open-domain question answering results. The results show the average of 5 runs, with standard error in the superscript. 
The CuratedTREC and WebQuestions models are initialized by training on SQuAD OPEN first. On the bottom, YodaQA and 
DrQA-MTL use additional resources (usage of KB for the former, and multiple training datasets for the latter), so are not a true 
apple-to-apple comparison to the other methods. EM: Exact Match. 

F1 
EM 

Single Reader (SR) 
38.3 31.4 
SR + Ranker (from SR 2 ) 38.9 31.8 
SR + Ranker (from R 3 ) 
40.0 33.1 

SR 2 
38.7 31.9 
R 3 
40.8 34.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Effects of rankers from SR 2 and R 3 (on Quasar-
T test dataset). Here we use the same single reader model 
(SR) as the reader, combined with two different rankers. The 
performance of the two runs of SR 2 and R 3 (that provide the 
rankers) is listed at bottom. 

TOP-k 
F1 
EM 

Single Reader (SR) 
1 
38.3 31.4 
Single Reader (SR) 
3 
51.7 43.7 
Single Reader (SR) 
5 
58.7 49.2 
SR + Ranker (from R 3 ) 
1 
40.0 33.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>An example of the answers extracted by the R 3 and SR 2 methods, given the question. The words in bold are the 
extracted answers. The passages are ranked by the highest score (Ranker+Reader) of the answer span in each passage. 

TOP-1 TOP-3 TOP-5 

IR 
19.7 
36.3 
44.3 
Ranker from SR 2 
28.8 
46.4 
54.9 
Ranker from R 3 
</table></figure>

			<note place="foot" n="3"> This forms a closed-domain QA by our adopted definition where the domain consists of the given passage only. The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)</note>

			<note place="foot" n="4"> Passage ranking models for non-factoid QA (Wang, Smith, and Mitamura 2007; Yang, Yih, and Meek 2015) are able to learn to rank these passages; but these models are trained using human annotated answer labels, which are not available here. 5 In this paper we use sentence-level index thus each passage is an individual sentence. See the experimental setting.</note>

			<note place="foot" n="6"> Baseline method SR 2 , described in Experimental Settings. 7 For computational efficency, we sample 10 passages during training, and make sure there are at least 2 negative passages and as many positive passages as possible.</note>

			<note place="foot" n="8"> https://lucene.apache.org/</note>

			<note place="foot" n="10"> Evaluation tooling is from SQuAD (Rajpurkar et al. 2016). 11 The performance of our Single Reader model on the original SQuAD dev set is F1 77.0, EM 67.6 which is close to the BiDAF model, F1 77.3, EM 67.7 and DrQA model, F1 78.8, EM 69.5.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling of the question answering task in the yodaqa system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baudiš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP</title>
		<meeting>of Conf. on EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discriminative information retrieval for question answering sentence selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EACL</title>
		<meeting>of Conf. on EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Coarse-to-fine question answering for long documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gated-attention readers for text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">QUASAR: Datasets for question answering by search and reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03904</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Guney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05179</idno>
		<title level="m">SearchQA: A new q&amp;a dataset augmented with context from a search engine</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Building watson: An overview of the deepqa project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Baseball: an automatic question-answerer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Green</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chomsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laughery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">western joint IRE-AIEE-ACM computer Conf</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1961-05-09" />
			<biblScope unit="page" from="219" to="224" />
		</imprint>
	</monogr>
	<note>In Papers presented at the</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scaling question answering to the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="242" to="262" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rationalizing neural predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP</title>
		<meeting>of Conf. on EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving information extraction by acquiring external evidence with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
	</analytic>
	<monogr>
		<title level="m">MS MARCO: A human generated machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Proc. of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP</title>
		<meeting>of Conf. on EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP. Seo, M</title>
		<meeting>of Conf. on EMNLP. Seo, M</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Proc. of ICLR</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 23rd annual Intl. ACM SIGIR Conf. on Research and development in information retrieval</title>
		<meeting>of 23rd annual Intl. ACM SIGIR Conf. on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
	<note>Trec</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning natural language inference with LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on NAACL</title>
		<meeting>of Conf. on NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A compare-aggregate model for matching text sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Machine comprehension using match-LSTM and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Multiperspective context matching for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1612.04211</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasi-synchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP</title>
		<meeting>of Conf. on EMNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">;</forename><surname>-T</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on EMNLP</title>
		<meeting>of Conf. on EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improved neural relation detection for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
