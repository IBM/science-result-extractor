<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T09:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Hybrid Approach to Vietnamese Word Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Phong</forename><surname>Nguyen</surname></persName>
							<email>phongnt_570@vnu.edu.vn</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Technology</orgName>
								<orgName type="institution">VNU University of Engineering and Technology No</orgName>
								<address>
									<addrLine>144 Xuan Thuy Street Dich Vong Hau Ward</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cau Giay District Hanoi</orgName>
								<address>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Hybrid Approach to Vietnamese Word Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Word segmentation is the very first task for Viet-namese language processing. Word-segmented text is the input of almost other NLP tasks. This task faces some challenges due to specific characteristics of the language. As in many other Asian languages such as Japanese, Korean and Chinese, white spaces in Vietnamese are not always used as word separators and a word may contain one or more syllables. In this paper, we propose an efficient hybrid approach to detect word boundary for Vietnamese texts using logistic regression as a binary classifier combining with longest matching algorithm. First, longest matching algorithm is used to catch words that contain more than two syllables in input sentence. Next, the system utilizes the classifier to determine the boundary of 2-syllable words and proper names. Then, the predictions having low confidence conducted by the classifier are verified by a dictionary to get the final result. Our system can achieve an F-measure of 98.82% which is the most accurate result for Vietnamese word segmentation to the best of our knowledge. Moreover, the system also has a high speed. It can run word segmentation for nearly 34k tokens per second.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In linguistics, word is the smallest meaningful unit of speech that can stand by itself. Vietnamese, an Austroasiatic language, uses a Latin alphabet with additional diacritics and certain letters. However, unlike many occidental languages using Latin alphabets, Vietnamese has similar characteristics to other East Asian languages such as Japanese, Korean, Chinese and Thai in which white spaces are not always word separators and a word may consist of more than one syllable with many ambiguous cases. This leads to some challenges in Vietnamese word segmentation.</p><p>Studies on Vietnamese word segmentation used either dictionary-based algorithms, statistical models or hybrid approaches. Recent studies using hybrid approaches such as <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> can provide state-of-the-art results at approximately 97%.</p><p>In this study, we propose an efficient hybrid approach to solve this task. In our approach, word segmentation is represented as a binary classification problem in which we have to determine the label of each white space in input text. These two labels are SPACE (separator of two syllables which belong to two different words) and UNDERSCORE (separator of two syllables inside a word). <ref type="bibr">Our</ref>  mainly based on three steps. First, we use a forward longest matching algorithm to determine the boundary of all words having at least three syllables. Next, the classifier using logistic regression helps to detect the boundary of 2-syllable words and proper names. Finally, we continue to use the dictionary to recheck the predictions having low confidence produced by the machine learning process and return final labels for white spaces. For experiments, we evaluate our approach using 10-fold cross-validation on Vietnamese Treebank corpora <ref type="bibr" target="#b3">[4]</ref> of 75k manually word-segmented sentences. Our system can yield an F-measure of 98.82% which is the best result for Vietnamese word segmentation known to us. Furthermore, the system can also perform at a high speed of nearly 34k tokens per second when running on a personal computer.</p><p>The rest of this paper is organized as follows. In Section II, we talk about the difficulties in Vietnamese word segmentation. In Section III, the methods used in other studies to resolve word segmentation task are discussed. Section IV provides details of our approach. We report and discuss about the experimental results of our system in Section V. Finally, we make some conclusions on this work in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DIFFICULTIES IN VIETNAMESE WORD SEGMENTATION</head><p>Vietnamese is an inflexionless language in which every word never changes its form. Vietnamese words are made of one or more syllables. A word which contains only one syllable is called single word. On the other hand, a word which is composed of more than one syllable is called compound word. Frequency of each kind of word is different from others. We tried to make some statistics on the dictionary provided by VLSP project l and the frequency analysis told us some useful knowledge. Almost of the words (71%) in this dictionary are 2-syllable words. Single words account for 17.67% of total words. Therefore, the percentage of over-2-syllable words is just under 12%. Due to this low frequency, it leads us to a simple idea that we can just use the dictionary to cover those words and then find an efficient way to deal with the other words in the input text. There are two kinds of the remaining words that we have to care about, which are 2-syllable words and proper names (in Vietnamese, names of people and locations are considered as lexical units).</p><p>One simple method to deal with proper names is to compose all consecutive upper-case syllables into a word. This method is obviously not good in many cases such as when two proper names appear consecutively.</p><p>For 2-syllable words, the easiest way is to scan through the input sentence and connect all of two consecutive syllables that can compose a word in the dictionary. There are many ambiguous cases where this method produce wrong results. One of the most frequent cases is called overlap ambiguity in which a sentence has three consecutive syllables Si S i+l Si+2 where both SiSi+l and Si+lSi+2 are words in the dictionary but in the current context, only one of them is the right word. In another common situation, a word composed of two consecutive syllables Si Si+ 1 is in the dictionary, but in the current context, these two syllables are actually two single words. Other significant case that this method cannot handle is out-of-vocabulary problem in which two consecutive syllables Si Si+ 1 actually compose a right word in its context but it has not appeared in the dictionary.</p><p>Taken together, it is necessary to have more effective techniques to deal with those problems. In the next section, we talk about studied approaches to word segmentation Vietnamese and other languages' texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RELATED WORKS</head><p>There are many effective approaches that have been studied to resolve word segmentation task <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[6]</ref>. The first and traditional approach is based on dictionary. There are two common techniques of this approach, namely maximum matching (MM) and longest matching (LM). While MM algorithm aims to find the segmentation candidates by segmenting input sentence into a sequence with the smallest number of words, LM algorithm tends to scan through the sentence and at each syllable, it finds the longest word composed of this syllable and the next consecutive ones. Systems using this kind of approach for Chinese can gain very promising results <ref type="bibr" target="#b7">[7]</ref>, <ref type="bibr" target="#b9">[8]</ref>. However, for Vietnamese, this simple approach seems to be unable to deal with out-of-vocabulary problem and overlap ambiguity.</p><p>The second one is statistical approach. As in many other core NLP tasks, this approach has proved to be good for word segmentation too. For instance, the methods using Conditional Random Fields (CRFs) and Support Vector Machines (SVMs) in <ref type="bibr" target="#b10">[9]</ref> can reach results of over 94% while evaluating on a small corpus of 7800 Vietnamese sentences. Other studies using CRFs <ref type="bibr" target="#b11">[10]</ref>, SVMs <ref type="bibr" target="#b12">[11]</ref>, Hidden Markov Model (HMM) <ref type="bibr" target="#b13">[12]</ref>, <ref type="bibr" target="#b14">[13]</ref>, n-gram model <ref type="bibr" target="#b15">[14]</ref>, Maximum Entropy (MaxEnt) <ref type="bibr" target="#b16">[15]</ref>, <ref type="bibr" target="#b17">[16]</ref> and probabilistic ensemble learning <ref type="bibr" target="#b18">[17]</ref> also produces high accuracy for Vietnamese and other East Asian languages. Statistical approaches help to gain good result for Thai <ref type="bibr" target="#b19">[18]</ref>, too.</p><p>Although statistical algorithms can provide a good way to deal with ambiguous problems, both of those approaches still have their own limitations. Thus, some studies combined these two approaches into their systems. Some hybrid approaches for Vietnamese word segmentation were presented to use Weighted Finite State Transducer (WFST) with Neural Network <ref type="bibr" target="#b2">[3]</ref>, or combine MM and n-gram language model <ref type="bibr" target="#b0">[1]</ref>, or use MM combining with stochastic models using partof-speech information <ref type="bibr" target="#b1">[2]</ref>. These approaches are able to reach state-of-the-art results at approximately 97%. For Chinese, the study in <ref type="bibr" target="#b20">[19]</ref> proposes a lattice-based framework for joint Chinese word segmentation, POS tagging and parsing which helps to significantly improve the accuracy of the three subtasks. Joint model of word segmentation and POS tagging was also used for Japanese <ref type="bibr" target="#b21">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OUR APPROACH</head><p>In this section, we first talk about how we represent word segmentation task. Next, we describe three main components of our segmentation system before proposing its architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem representation</head><p>The two main ways of problem representation for Vietnamese word segmentation are syllable-based and whitespace-based.</p><p>The first one can be described as a sequential tagging task. For example, in the approach presented in <ref type="bibr" target="#b10">[9]</ref>, there are three labels for syllables, which are B_W (Begin of a Word), 1_W (Inside of a Word) and 0 (Outside of a word). This approach is implemented in JVnSegmenter <ref type="bibr" target="#b22">[21]</ref>, a toolkit for Vietnamese word segmentation.</p><p>The second way is to cast Vietnamese word segmentation as a binary classification problem for white spaces. It should be repeated that in Vietnamese, there are two kinds of white space. The first one is separator of two syllables which belong to two different words (SPACE) and the second one is separator of two syllables inside a word (UNDERSCORE). PELSegmenter <ref type="bibr" target="#b18">[17]</ref> and DongDu 2 are toolkits that use this problem representation.</p><p>We use the second way of problem representation for our system because of its simplicity. Moreover, in this way, it is possible to modify the label of a white space but does not affect the labels of other ones beside it. In the next section, we describe the simplest component of our system, longest matching algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Longest matching</head><p>Due to the low frequency of over-2-syllable words and in our observation, ambiguity is inappreciable for them, we just use such a dictionary to deal with those words. The dictionary-based technique in our system is longest matching. The dictionary is the one used in Section II. The work after longest matching is to handle the 2-syllable words and proper names efficiently. Our binary classifier using logistic regression is responsible for this task.</p><p>2https://github.comlrockkhuya/DongDu</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c. Logistic regression as binary classification</head><p>Logistic regression is used to construct a binary classifier for white spaces in our system. From training data, we have a training set D == {(X, Y)} where X denotes feature vector and Y denotes the corresponding label of white space. To be convenient, we denote the two values for Y as 1 and 0 corresponding to UNDERSCORE and SPACE labels respectively. Based on this training set, logistic regression assumes a parametric model and learns the conditional distribution P(YIX). The assumed parametric model is presented in equation 1 and equation 2, in which Wi denotes weight (or parameter).</p><formula xml:id="formula_0">P(Y == 0IX) == 1 -P(Y == llX) (2)</formula><p>The rule of our binary classifier is that we assign UNDER-SCORE label for a white space given its feature vector X if</p><formula xml:id="formula_1">P(Y == llX) &gt; P(Y == 0IX) (or P(Y == llX) &gt; 0.5) and</formula><p>otherwise, we assign SPACE label for it if P(Y == llX) &lt; 0.5.</p><p>This statistical method seems to be able to handle proper names and many ambiguous problems well if we have a good feature set and large training data. However, it still has serious limitations as we map a continuous domain of probability P to a discrete domain of binary variable. But that is also the reason why we choose logistic regression instead of other methods. Obviously, no machine learning method can perform perfectly in all cases and it is necessary to have verification for its outcome. Logistic regression provides a simple way to detect those low-confident predictions. It is clear that predictions with probabilities P in a narrow boundary around 0.5 have low confidence of precision. Additionally, it is also possible that in the overlap ambiguity case, this classifier may connect all three syllables to compose a word. We will propose our simple techniques to resolve these problems in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Post-processing for binary classifier</head><p>We use the dictionary to handle the low-confident predictions and the results in overlap ambiguity cases produced by the binary classifier. First, we define that a prediction for label Y of a white space given its feature vector X is a lowconfident prediction if the following condition holds:</p><formula xml:id="formula_2">IP(Y == llX) -0.51 &lt; r,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>r is a threshold</head><p>Assume that we have a sequence of syllables and labeled white spaces after the binary classification using logistic regression in the form of:</p><formula xml:id="formula_3">... Si-l [ ]Si [*]Si+l [ ]Si+2 ...</formula><p>where Sj denotes syllable; [ ] denotes SPACE label; <ref type="bibr">[_]</ref> denotes UNDERSCORE label and <ref type="bibr">[*]</ref> is the label that has low-confident precision. Our solution is to verify whether the word SiSi+l is in the dictionary or not. The result of this operation is the final label for <ref type="bibr">[*]</ref>. In another case, the conducted sequence looks like that:</p><p>In this case, Si-lSiSi+l is not a word in the dictionary. That means it is much likely a wrong word because of the low frequency of 3-syllable words. We divided this case into four possibilities:</p><p>• word Si-lSi is in dictionary but word SiSi+l is not • word SiSi+l is in dictionary but word Si-lSi is not • both of them are not in dictionary • both of them are in dictionary For the first and second cases, we only keep up the word that appears in the dictionary. For the third case, we change both labels of two white spaces into SPACE. The last case is corresponding to overlap ambiguity. In this case, we keep up UNDERSCORE label of white space that has higher probability conducted by the classifier and change the other one to SPACE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Proposed segmentation system</head><p>Combine all the above components with the pre-processing step for raw input data, we have the architecture of our system as presented in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>In the pre-processing step, we first standardize the raw text, then use regular expressions to recognize regular patterns such as numbers, times and dates, then separate punctuation marks, parentheses and quotation marks at the end of words, and then utilize some simple heuristic rules to split the text into sentences. Next, each sentence is passed into the LM component to detect boundary for words having at least three syllables. Continuously, the remaining white spaces will be labeled by the classifier using LR. This classifier was trained on training data before. The post-processing then handles the low-confident predictions conducted by the classifier to return the final segmented text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we present the feature templates used for logistic regression and the performances of different systems compared to our system. We also talk about the affection of threshold r to accuracies of our segmentation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Features</head><p>Performance of any statistical technique is based on the quality of feature set. For the classifier using logistic regression of our system, to generate feature vector of each white space, we capture a window of size 2 for it as depicted in <ref type="figure" target="#fig_1">Figure 2</ref>, where s denotes syllable; y denotes white space and the subscript is the index of corresponding syllable or white space. There are five types of syllable we defined in our system, namely LOWER, UPPER, ALLUPPER, NUMBER and OTHER corresponding to the cases that the syllable has all lowercase letters, the syllable has upper-case initial letter, the syllable has all upper-case letters, the syllable is a number or the other cases, respectively. For n-gram features, we use both the lowercase form of syllables and their types. We do not use the original form of syllables from input text to extract n-gram features because we found that this way of feature extraction may produce profitless features and they are not good for logistic regression. Moreover, we only add features of syllable's types to feature vector if the type is different from LOWER. Taking all features of LOWER type to feature vectors can make the regression model confused and draw its performance because almost syllables are of LOWER type. These techniques can reduce a large number of useless features. The sixth feature template in <ref type="table" target="#tab_1">Table I</ref> is used for full-reduplicative words. The seventh one catches information of Vietnamese people's name and the last one is used for detecting two consecutive proper names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>We analyze affection of each component to our whole system. In our experiments, we use Vietnamese Treebank corpora of 75k manually word-segmented sentences which is one of the largest annotated corpora for Vietnamese. The corpus is randomly splitted into ten equal partitions for 10-fold cross-validation. F-measure is used, in which precision ratio (P) is computed as number of right segmented words over total number of words conducted by the segmentation system; recall ratio (R) is computed as number of right segmented words over total number of words in the golden test set. The average accuracies of systems over ten folds are presented in <ref type="table" target="#tab_1">Table II.</ref> We utilize LIBLINEAR L2-regularized logistic regression <ref type="bibr" target="#b23">[22]</ref> to implement the classifier for our experiments. Our baseline system is LM which uses only longest matching algorithm and the rule to compose all consecutive UPPER syllables into a word. Longest matching algorithm is only used for phrases which have LOWER syllable(s) and do not consist of any NUMBER or OTHER syllable. This system can gain an F-measure of 97.21 %, however, it obviously cannot resolve overlap ambiguity and out-of-vocabulary problems. Moreover, the rule for proper names is too much greedy and fails in many cases. Meanwhile, if we only utilize the classifier using logistic regression in system LR, the result is much better. The regression model can handle many cases of overlap ambiguity and out-of-vocabulary and provide a better way to detect proper names. Combining these two components to LM + LR system provides a slightly increased accuracy compared to LR system. The precision ratio is higher because LM + LR is able to cover all the over-2-syllable words that the LR system fails to catch. However, its recall ratio is decreased because of the inconsistency of those words in the training data and rarely ambiguous cases.</p><p>Post-processing for LR makes a significant impact on the result of segmentation. LR + Post system, which adds postprocessing after LR system, can reach the highest recall ratio of 98.99%. Our whole system which is composed of all components (LM + LR + Post) makes the best result at 98.82% for F-measure. Obviously, performance of post-processing is mainly based on threshold r. In this experiment, we use r = 0.33 which helps to gain the best result. In the next section, we take a deeper look into how to choose a proper threshold r and discuss about its affection to the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c. Discussion on threshold r and post-processing</head><p>Choosing a proper threshold r depends on the quality of dictionary and how well the machine learning process performs. It can be described that if we choose a high r, it means we rely on the dictionary more than the result of the classifier, and otherwise. <ref type="figure" target="#fig_2">Figure 3</ref> depicts our analysis on the affection of threshold r to our system.</p><p>Due to the analysis, we can conclude that our system's results on Vietnamese Treebank corpora is not too sensitive with the variability of r in a wide range from 0.25 to 0.40. However, the high similarity between domains of the training data and test set is one reason for the high performance of our system. To adapt for other domains, it may face more </p><formula xml:id="formula_4">(Ii), i = -2, -1,0,1,2 2 (Ii, li+l), i = -2, -1,0,1 3 (ti), i = -2, -1,0,1,2 4</formula><p>(ti, ti+l), i = -2, -1,0,1 and ti i-LOWER 5 (ti, ti+l, ti+2), i = -2, -1, °and ti i-LOWER 6 (to = tl = LOWER and 10 = II)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7</head><p>(to = tl = UPPER and isVNFamilyName(so))?</p><p>8 (to = tl = UPPER and isVNSyllable(so) and !isVNSyllable(sl))? problems with new words which even the dictionary cannot cover. In this situation, a validation set is needed in order to choose a proper threshold r for new domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison to other toolkits</head><p>Our approach is compared to other approaches that have been presented in other studies. The accuracy figures are depicted in <ref type="table" target="#tab_1">Table III.</ref> Our system provides better result compared to other toolkits on Vietnamese Treebank corpus. It should be repeated that our classifier does not take information from the dictionary. We suspect that this is the reason why it performs better than other stochastic-based toolkits, DongDu and JVnSegmenter. vnTokenizer <ref type="bibr" target="#b0">[1]</ref>, which uses regexes to cover proper names before handling normal words, fails in many cases where upper-case syllables appear consecutively. It is obvious that statistical systems can perform better than vnTokenizer because the training data is not too different from the test set in term of content domain.</p><p>To make another comparison, we retrained each toolkit using the full corpus of Vietnamese Treebank and then evaluated them on an independent test set that consists of 10 files from 800001.seg to 800010.seg provided by VLSP project. From <ref type="table" target="#tab_1">Table III</ref>, we can see that performances of statistical segmentation systems are decreased considerablely, because the new test set has a totally different domain, with many new words that have not appeared in neither the training data nor the dictionary of these systems. Our system with the main component using logistic regression is not an exception but it still has a good performance because of the simple feature set which does not make use of information from dictionary. vnTokenizer performs quite stablely and its result is slightly increased. Notablely, vnTokenizer's dictionary has more than 40k words <ref type="bibr" target="#b0">[1]</ref>, this number of ours is 32k. Although having a poorer dictionary, our system is still able to outperform vnTokenizer.</p><p>Moreover, we also collected a corpus of 1k articles from Vietnamese online newspapers to measure segmentation speed of toolkits. Except DongDu which is developed in C++, the other toolkits are developed in Java. The evaluation is processed on a personal computer with 4 Intel Core i5-3337U CPUs @ 1.80GHz and 6GB of memory. The results is reported in Table IV. Our system can run faster than other toolkits. DongDu toolkit also utilizes LIBLINEAR for machine learning, however, its feature set is much more complicated and its LIBLINEAR version is older than ours. We suspect these are the reasons why DongDu's speed is not as high as our system's. vnTokenizer and JVnSegmenter were written in old versions of Java. Their code to process on String seems to be inefficient so that their speeds are quite low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. UETsegmenter</head><p>Our toolkit used for the above experiments is written in Java and called UETsegmenter. It provides APIs for Vietnamese word segmentation using a pretrained model and also some methods for training and testing new models. The toolkit and related resources are freely available for download 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS</head><p>In this paper, we propose a hybrid approach to Vietnamese word segmentation using longest matching and logistic regression. We cast this task as a binary classification problem for white spaces and the results show that longest matching algorithm, logistic regression combining with our simple postprocessing techniques helps to gain high accuracy. Our system can reach state-of-the-art result at 98.82% for F-measure while evaluating on Vietnamese Treebank corpus. Moreover, the system can perform at a high speed of 34k tokens per second. For future works, we will make a deeper study on the affection of dictionary and the classifier on choosing proper threshold and extend post-processing to deal with other cases. We will also find an efficient way to enrich the dictionary to produce a better segmentation system. 3https://github.comlphongnt570IUETsegmenter </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Architecture of our segmentation system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. A 5-syllable window.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Affection of threshold r on word segmentation result.</figDesc><graphic url="image-6.png" coords="5,58.92,208.32,234.24,124.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>system is Anh-Cuong Le*</head><label></label><figDesc></figDesc><table>Faculty of Information Technology 
Ton Duc Thang University 
No. 19 Nguyen Huu Tho Street 
Tan Phong Ward, District 7 
Ho Chi Minh City, Vietnam 
Email: leanhcuong@tdt.edu.vn 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table I represents all feature templates for logistic regres- sion. In Table I, Ii denotes the lowercase-simplified form of syllable Si; ti is the type of syllable Si; (Ii, Ij) is a combina- tion feature; isV N FamilyName(Si) returns true if and only if Si is a Vietnamese family name; isV N Syllable (Si) returns</head><label>I</label><figDesc>true if and only if Si is a valid Vietnamese syllable.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table II ACCURACIES OF SUB-SYSTEMS (%).</head><label>II</label><figDesc></figDesc><table>Sub-system 
P 

R 
F 
LM 
97.11 
97.31 
97.21 
LR 
97.95 
98.29 
98.12 
LM+LR 
98.11 
98.16 
98.14 
LR + Post 
98.59 
98.99 
98.79 
LM + LR + Post 
98.77 
98.87 
98.82 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table I FEATURE TEMPLATES USED FOR LOGISTIC REGRESSION.</head><label>I</label><figDesc></figDesc><table>No. 
Template 
1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table III ACCURACY COMPARISON (%).</head><label>III</label><figDesc></figDesc><table>Toolkit 
to-fold CV 
Independent test set 

p 
R 

F 
P 

R 

F 
vnTokenizer 
97.61 
96.86 
97.23 
96.98 
97.69 
97.33 
JVnSegmenter -Maxent 
97.18 
97.28 
97.23 
96.60 
97.40 
97.00 
JVnSegmenter -CRFs 
97.58 
97.68 
97.63 
96.63 
97.49 
97.06 
DongDu 
97.44 
98.01 
97.72 
96.35 
97.46 
96.90 
Ours 
98.77 
98.87 
98.82 
97.51 
98.23 
97.87 

Table IV 

SPEED COMPARISON. 

Toolkit 
Speed (tokens/s) 
JVnSeg (CRFs) 
764 
JVnSeg (MaxEnt) 
1082 </table></figure>

			<note place="foot" n="1">http://vlsp.hpda.vn: 8080/demo/?page=home 978-1-5090-4134-3/16/$31.00 ©2016 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This paper is supported by The Vietnam National Foundation for Science and Technology Development (NAFOSTED) under grant number 102. <ref type="bibr">01-2014.22.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A hybrid approach to word segmentation of vietnamese texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussanaly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Language and Automata Theory and Applications-LATA 2008</title>
		<meeting><address><addrLine>BerlinlHeidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">5196</biblScope>
			<biblScope unit="page" from="240" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hybrid approach to vietnamese word segmentation using part-of-speech tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Pham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge and Systems Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="154" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vietnamese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NLPRS</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="749" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building a large syntactically-annotated corpus of vietnamese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-L</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-M.-H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Le</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1698381.1698416" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Linguistic Annotation Workshop, ser. ACL-IJCNLP &apos;09</title>
		<meeting>the Third Linguistic Annotation Workshop, ser. ACL-IJCNLP &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="182" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word segmentation of Vietnamese texts: a comparison of approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">T</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rossignol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th international conference on Language Resources and Evaluation -LREC</title>
		<meeting><address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
	<note>ELRAEuropean Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Available</surname></persName>
		</author>
		<ptr target="https:/lhal.inria.fr/inria-00334760" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Chinese word segmentation: A decade review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="8" to="20" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Word identification for mandarin chinese sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Computational Linguistics</title>
		<meeting>the 14th Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="101" to="107" />
		</imprint>
	</monogr>
	<note>ser. COLING &apos;92</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<idno type="doi">10.3115/992066.992085</idno>
		<ptr target="http://dx.doi.org/10.3115/992066.992085" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Chinese word segmentation based on maximum matching and word binding force</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chan</surname></persName>
		</author>
		<idno type="doi">10.3115/992628.992665</idno>
		<ptr target="http://dx.doi.org/10.3115/992628.992665" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Computational Linguistics</title>
		<meeting>the 16th Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="200" to="203" />
		</imprint>
	</monogr>
	<note>ser. COLING &apos;96</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Vietnamese word segmentation with cns and svms: An investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-T</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 20th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<publisher>PACLIC</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Applying conditional random fields to japanese morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="230" to="237" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An empirical study of active learning with support vector machines for japanese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sassano</surname></persName>
		</author>
		<idno type="doi">10.3115/1073083.1073168</idno>
		<ptr target="http://dx.doi.org/10.3115/1073083.1073168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL &apos;02<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Vietnamese word segmentation using hidden markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop for Computer, Information, and Communication Technologies in Korea and Vietnam</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Japanese word segmentation by hidden markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Papageorgiou</surname></persName>
		</author>
		<idno type="doi">10.3115/1075812.1075875</idno>
		<ptr target="http://dx.doi.org/10.3115/1075812.1075875" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Language Technology, ser. HLT &apos;94</title>
		<meeting>the Workshop on Human Language Technology, ser. HLT &apos;94<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="283" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A method for word segmentation in vietnamese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Corpus Linguistics</title>
		<meeting>Corpus Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving vietnamese word segmentation and pos tagging using mem with various kinds of resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Media Technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="890" to="909" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A maximum entropy approach for vietnamese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research, Innovation and Vision for the Future</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="248" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic ensemble learning for vietnamese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="doi">10.1145/2600428.2609477</idno>
		<ptr target="http://doi.acm.org/10.1145/2600428.2609477" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International ACM SIGIR Conference on Research &amp;#38; Development in Information Retrieval, ser. SIGIR &apos;14</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp;#38; Development in Information Retrieval, ser. SIGIR &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="931" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparative study on thai word segmentation approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Haruechaiyasak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kongyoung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology</title>
		<imprint>
			<date type="published" when="2008-05" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="125" to="128" />
		</imprint>
	</monogr>
	<note>5th International Conference on</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A lattice-based framework for joint chinese word segmentation, pos tagging and parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Accurate word segmentation and pos tagging for japanese microblogs: Corpus annotation and joint modeling with lexical normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="99" to="109" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Jvnsegmenter: A java-based vietnamese word segmentation tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Retrieved on</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1390681.1442794" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
