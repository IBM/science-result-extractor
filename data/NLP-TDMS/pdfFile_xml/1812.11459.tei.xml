<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T09:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A neural joint model for Vietnamese word segmentation, POS tagging and dependency parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Dat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
							<email>dqnguyen@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A neural joint model for Vietnamese word segmentation, POS tagging and dependency parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose the first joint model for Viet-namese word segmentation, part-of-speech (POS) tagging and dependency parsing. Our model extends the BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) with BiLSTM-CRF-based neural layers (Huang et al., 2015) for word segmentation and POS tagging. On benchmark Vietnamese datasets, experimental results show that our joint model obtains state-of-the-art or competitive performances.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dependency parsing is extremely useful in many downstream applications such as relation extraction ( <ref type="bibr" target="#b0">Bunescu and Mooney, 2005</ref>) and machine translation ( <ref type="bibr" target="#b4">Galley and Manning, 2009)</ref>. POS tags are essential features used in dependency parsing. In real-world parsing, most parsers are used in a pipeline process with a precursor POS tagging model for producing predicted POS tags. In English where white space is a strong word boundary indicator, POS tagging is considered to be the first important step towards parsing.</p><p>In contrast to English, for Vietnamese NLP, word segmentation is considered to be the key first step. This is because white space is used in Vietnamese to separate syllables that constitute words, in addition to marking word boundaries <ref type="bibr" target="#b10">(Nguyen et al., 2018)</ref>. For example, a 4-syllable written text "Tôi là sinh viên" (I am student) forms 3 words "Tôi I là am sinh_viên student ". 1 When parsing realworld Vietnamese text where gold word segmentation is not available, a pipeline process is defined that starts with a word segmenter to segment the 1 About 85% of Vietnamese word types are composed of at least two syllables and 80%+ of syllable types are words by themselves ( <ref type="bibr" target="#b9">Thang et al., 2008)</ref>. Conventionally, for Vietnamese word segmentation, white space is only used to separate word tokens while underscore is used to separate syllables inside a word.</p><p>text. The segmented text (e.g. "Tôi là sinh_viên") is provided as the input to the POS tagger, which automatically generates POS-annotated text (e.g. "Tôi/PRON là/VERB sinh_viên/NOUN") which is in turn fed to the parser. See <ref type="figure" target="#fig_0">Figure 1</ref> for the final output. However, Vietnamese word segmenters and POS taggers have a non-trivial error rate, thus leading to error propagation. A solution to these problems is to develop models for jointly learning word segmentation, POS tagging and dependency parsing, such as those that have been actively explored for Chinese. These include traditional feature-based models ( <ref type="bibr" target="#b5">Hatori et al., 2012;</ref><ref type="bibr" target="#b7">Qian and Liu, 2012;</ref><ref type="bibr" target="#b12">Zhang et al., 2014</ref><ref type="bibr" target="#b13">Zhang et al., , 2015</ref>) and neural models ( <ref type="bibr">Kurita et al., 2017;</ref><ref type="bibr">Li et al., 2018</ref>). These models construct transition-based frameworks at character level.</p><p>In this paper, we present a novel end-to-end neural network-based joint model for word segmentation, POS tagging and dependency parsing. To the best of our knowledge, our model is the first one which is proposed to jointly learn these three tasks for Vietnamese. More specifically, our model can be viewed as an extension of the BIST graph-based dependency parser <ref type="bibr">(Kiperwasser and Goldberg, 2016)</ref>, that incorporates BiLSTM-CRFbased architectures <ref type="bibr">(Huang et al., 2015</ref>) to predict the segmentation and POS tags. Experiments on standard benchmark datasets show that our model produces state-of-the-art or competitive results to the three Vietnamese NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our proposed model</head><p>As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, our joint model can be viewed as a mixture of three components: word segmentation, POS tagging and dependency parsing. Our word segmentation component formalizes the Vietnamese word segmentation task as a sequence labeling problem, thus uses a standard BiLSTM-CRF architecture <ref type="bibr">(Huang et al., 2015</ref>  lables, resulting in a word-segmented sequence.</p><p>As for word segmentation, our POS tagging component also uses a BiLSTM-CRF to predict POS tags from the sequence of segmented words. Based on the input segmented words and their predicted POS tags, our dependency parsing component uses a graph-based architecture similarly to the one from <ref type="bibr">Kiperwasser and Goldberg (2016)</ref> to decode dependency arcs and labels. Syllable vector representation: Given an input sentence S of m syllables s 1 , s 2 , ..., s m , we apply an initial word segmenter to produce initial BIO word-boundary tags b 1 , b 2 , ..., b m . Following VnCoreNLP's word segmenter ( <ref type="bibr" target="#b10">Nguyen et al., 2018)</ref>, our initial word segmenter is simply based on the lexicon-based longest matching strategy <ref type="bibr" target="#b6">(Poowarawan, 1986)</ref>. Then we create a vector v i to represent each i th syllable in the input sentence S by concatenating its syllable embedding e (S) s i and its initial word-boundary tag embedding e</p><formula xml:id="formula_0">(B) b i : v i = e (S) s i • e (B) b i (1)</formula><p>Word segmentation (WSeg): The WSeg component uses a BiLSTM (BiLSTM WS ) to learn a latent feature vector representing the i th syllable from a sequence of vectors v 1:m :</p><formula xml:id="formula_1">r (WS) i = BiLSTM WS (v 1:m , i)<label>(2)</label></formula><p>The WSeg component then uses a single-layer feed-forward network (FFNN WS ) to perform linear transformation over each latent feature vector:</p><formula xml:id="formula_2">h (WS) i = FFNN WS r (WS) i (3)</formula><p>Next, the WSeg component feeds output vectors h (WS) i into a linear-chain CRF layer ( <ref type="bibr">Lafferty et al., 2001</ref>) for final BIO word-boundary tag prediction. A cross-entropy objective loss L WS is computed during training, while the Viterbi algorithm is used for decoding. Word vector representation: Assume that we form n words w 1 , w 2 , ..., w n based on m syllables in the input sentence S. Note that we use gold word segmentation when training, and use predicted segmentation produced by the WSeg component when decoding. We create a vector x j to represent each j th word w j by concatenating its word embedding e (W) w j and its syllable-level word embedding e (SW)</p><formula xml:id="formula_3">w j : x j = e (W) w j • e (SW) w j (4)</formula><p>Here, to obtain e (SW)</p><p>w j , we combine sentence-level context sensitive syllable encodings (from Equation 2) and feed it into a FFNN (FFNN SW ):</p><formula xml:id="formula_4">e (SW) w j = FFNN SW r (WS) f (w j ) • r (WS) l(w j ) (5)</formula><p>where f (w j ) and l(w j ) denote indices of the first and last syllables of w j in S, respectively. POS tagging: The POS tagging component first feeds a sequence of vectors x 1:n into a BiLSTM (BiLSTM POS ) to learn latent feature vectors representing input words, and passes each of these latent vectors as input to a FFNN (FFNN POS ):</p><formula xml:id="formula_5">r (POS) j = BiLSTM POS (x 1:n , j) (6) h (POS) j = FFNN POS r (POS) j<label>(7)</label></formula><p>Output vectors h (POS) j are then fed into a CRF layer for POS tag prediction. A cross-entropy loss L POS is computed for POS tagging when training. Dependency parsing: Assume that the POS tagging component produces p 1 , p 2 , ..., p n as predicted POS tags for the input words w 1 , w 2 , ..., w n , respectively. Each j th predicted POS tag p j is represented by an embedding e (P) p j . We create a sequence of vectors z 1:n as input for the dependency parsing component, in which each z j is resulted by concatenating the word vector representation x j (from Equation 4) and the corresponding POS tag embedding e (P) p j . The dependency parsing component uses a BiLSTM (BiLSTM DEP ) to learn latent feature representations from the input z 1:n :</p><formula xml:id="formula_6">z j = x j • e (P) p j (8) r (DEP) j = BiLSTM DEP (z 1:n , j)<label>(9)</label></formula><p>Based on latent feature vectors r (DEP) j , either a transition-based or graph-based neural architecture can be applied for dependency parsing <ref type="bibr">(Kiperwasser and Goldberg, 2016)</ref>. <ref type="bibr">Nguyen et al. (2016)</ref> showed that in both neural network-based and traditional feature-based categories, graphbased parsers perform significantly better than transition-based parsers for Vietnamese. Thus, our parsing component is constructed similarly to the BIST graph-based dependency parser from <ref type="bibr">Kiper- wasser and Goldberg (2016)</ref>. A difference is that we first use FFNNs to split r (DEP) j into head and dependent representations:</p><formula xml:id="formula_7">h (A-H) j = FFNN Arc-Head r (DEP) j (10) h (A-D) j = FFNN Arc-Dep r (DEP) j (11) h (L-H) j = FFNN Label-Head r (DEP) j<label>(12)</label></formula><formula xml:id="formula_8">h (L-D) j = FFNN Label-Dep r (DEP) j<label>(13)</label></formula><p>To score a potential dependency arc, we use a FFNN (FFNN ARC ) with a one-node output layer:</p><formula xml:id="formula_9">score(i, j) = FFNN ARC h (A-H) i • h (A-D) j<label>(14)</label></formula><p>Given scores of word pairs, we predict the highest scoring projective parse tree by using the Eisner (1996) decoding algorithm. This unlabeled parsing model is trained with a margin-based hinge loss L ARC ( <ref type="bibr">Kiperwasser and Goldberg, 2016)</ref>.</p><p>To label predicted arcs, we use another FFNN (FFNN LABEL ) with softmax output:</p><formula xml:id="formula_10">v (i,j) = FFNN LABEL h (L-H) i • h (L-D) j<label>(15)</label></formula><p>Based on vectors v (i,j) , a cross entropy loss L LABEL for dependency label prediction is computed when training, using the gold labeled tree. Joint training: We train our joint model by summing the losses L WS , L POS , L ARC and L LABEL prior to computing the gradients. Model parameters are learned to minimize the sum of the losses. Discussion: Our model can be also viewed as an extension of the joint POS tagging and dependency parsing model jPTDP-v2 <ref type="bibr">(Nguyen and Ver- spoor, 2018)</ref>, where we incorporate a BiLSTM-CRF architecture for word boundary prediction. Other improvements to jPTDP-v2 include: (i) we use 'global' sentence-level context for learning word embeddings (in Equation 5) rather than 'local' single word-based character-level embeddings, (ii) we use a CRF layer for POS tagging instead of a softmax layer, and (iii) following , we employ head and dependent projection representations (in Equations 10-13) as feature vectors for dependency parsing rather than the top recurrent states (in Equation 9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental setup</head><p>Datasets: We follow the setup used in the VnCoreNLP toolkit ( <ref type="bibr" target="#b10">Vu et al., 2018</ref>). <ref type="bibr">2</ref> For word segmentation and POS tagging, we use standard datasets from the Vietnamese Language and Speech Processing (VLSP) 2013 shared tasks. <ref type="bibr">3</ref> To train the word segmentation layer, we use 75K manually word-segmented sentences in which 70K sentences are used for training and 5K sentences are used for development. For POS tagging, we use 27,870 manually word-segmented and POS-annotated sentences in which 27K and 870 sentences are used for training and development, respectively. For both tasks, the test set consists of 2120 manually word-segmented and POS-annotated sentences. To train the dependency parsing layer, we use the benchmark Vietnamese dependency treebank VnDT of 10,200 sentences ( <ref type="bibr">Nguyen et al., 2014</ref>), and follow a standard split to use the last 1,020 sentences of VnDT for test, the first 200 sentences for development and the remaining 8,980 sentences for training. Implementation: We implement our joint model (namely, jointWPD) using DYNET v2.0 (Neubig et al., 2017) with a fixed random seed. We learn model parameters using Adam ( <ref type="bibr">Kingma and Ba, 2014</ref>) without mini-batches, and run for 50 epochs. We compute the average of F1 scores computed for word segmentation, POS tagging and (LAS) dependency parsing after each training epoch. We choose the model with the highest average score over development sets to apply to test sets. See Appendix for implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Main results</head><p>Our scores on the test sets are presented in Table 1. We compare our scores with the traditional feature-based Vietnamese NLP pipeline VnCoreNLP ( <ref type="bibr" target="#b10">Vu et al., 2018</ref>) which produced the previous highest reported results on the same test sets. In particular, VnCoreNLP's POS tagging component <ref type="bibr">(Nguyen et al., 2017</ref>) obtained 0.5+% absolute higher results than BiLSTM-CRFbased models with character-level word embed-   dings ( <ref type="bibr">Lample et al., 2016;</ref><ref type="bibr">Ma and Hovy, 2016)</ref>, while its dependency parsing component ( <ref type="bibr" target="#b10">Vu et al., 2018</ref>) did slightly better than the well-known BIST dependency parsers <ref type="bibr">(Kiperwasser and Gold- berg, 2016)</ref>. Note that published scores of VnCoreNLP for POS tagging and dependency parsing were reported using gold word segmentation (see Appendix for more details). Since we use the same experimental setup, we thus rerun VnCoreNLP on the unsegmented test sentences and compute its scores. Our model jointWPD obtains a slightly lower word segmentation score and a similar POS tagging score against VnCoreNLP. However, jointWPD obtains 2.5+% higher LAS and UAS than VnCoreNLP.</p><p>In addition, we also present in <ref type="table">Table 1</ref> scores of the joint POS tagging and dependency parsing model jPTDP-v2 <ref type="bibr">(Nguyen and Verspoor, 2018)</ref> and the state-of-the-art Biaffine dependency parser (Dozat and Manning, 2017) on this task. 4 <ref type="bibr">4</ref> We reimplement jPTDP-v2 such that its POS tagging layer makes use of the VLSP 2013 POS tagging training set of 27K sentences, and then perform hyper-parameter tuning. The original jPTDP-v2 implementation only uses gold POS tags available in 8,980 dependency trees, thus giving lower For Biaffine which requires automatically predicted POS tags, following <ref type="bibr" target="#b10">Vu et al. (2018)</ref>, we produce the predicted POS tags on the whole VnDT treebank by using VnCoreNLP. We train both jPTDP-v2 and Biaffine with gold word segmentation. For test, these models are fed with predicted word-segmented test sentences produced by VnCoreNLP. Our model jointWPD does better than jPTDP-v2 with 0.7% LAS improvement. However, jointWPD obtains 1.2% lower LAS than Biaffine which uses a more sophisticated "biaffine" attention mechanism for predicting dependency arcs and labels. We will extend our dependency parsing component with the biaffine attention mechanism to investigate the benefit for our joint model in future work. <ref type="table" target="#tab_2">Table 2</ref> presents performances of pipeline approaches: WS → Pos → Dep where we treat our word segmentation, POS tagging and dependency parsing components as independent networks, and train them separately; and WS &amp; Pos → Dep where only the word segmentation and POS tagging components are jointly trained. We find that the fully-joint approach jointWPD does better than the two pipeline approaches. <ref type="table" target="#tab_2">Table 2</ref> also presents ablation tests over 4 factors. When not using either initial word-boundary tag embeddings or the CRF layer for word-boundary tag prediction, all scores degrade by about 0.5+% absolutely. The 2 remaining factors, including (c) using a softmax classifier for POS tag prediction rather than a CRF layer and (d) removing POS tag embeddings, do not effect the word segmentation score. Both factors moderately decrease the POS tagging score. Factor (c) slightly decreases LAS and UAS parsing scores, while factor (d) degrades the parsing scores by about 1.0+%, clearly showing the usefulness of POS tag information for dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we have presented the first model for joint word segmentation, POS tagging and dependency parsing in Vietnamese. Experiments on benchmark Vietnamese datasets show that our joint model obtains results competitive with the state-of-the-art. A Chinese character is analogous to a syllable in Vietnamese. We will therefore evaluate the application of our model to Chinese in future work.</p><p>parsing performance than ours. For Biaffine, we use its updated version ) which won the CoNLL 2017 shared task on dependency parsing ( <ref type="bibr" target="#b11">Zeman et al., 2017</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of our joint model. Linear transformations are not shown for simplification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Using a softmax layer for word-boundary tag predic- tion instead of a CRF layer; (c): Using a softmax layer for POS tag prediction instead of a CRF layer; (d) With- out using the POS tag embeddings for the dependency parsing component, i.e. Equation 8 becomes z j = x j .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>F1 scores for unsegmented development sen-
tences. (a): Without using initial word-boundary tag 
embedding, i.e., Equation 1 becomes v i = e 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-
tional LSTM-CRF Models for Sequence Tagging. 
arXiv preprint, arXiv:1508.01991. 

Diederik P. Kingma and Jimmy Ba. 2014. Adam: 
A Method for Stochastic Optimization. CoRR, 
abs/1412.6980. 

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and Accurate Dependency Parsing Using Bidi-
rectional LSTM Feature Representations. Transac-
tions of ACL, 4:313-327. 

Shuhei Kurita, Daisuke Kawahara, and Sadao Kuro-
hashi. 2017. Neural Joint Model for Transition-
based Chinese Syntactic Analysis. In Proceed-
ings of the 55th Annual Meeting of the Association 
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1204-1214. 

John D. Lafferty, Andrew McCallum, and Fernando 
C. N. Pereira. 2001. Conditional Random Fields: 
Probabilistic Models for Segmenting and Labeling 
Sequence Data. In Proceedings of the Eighteenth In-
ternational Conference on Machine Learning, pages 
282-289. 

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016. 
Neural Architectures for Named Entity Recognition. 
In Proceedings of the 2016 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies, 
pages 260-270. 

Haonan Li, Zhisong Zhang, Yuqi Ju, and Hai Zhao. 
2018. Neural Character-level Dependency Parsing 
for Chinese. In Proceedings of the Thirty-Second 
AAAI Conference on Artificial Intelligence, pages 
5205-5212. 

Xuezhe Ma and Eduard Hovy. 2016. End-to-end Se-
quence Labeling via Bi-directional LSTM-CNNs-
CRF. In Proceedings of the 54th Annual Meeting of 
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 1064-1074. 

Graham Neubig, Chris Dyer, Yoav Goldberg, Austin 
Matthews, Waleed Ammar, Antonios Anastasopou-
los, Miguel Ballesteros, David Chiang, Daniel 
Clothiaux, Trevor Cohn, Kevin Duh, Manaal 
Faruqui, Cynthia Gan, Dan Garrette, Yangfeng Ji, 
Lingpeng Kong, Adhiguna Kuncoro, Gaurav Ku-
mar, Chaitanya Malaviya, Paul Michel, Yusuke 
Oda, Matthew Richardson, Naomi Saphra, Swabha 
Swayamdipta, and Pengcheng Yin. 2017. DyNet: 
The Dynamic Neural Network Toolkit. 
arXiv 
preprint arXiv:1701.03980. 

Dat Quoc Nguyen, Mark Dras, and Mark Johnson. 
2016. An empirical study for Vietnamese depen-
dency parsing. In Proceedings of the Australasian 
Language Technology Association Workshop 2016, 
pages 143-149. 

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham, 
Phuong-Thai Nguyen, and Minh Le Nguyen. 2014. 
From Treebank Conversion to Automatic Depen-
dency Parsing for Vietnamese. In Proceedings 
of 19th International Conference on Application of 
Natural Language to Information Systems, pages 
196-207. 

Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark 
Dras, and Mark Johnson. 2018. A Fast and Accu-
rate Vietnamese Word Segmenter. In Proceedings 
of the 11th International Conference on Language 
Resources and Evaluation, pages 2582-2587. 

Dat Quoc Nguyen and Karin Verspoor. 2018. An Im-
proved Neural Network Model for Joint POS Tag-
ging and Dependency Parsing. In Proceedings of 
the CoNLL 2018 Shared Task: Multilingual Pars-
ing from Raw Text to Universal Dependencies, pages 
81-91. 

Dat Quoc Nguyen, Thanh Vu, Dai Quoc Nguyen, Mark 
Dras, and Mark Johnson. 2017. From Word Seg-
mentation to POS Tagging for Vietnamese. In Pro-
ceedings of the Australasian Language Technology 
Association Workshop 2017, pages 108-113. </table></figure>

			<note place="foot" n="2"> https://github.com/vncorenlp/ VnCoreNLP 3 http://vlsp.org.vn/vlsp2013</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Implementation details: When training, each task component is fed with the corresponding task-associated training sentence. The dependency parsing training set is smallest in size (consisting of 8,980 sentences), thus for each training epoch, we sample the same number of sentences from the word segmentation and POS tagging training sets. Dropout ( <ref type="bibr" target="#b8">Srivastava et al., 2014</ref>) is applied with a 67% keep probability to the inputs of BiLSTMs and FFNNs. Following <ref type="bibr">Kiperwasser and Goldberg (2016)</ref>, we use word dropout to learn embeddings for unknown syllables/words: we replace each syllable/word token s/w appearing #(s/w) times with a "unk" symbol with prob-</p><p>We initialize syllable and word embeddings with 100-dimensional pre-trained Word2Vec vectors as used in <ref type="bibr">Nguyen et al. (2017)</ref>, while POS tag embeddings are randomly initialized. These embeddings are then updated when training. The sizes of the output layers of FFNN WS , FFNN POS and FFNN LABEL are the number of BIO wordboundary tags (i.e. 3), the number of POS tags and the number of dependency relation types, respectively. We perform a minimal grid search of hyperparameters, resulting in the POS tag embedding size of 100, the size of the output layers of remaining FFNNs at 100, the number of BiLSTM layers at 2 and the size of LSTM hidden states in each layer at 128.  Additional results: <ref type="table">Table 3</ref> presents POS tagging and parsing accuracies regarding gold word segmentation. In this case, for our jointWPD, we feed the POS tagging and parsing components with gold word-segmented sentences when decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model WSeg PTag LAS UAS</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Shortest Path Dependency Kernel for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="724" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep Biaffine Attention for Neural Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stanford&apos;s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="20" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Three New Probabilistic Models for Dependency Parsing: An Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Computational Linguistics</title>
		<meeting>the 16th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quadratic-Time Dependency Parsing for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="773" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hatori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1045" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dictionary-based Thai Syllable Separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuen Poowarawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Electronics Engineering Conference</title>
		<meeting>the Ninth Electronics Engineering Conference</meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="409" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint Chinese Word Segmentation, POS Tagging and Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="501" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Word segmentation of Vietnamese texts : a comparison of approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><forename type="middle">Hong</forename><surname>Dinh Quang Thang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen Thi Minh</forename><surname>Phuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cam</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rossignol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vu Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Language Resources and Evaluation</title>
		<meeting>the 6th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1933" to="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">VnCoreNLP: A Vietnamese Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="56" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memduh</forename><surname>Gokirmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajic Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslava</forename><surname>Hlavacova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Václava</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zdenka</forename><surname>Uresova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Taji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Depaiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Droganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gr¨agr¨ Gr¨a C ¸ ¨ Oltekin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<editor>Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector Fernandez Alcalde, Jana Strnadová, Esha Banerjee, Ruli Manurung, Antonio Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendonca, Tatiana Lando, Rattima Nitisaroj, and Josie Li</editor>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Character-Level Chinese Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1326" to="1336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Randomized Greedy Inference for Joint Segmentation, POS Tagging and Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="42" to="52" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
