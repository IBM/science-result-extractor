<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T09:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-09">September 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Sheffield</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
								<orgName type="institution" key="instit3">University of Washington</orgName>
								<orgName type="institution" key="instit4">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
							<email>aritter@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Sheffield</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
								<orgName type="institution" key="instit3">University of Washington</orgName>
								<orgName type="institution" key="instit4">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Clark</surname></persName>
							<email>ssclark@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Sheffield</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
								<orgName type="institution" key="instit3">University of Washington</orgName>
								<orgName type="institution" key="instit4">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
							<email>kalina@dcs.shef.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Sheffield</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
								<orgName type="institution" key="instit3">University of Washington</orgName>
								<orgName type="institution" key="instit4">University of Sheffield</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
						<meeting>Recent Advances in Natural Language Processing <address><addrLine>Hissar, Bulgaria</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="7" to="13"/>
							<date type="published" when="2013-09">September 2013</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Part-of-speech information is a prerequisite in many NLP algorithms. However, Twitter text is difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style. We present a detailed error analysis of existing taggers, motivating a series of tagger augmentations which are demonstrated to improve performance. We identify and evaluate techniques for improving English part-of-speech tagging performance in this genre. Further, we present a novel approach to system combination for the case where available taggers use different tagsets, based on vote-constrained bootstrapping with unlabeled data. Coupled with assigning prior probabilities to some tokens and handling of unknown words and slang, we reach 88.7% tagging accuracy (90.5% on development data). This is a new high in PTB-compatible tweet part-of-speech tagging, reducing token error by 26.8% and sentence error by 12.2%. The model, training data and tools are made available.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter provides a wealth of uncurated text. The site has over 200 million users active each month <ref type="bibr" target="#b26">(O'Carroll, 2012</ref>) generating messages at a peak rate over 230 000 per minute <ref type="bibr" target="#b1">(Ashtari, 2013)</ref>. Information found on Twitter has already been shown to be useful for a variety of applications (e.g. monitoring earthquakes ( <ref type="bibr" target="#b31">Sakaki et al., 2010</ref>) and predicting flu <ref type="bibr" target="#b9">(Culotta, 2010)</ref>). However, the lack of quality part-of-speech taggers tailored specifically to this emerging genre impairs the accuracy of key downstream NLP techniques (e.g. named entity recognition, term extraction), and by extension, overall application results.</p><p>Microblog text (from e.g. Twitter) is characterised by: short messages; inclusion of URIs; username mentions; topic markers; and threaded conversations. It often presents colloquial content containing abbreviations and errors. Some of these phenomena comprise linguistic noise, which when coupled with message brevity (140 characters for "tweets") and the lack of labeled corpora, make microblog part-of-speech tagging very challenging. Alongside the genre's informal nature, such limits encourage "compressed" utterances, with authors omitting not only needless words but also those with grammatical or contextualising function.</p><p>Part-of-speech tagging is a central problem in natural language processing, and a key step early in manly NLP pipelines. Machine learning-based part-of-speech (PoS) taggers can exploit labeled training data to adapt to new genres or even languages, through supervised learning. Algorithm sophistication apart, the performance of these taggers is reliant upon the quantity and quality of available training data. Consequently, lacking large PoS-annotated resources and faced with prevalent noise, state-of-the-art PoS taggers perform poorly on microblog text ), with error rates up to ten times higher than on newswire (see Section 3).</p><p>To address these issues, we propose a data-intensive approach to microblog part-of-speech tagging for English, which overcomes data sparsity by using the thousands of unlabeled tweets created every minute, coupled with techniques to smooth out genre-specific noise. To reduce the impact of data sparsity, we introduce a new method for vote-constrained bootstrapping, evaluated in the context of PoS tagging. Further, we introduce methods for handling the genre's characteristic errors and slang, and evaluate the performance impact of adjusting prior tag probabilities of unambiguous tokens.</p><p>1. A comprehensive comparative evaluation of existing POS taggers on tweet datasets is carried out (Section 3), followed by a detailed analysis and classification of common errors (Section 4), including errors due to tokenisation, slang, out-ofvocabulary, and spelling. 2. Address tweet noisiness through handling of rare words (Section 5.1) and adjusting prior tag probabilities of unambiguous tokens, using external knowledge (Section 5.2). 3. Investigate vote-constrained bootstrapping on a large corpus of unlabeled tweets, to create needed tweet-genre training data (Section 5.3). 4. Demonstrate that these techniques reduce tokenlevel error by 26.8% and sentence-level error by 12.2% (Section 6). <ref type="table" target="#tab_3">TnT  96.76%  85.86% 96.46%  - SVMTool 97.39%  89.01% 97.16%  - TBL  - -93.67%  - Stanford  - 90</ref>.46% 97.28% 56.79% <ref type="table">Table 1</ref>: Token-level labeling accuracy for four off-theshelf PoS taggers on newswire. Not all these performance measures are supplied in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tagger</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Known Unknown Overall Sentence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Regarding Twitter part-of-speech tagging, the two most similar earlier papers introduce the ARK tagger (Gimpel et al., 2011) and T-Pos ( <ref type="bibr" target="#b30">Ritter et al., 2011</ref>). Both these approaches adopt clustering to handle linguistic noise, and train from a mixture of hand-annotated tweets and existing PoS-labeled data. The ARK tagger 1 reaches 92.8% accuracy at token level but uses a coarser, custom tagset. T-Pos 2 is based on the Penn Treebank set and, in its evaluation, achieves an 88.4% token tagging accuracy. Neither report sentence/wholetweet accuracy rates. <ref type="bibr" target="#b15">Foster et al. (2011)</ref> introduce results for both PoS tagging and parsing, but do not present a tool, and focus more on the parsing aspect. Previous work on part-of-speech tagging in noisy environments has focused on either dealing with noisy tokens either by using a lexicon that can handle partial matches through e.g. topic models ( <ref type="bibr" target="#b12">Darling et al., 2012)</ref> or Brown clustering <ref type="bibr" target="#b7">(Clark, 2003)</ref>, or by applying extra processing steps to correct/bias tagger performance, e.g., post-/pre-processing respectively <ref type="bibr" target="#b16">(Gadde et al., 2011</ref>). Finally, classic work on bootstrapped PoS tagging is that of , who use a cotraining approach to improve tagger performance using unlabeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Comparing taggers on Twitter data</head><p>In order to evaluate a new tagging approach, we must first have a good idea of the current performance of state-of-the art tools, and a common basis (e.g. corpus and tagset) for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conventional Part-of-speech Taggers</head><p>To quantify the disadvantage conventional PoS taggers have when faced with microblog text, we evaluate state-of-the-art taggers against Twitter data. We used the same training and evaluation data for each tagger, re-training taggers where required.</p><p>When measuring the performance of taggers, as per popular convention we report the overall proportion of tags that are accurately assigned. Where possible we report performance on "unknown" words -those that  <ref type="table">Table 2</ref>: Token tagging performance of WSJ-trained taggers (sections 0-18) on Twitter data. Figures listed are the proportion of tokens labeled with the correct part-of-speech tag, and the proportion of sentences in which all tokens were correctly labeled.</p><p>do not occur in the training data. Further, as per Manning (2011) we report the rate of getting whole sentences right, since "a single bad mistake in a sentence can greatly throw off the usefulness of a tagger to downstream tasks". <ref type="bibr">3</ref> We evaluated four state-of-the-art trainable and publicly available PoS taggers that used the Penn Treebank tagsettrereetagger: SVMTool ( <ref type="bibr">Giménez and Mar- quez, 2004</ref>), the Stanford Tagger ( <ref type="bibr" target="#b33">Toutanova et al., 2003)</ref>, <ref type="bibr">TnT (Brants, 2000</ref>) and a transformation-based learning (TBL) tagger <ref type="bibr" target="#b5">(Brill, 1995</ref>) supported by sequential n-gram backoff. The NLTK implementations of TnT and TBL were used ( <ref type="bibr" target="#b2">Bird et al., 2009</ref>). The 'left3words' model was used with the Stanford tagger, and 'M0' with SVMTool. For initial comparison, taggers were tested on standard newswire text from the Penn Treebank ( <ref type="bibr" target="#b24">Marcus et al., 1993</ref>), <ref type="bibr">4</ref> training with Wall Street Journal (WSJ) sections 0-18 and evaluating on sections 19-21. The base performance for each tagger is given in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Labeled Tweet Corpora</head><p>Three PoS-labeled microblog datasets are currently available. The T-Pos corpus of 15K tokens introduced by <ref type="bibr" target="#b30">Ritter et al. (2011)</ref> uses a tagset based on the Penn Treebank tagset,plus four new tags for URLs (URL), hashtags (HT), username mentions (USR) and retweet signifiers (RT). The DCU dataset of 14K tokens <ref type="bibr">(Fos- ter et al., 2011</ref>) is also based on the Penn Treebank (PTB) set, but does not have the same new tags as TPos, and uses slightly different tokenisation. The ARK corpus of 39K tokens <ref type="bibr" target="#b18">(Gimpel et al., 2011</ref>) uses a novel tagset, which, while suitable for the microblog genre, is somewhat less descriptive than the PTB sets on many points. For example, its V tag corresponds to any verb, conflating PTB's VB, VBD, VBG, VBN, VBP, VBZ, and MD tags. Intuitively, this seems to be a simpler tagging task, and performance using it reaches 92.8% ( <ref type="bibr" target="#b27">Owoputi et al., 2012</ref>).   <ref type="table">Table 3</ref>: Performance of taggers trained on a WSJ/IRC/Twitter (T-train) corpus. T-Pos is the only tagger with Twitter-specific customisations.</p><p>Although it is possible to transduce data labeled using the T-Pos or PTB tagsets to the ARK tagset, the reverse is not true. We built a tagger using the T-Pos tagset. This choice was motivated by the tagset's PTB compatibility, the volume of existing tools which rely on a PTB-like tagging schema, and the fact that labeling microtext using this more complex tagset is not vastly more difficult than with the ARK tagset (e.g. Ritter et al. <ref type="formula">(2011))</ref> The following datasets were used in our study. We shuffled and then split the T-Pos data 70:15:15 into training, development and evaluation sets named Ttrain, T-dev and T-eval. Splits are made at whole-tweet level. For comparability, we mapped the DCU development and evaluation datasets (D-dev and D-eval) into the T-Pos tokenisation and tagset schema.</p><p>Some near-genre corpora are available. For example, resources are available of IRCtext and SMS text <ref type="bibr" target="#b0">(Almeida et al., 2011</ref>). Of these, only one is annotated for part-of-speech tags -the NPS IRC corpus <ref type="bibr" target="#b14">(Forsyth and Martell, 2007</ref>) -which we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance Comparison</head><p>For training data composition, we approximate Ritter's approach. We use 50K tokens from the Wall Street Journal part of the Penn Treebank (WSJ), 32K tokens from the NPS IRC corpus, and T-train (2.3K tokens). We vary in that we have a fixed split of Twitter data, where earlier work did four-way cross-validation.</p><p>The first experiment was to evaluate the performance of the news-trained taggers described in Section 3.1 on two tweet corpora: T-dev and D-dev. As shown in <ref type="table">Table 2</ref>, performance on tweets is poor and, in some cases, absolute token accuracy is 20% lower than with newswire <ref type="table">(Table 1</ref>). This comparison is somewhat unfair as not all labels in the test set are seen in the training data. Combining training data of 10K tokens of tweets, 10K tokens of a genre similar to tweets (IRC) and 50K tokens of non-tweets (newswire) is fairer; performance of taggers trained on this dataset is given in <ref type="table">Table 3</ref>. All taggers performed better against T-dev after having T-train and the IRC data included in their training data (e.g. from 73.37% to 83.14% for the Stanford tagger), showing the impact of tweet-genre training data.</p><p>However, the improvements are much less impressive on D-dev, which is a completely different corpus. There, e.g. Stanford improves only from 83.29% on    <ref type="table" target="#tab_3">Table 4</ref>, the newswire-only trained Stanford tagger performed worst, with IRC (a tweet-like genre) training data yielding some improvement and tweetgenre data having greatest effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Error analysis</head><p>We investigated errors made on words not in the training lexicon (unknown words). For the basic Stanford tagger model trained using WSJ+IRC+Twitter (Ttrain), the tagging accuracy on known tokens (e.g. those in the training lexicon) is 83.14%, and 38.56% on unknown words. One approach for improving overall accuracy is to better handle unknown words.</p><p>Tagging of unknown words forces the tagger to rely on contextual clues. Errors on these words make up a large part of the mis-tagged tokens. One can see the effect that improving accuracy on unknown words has on overall performance by comparing, for example, the Stanford tagger when trained on non-tweet vs. tweet data in <ref type="table" target="#tab_3">Table 4</ref>. We identified the unknown words that were tagged incorrectly and categorised them into eight groups.</p><p>Gold standard error -Where the ground truth data is wrong. For example, the Dutch dank je should in an English corpus be tagged as foreign words (FW), but in our dataset is marked dank/URL je/IN. These are not tagger errors but rather evaluation errors, avoided by repairing the ground truth.</p><p>In-vocabulary -Tokens that are common in general, but do not occur in the training data. For example, Internet and bake are unknown words and mis-tagged in the evaluation corpus. This kind of error may be fixed by a larger training set or the use of a lexicon, especially for monosemous words.</p><p>Pre-taggable -Words to which a label may be reliably assigned automatically. This group includes wellformed URLs, hash tags and smileys.</p><p>Proper noun -Proper nouns not in the training data. Most of these should be tagged NNP, and are often useful for later named entity recognition. Incorrectly tagged proper nouns often had incorrect capitalisation; for example, derek and birmingham. Gazetteer approaches may help annotate these, in cases of words that can only occur as proper nouns.</p><p>Slang -An abundance of slang is a characteristic feature of microblog text, and these words are often incorrectly tagged, as well as being rarely seen due to a proliferation of spelling variations (all incorrect). Examples include LUVZ, HELLA and 2night. Some kind of automatic correction or expanded lexicon could be employed to either map these back to dictionary words or to include previously-seen spelling variations.</p><p>Tokenisation error -Occasionally the tokeniser or original author makes tokenisation errors. Examples include ass**sneezes, which should have been split into more than one token as indicated by special/punctuation characters, and eventhough, where the author has missed a space. These are hard to correct. Specific subtypes of error, such as the joined words in the example, could be checked for and forcibly fixed, though this requires distinguishing intentional from unintentional word usage.</p><p>Genre-specific -Words that are unique to specific sites, often created for microblog usage, such as unfollowing. Extra tweet-genre-specific training data may to reduce genre-specific word errors.</p><p>Orthographic error -Finally, although it is difficult to detect the intent of the user, some content seems likely to have been accidentally mis-spelled. Examples include Handle] and suprising. Automatic spelling correction may improve performance in these cases.</p><p>We also examined the impact the volume of training data had on performance. <ref type="figure" target="#fig_1">Figure 1</ref> shows a continuing performance increase as ground-truth tweets are added, suggesting more tweet-genre training data will yield improvements. Conversely, there is already enough newswire-type training data and adding more is unlikely to greatly increase performance <ref type="figure" target="#fig_2">(Figure 2)</ref>. Consequently, subsequent experiments do not include more newswire beyond the 50K-token WSJ corpus excerpt also used in T-Pos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Addressing Noise and Data Sparseness</head><p>Our examination of frequent PoS tagging errors identified some readily rectifiable classes of problem. These were: slang, jargon and common mis-spellings; genrerelated phrases; smileys; and unambiguous named entities. In addition, observations suggested that more tweet training data would help. Thus, we augmented our approach in three ways: improved handling of unknown and slang words; conversion of unambiguous tags into token prior probabilities; and addition of semi-supervised training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Normalisation for Unknown Words</head><p>Tagging accuracy on tokens not seen in the training data (out-of-vocabulary, or OOV tokens) is lower than that on those previously encountered (see <ref type="table">Table 1</ref>). Consequently, reducing the proportion of unknown words is likely to improve performance. Informal error analysis suggested that slang makes up a notable proportion of the unknown word set. To provide invocabulary (IV) versions of slang words (i.e. to normalise them), we created a set of mappings from OOV words to their IV equivalents, using slang dictionaries and manual examination of the training data. The mapping is applied to text before it is tagged, and the original token is labeled with a PoS tag based on the mapped (normalised) word.</p><p>Many texts contain erroneous or slang tokens, which can be mapped to in-lexicon versions of themselves via normalisation. A critical normalisation subtask is Sent. Baseline <ref type="bibr">7</ref> 83.14% 6.78% Word shape features <ref type="bibr">8</ref> 87.91% 22.88% As above, excl. company suffixes 88.34% 25.42% Low common word threshold <ref type="bibr">9</ref> 88.36% 25.42% Low common &amp; rare word thresh. <ref type="bibr">10</ref> 88.49% 25.42% <ref type="table">Table 6</ref>: Impact of introduction of word shape features, as token accuracy on T-dev. distinguishing previously-unseen but correctly spelled words (such as proper nouns) from those with orthographic anomalies. Anomalous tokens are those with unusual orthography, either intentional (e.g. slang) or unintentional (e.g. typos). Slang words account for a large proportion of mislabeled unknowns <ref type="table" target="#tab_4">(Table 5)</ref>. Normalisation is a difficult task and current approaches are complex ( <ref type="bibr" target="#b21">Kaufmann and Kalita, 2010;</ref><ref type="bibr" target="#b20">Han and Baldwin, 2011;</ref><ref type="bibr" target="#b22">Liu et al., 2012</ref>). Rather than apply sophisticated word clustering or multi-stage normalisation, we took a data-driven approach to investigating and then handling problematic tokens.</p><p>Setup In our data, a small subset of orthographic errors and otherwise-unusual words account for a large part of the total anomalous words. We use a lookup list (derived from unknown words in the training corpus) to map these to more common forms, e.g. luv→love and hella→very. 5 This lookup list is based upon both external slang gazetteers and observations over T-train.</p><p>To supplement this knowledge-based approach, we enable and fine-tune unknown-word handling features of the Stanford tagger. The tagger contains highlyconfigurable feature generation options for handling unknown words. These extra rare word features accounted for information such as word shape, word length and so on. <ref type="bibr">6</ref> Their inclusion should increase the amount of unknown word handling information in the final model. Results are given in <ref type="table">Table 6</ref>.</p><p>We also tuned the rare word thresholds for our corpus, changing the threshold for inclusion of a token's rare word features. We tried values from zero to 20 in steps of 1; per-token performance peaked at 88.49% for rarewordthreshold = 3. It slowly declined for higher values up to 700 (tested in larger steps). This modest improvement indicates value in optimising the rare word threshold.</p><p>Unknown Handling Results Thus, we were able to increase part-of-speech tagging performance in three ways: by adapting the idea of normalisation and implementing it with both fixed word-lists (repairing all but 20% of problem tokens), with extra features encoding word shapes to handle OOV terms, and with a Entity pre-labeled Token Baseline 88.49% Slang 88.76% Named Entities 88.71% Smileys 88.54% Genre-specific 88.58% All 89.07% Error reduction 5.03% <ref type="table">Table 7</ref>: Impact of prior labeling and mapping slang to IV terms on T-dev; rare word threshold is 3.</p><p>more sensitive threshold to inclusion of rare words in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Tagging from External Knowledge</head><p>It is possible to constrain the possible set of sentence labelings by pre-assigning probability distributions to tokens for which there is an unambiguous tag. In these cases, the distribution is just P (t correct ) = 1.0. This strategy not only improves accuracy on these tokens, but also reduces uncertainty regarding the set of potential sentence taggings. For example, in a simplified HMM bigram tagging scenario, one has a sequence of words w 0 , w 1 ..w n having corresponding tags t 0 , t 1 ..t n , and is concerned with emission distributions P (w i |t i ) and tag transition probabilities P (t i |t i−1 ). Knowing P (t i ) for one word affects all subsequent tag distributions. As the tagger is typically used in a bidirectional mode (effectively adding reverse transition probabilities P (t i |t i+1 )), using prior knowledge to inform labels reduces tagging uncertainty over the whole sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>In the above error analysis, off-the-shelf taggers made errors on some Twitter-specific phenomena. Some errors on tokens where the four tweet-specific labels URL, USR, RT and HT apply can be reliably and automatically prevented by using regular expression patterns to detect pertinent tokens.</p><p>A second category of mistakes was smileys (aka emoticons), of which the most frequent can be labeled UH unambiguously using a look-up list. Some flexibility is required to capture smiley variations, e.g. --vs. --( <ref type="bibr" target="#b28">Park et al., 2013)</ref>, which was implemented again with high-accuracy regular expressions.</p><p>Proper noun errors (NN/NNP) were relatively common -an observation also made by <ref type="bibr" target="#b30">Ritter et al. (2011)</ref>. It is possible to recognise unambiguous named entities (i.e. words that only ever occur as NNP) using external knowledge sources, such as a gazetteer list or an entity database. In this case, we used GATE's ANNIE gazetteer lists of personal first-names and cities <ref type="bibr">(Cun- ningham et al., 2002</ref>) and, in addition, a manually constructed list of corporation and website names frequently mentioned in the training data (e.g. YouTube, Toyota). Terms were excluded from the latter list if their PoS tag is ambiguous (e.g. google may occur as a proper noun or verb and so is not included). Tagging with Priors Results In our experiments, the tagger was adapted to take prior probabilities into account, and experiments run using a model trained on WSJ+IRC+T-train that includes the noise-handling augmentations described in Section 5.1. <ref type="table">Table 7</ref> shows the performance difference on each of the four categories of token discussed above. Each has an effect, combining to yield a 5.0% error reduction (P&lt;0.005, McNemar's test). When the original model detailed in <ref type="table">Table 3</ref> is used, token performance improves from 83.14% accuracy to 86.93%. Assignment of priors affords 22.5% error reduction in this scenario. We compare fixing the tag before tagging the rest of the sentence, with tagging the whole sentence and overwriting such tokens' tags. While the latter only affects unambiguous tokens, the former affects the other tags in the sentence during tagging, via e.g. transmission probabilities and window features. This is a novel adaptation of this tagger. To compare, when correcting this model's labels post-tagging, error reduction is only 19.0% (to 86.34%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Vote-constrained Bootstrapping</head><p>Having seen the impact that tweet data has on performance, one choice is to increase the amount of labeled training tweets. We have only a small amount of ground-truth, labeled data. However, large amounts of unlabeled data are readily accessible; a day's discourse on Twitter comprises 500 million tweets of unlabeled data <ref type="bibr" target="#b32">(Terdiman, 2012)</ref>. In this scenario, one option is bootstrapping <ref type="bibr" target="#b19">(Goldman and Zhou, 2000;</ref><ref type="bibr" target="#b8">Cucerzan and Yarowsky, 2002</ref>).</p><p>In bootstrapping, the training data is bolstered using semi-supervised data, a "pool" of examples not human curated but labeled automatically. To maintain high data quality, one should only admit to the pool instances in which there is a high confidence. We propose vote-constrained bootstrapping as bootstrapping where not all participating systems (or classifiers) use the same class label inventory. This allows different approaches to the same task to be combined into an ensemble. It is less strict than classic voting, because although both approaches constrain the set of labels that are seen in agreement with each other, classic voting constrains this maximally, to a 1:1 mapping.</p><p>In this scenario, equivalence classes are determined for class labels assigned by systems. Matches occur when all outputs are in the same class, thus only constraining the set of agreeing votes. This permits the constraint of valid responses through voting. The caveat is that at least one voting classifier must use the same class inventory as the eventual trained classifier. Given unlabeled data, the method is for each system to perform feature extraction and then classifications of instances. For instances where all classifiers assign a label in the same equivalence class, the instance may be admitted to the pool, using whichever class label is that belonging to the eventual output system.</p><p>In this instances, our approach is to use T-Pos and the ARK tagger to create semi-supervised data. We used a single tokeniser based on the T-Pos tokenisation scheme (PTB but catering for Twitter specific phenomena such as hashtags). To label the unlabeled data with maximum accuracy, we combined the two taggers, which are trained on different data with different features and different tagsets. The ARK tagger uses a tagset that is generally more coarse-grained than that of T-Pos, and so instead of requiring direct matches between the two taggers' output, the ARK labelings constrain the set of tags that could be considered a match.</p><p>To increase fidelity of data added to the pool, for PoS-tagging, we add a further criterion to the voteconstraint requirement. We define high-confidence instances as those from the tweets where the T-Pos labelings fit within the ARK tagger output's constraints on every token.</p><p>Setup We gathered unlabeled data directly from Twitter using the "garden hose" (a streaming 10% sample of global messages). Tweets were collected, automatically filtered to remove non-English tweets using the language identification of Preotiuc- <ref type="bibr" target="#b29">Pietro et al. (2012)</ref>, tokenised, and then labeled using both taggers. The labelings were compared using manuallypredefined equivalence classes, and if consistent for the whole tweet, the tweet-specific tags re-labeled using regular expressions (see Section 5.2) and the T-Pos tagset labeled tweet added to the pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tagger</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T-eval D-eval Token Sentence</head><p>Token Sentence T-Pos ( <ref type="bibr" target="#b30">Ritter et al., 2011)</ref>   <ref type="table">Table 8</ref>: Performance of our augmented tagger on the held-out evaluation data. ER is error reduction.</p><p>Vote-constraint results We set out to From our unlabeled data, taggers reached agreement on 19.2% of tweets. This reduced an initial capture of 832 135 English tweets (9 523 514 tokens) to 159 492 tweets with agreed PoS labelings (1 542 942 tokens). To see how confident we can be in taggings generated with this method, we checked accuracy of agreed tweets on Tdev. When tested on the T-dev dataset, the taggers agreed on 17.8% of tweets (accounting for 15.2% of tokens). Of the labelings agreed upon over T-dev, these were correct for 97.4% of tokens (71.3% of sentences).</p><p>After an initial dip, adding bootstrapped training data gave a performance increase. <ref type="figure" target="#fig_4">Figure 3</ref> shows the benefit of using vote-constrained bootsrapping, giving 90.54% token accuracy (28.81% for sentences) on Tdev after seeing 1.5M training tokens. The shape of the curve suggests potential benefit from even more bootstrapping data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>We set out to improve part-of-speech tagging on tweets, using the full, rich Penn Treebank set. We made a series of improvements based on observed difficulties with microblog tagging, including the introduction of a bootstrapping technique using labelers that have different tag sets.</p><p>Based on our augmentations, we evaluated against the held-out evaluation sets T-eval and D-eval. Results are in <ref type="table">Table 8</ref>, comparing with T-Pos (the other taggers are far behind as to not warrant direct comparison). Significance is at P&lt;0.01 using the <ref type="bibr" target="#b25">McNemar (1947)</ref> test with Yates' continuity correction.</p><p>Note that we use different evaluation splits in this paper compared to that used in the original T-Pos work. In this paper, training data and evaluation data are always the same across compared systems.</p><p>The augmentations offered significant improvements, which can be both extended (in terms of bootstrapping data, prior-probability lists and slang lists) as well as readily distributed independent of platform. The performance on the development set is even higher, reaching over 90.5% tagging accuracy. Both these tagging accuracies are significantly above anything previously reached on the Penn Treebank tagset. Critically, the large gains in sentence-level accuracy offer significant improvements for real world applications.</p><p>Regarding limits to this particular approach, the technique is likely sensitive to annotator errors given the size of the initial data, and probably limited by inter-annotator agreement. We have partially quantified the linguistic noise this genre presents, but it is still a significant problem -unknown word tagging does not reach nearly as high performance as on e.g. newswire. Finally, the wide variation in forms of expression (possibly encouraged by message length limits) may reduce the frequency of otherwise common phrases, making data harder to generalise over.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Twitter is a text source that offers much, but is difficult to process, partially due to linguistic noise. Additionally, existing approaches suffer from insufficient labeled training data. We introduced approaches for overcoming this noise, for taking advantage of genrespecific structure in tweets, and for generating data through heterogeneous taggers. These combined to provide a readily-distributable and improved part of speech tagger for twitter. Our techniques led to significant reductions in error rate, not only at the token but also at sentence level, and the creation of a 1.5 million token corpus of high-confidence PoS-labeled tweets.</p><p>Resources Presented -Our twitter part-of-speech tagger is available in four forms. First, as a standalone Java program, including handling of slang and prior probabilities. Second, a plugin for the popular language processing framework, GATE <ref type="bibr">(Cunning- ham et al., 2013)</ref>. Third, a model for the Stanford tagger, distributed as a single file, for use in existing applications. Finally, a high-speed model that trades about 2% accuracy for doubled pace. We also provide the bootstrapped corpus and its vote-constraint based creation tool, allowing replication of our results and the construction of new taggers with this large, highconfidence dataset.</p><p>This tagger is now part of the GATE TwitIE toolkit for processing social media text ( ). The tagger and datasets are also distributed via the GATE wiki, at:</p><p>http://gate.ac.uk/wiki/twitter-postagger.html</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Tagger</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Stanford tagger token-level accuracy on Tdev with increasing amounts of microblog training text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Token-level performance on T-dev with varying amounts of WSJ text, in addition to T-train and IRC data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Bootstrapping the tagger using data with vote-constrained labelings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance of Stanford tagger over the de-
velopment dataset T-dev using a combination of three 
genres of training data. 

Category 
Count Proportion 
GS error 
6 
6.7% 
IV 
24 
27.0% 
Pre-taggable 
7 
9.0% 
Proper noun 
10 
11.2% 
Slang 
24 
27.0% 
Tokenisation 
8 
9.0% 
Twitter-specific 
2 
2.2% 
Typo 
7 
7.9% 
Total Result 
89 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Categorisation of mis-tagged unknown words. 

WSJ to 84.19%. Candid analysis suggests that the 
DCU corpus contains less noisy utterances, with bet-
ter grammatical consistency and fewer orthographic er-
rors. 
Based on its strong performance, we concentrate on 
the Stanford tagger for the remainder of this paper. Us-
ing this, we measured the impact that tweet and tweet-
like training data have on PoS tagging accuracy. As 
shown in </table></figure>

			<note place="foot" n="1"> http://www.ark.cs.cmu.edu/TweetNLP/ 2 https://github.com/aritter/twitter nlp</note>

			<note place="foot" n="3"> In fact, as sentence boundaries are at best unclear in many tweets, we use a slightly stricter interpretation of &quot;sentence&quot; and only count entire tweets that are labeled correctly. 4 LDC corpus reference LDC99T42</note>

			<note place="foot" n="5"> An intensifier, from the original &quot;one hell of a ...&quot;. 6 http://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford /nlp/tagger/maxent/ExtractorFramesRare.html 8 The tagger&apos;s naacl2003unk feature set 9 veryCommonWordThresh = 40 10 veryCommonWordThresh = 40, rarewordthreshold = 3</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by funding from UK EPSRC grants EP/K017896/1 the CHIST-ERA uComp project (www.ucomp.eu) and EP/I004327/1. The authors would also like to thank John Bauer of Stanford University for his kind assistance with the Stanford Tagger, and Jennifer Foster of Dublin City University for her generous help with extra labeled data. Finally, the first author thanks Aarhus University for their facilities support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contributions to the study of SMS spam filtering: new collection and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yamakami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM symposium on Document engineering</title>
		<meeting>the 11th ACM symposium on Document engineering</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="259" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The super tweets of #sb47</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ashtari</surname></persName>
		</author>
		<ptr target="http://blog.twitter.com/2013/02/the-super-tweets-of-sb47.html" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Reilly Media Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">TwitIE: A Fully-featured Information Extraction Pipeline for Microblog Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TnT: a statistical part-of-speech tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth conference on Applied Natural Language Processing</title>
		<meeting>the sixth conference on Applied Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="565" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bootstrapping PoS taggers using unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh Conference on Natural Language Learning</title>
		<meeting>the seventh Conference on Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining distributional and morphological information for part of speech induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth conference of the European chapter of the Association for Computational Linguistics</title>
		<meeting>the tenth conference of the European chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bootstrapping a multilingual part-of-speech tagger in one personday</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Natural Language Learning</title>
		<meeting>the 6th Conference on Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards detecting influenza epidemics by analyzing twitter messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Social Media Analytics</title>
		<meeting>the First Workshop on Social Media Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">GATE: an Architecture for Development of Robust HLT Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tablan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics. ACL</title>
		<meeting>the 40th Anniversary Meeting of the Association for Computational Linguistics. ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Getting more out of biomedical documents with gate&apos;s full lifecycle open source text analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tablan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging in noisy and esoteric domains with a syntactic-semantic Bayesian HMM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Darling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference of the European chapter of the Association for Computational Linguistics</title>
		<meeting>the conference of the European chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Microblog-Genre Noise and Impact on Semantic Annotation Accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Conference on Hypertext and Social Media</title>
		<meeting>the 24th ACM Conference on Hypertext and Social Media</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lexical and discourse analysis of online chat dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Martell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Semantic Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Cetinoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Le Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Genabith</surname></persName>
		</author>
		<title level="m">Proceedings of the AAAI Workshop on Analyzing Microtext</title>
		<meeting>the AAAI Workshop on Analyzing Microtext</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>POS Tagging and Parsing the Twitterverse</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adapting a wsj trained part-of-speech tagger to noisy text: preliminary results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gadde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Faruquie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Multilingual OCR and Analytics for Noisy Unstructured Text Data</title>
		<meeting>the Joint Workshop on Multilingual OCR and Analytics for Noisy Unstructured Text Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SVMTool: A general POS tagger generator based on Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Giménez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Language Resources and Evaluation</title>
		<meeting>the 4th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging for twitter: annotation, features, and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Enhancing supervised learning with unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lexical normalisation of short text messages: Makn sens a# twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="368" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Syntactic normalization of twitter messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A broadcoverage normalization system for social media language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging from 97% to 100%: is it time for some linguistics?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="171" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Note on the sampling error of the difference between correlated proportions or percentages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mcnemar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="157" />
			<date type="published" when="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Twitter active users pass 200 million</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Part-of-Speech Tagging for Twitter: Word Clusters and Other Advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<idno>CMU-ML-12-107</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Department</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Emoticon Style: Interpreting Differences in Emoticons Across Cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Barash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Seventh International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="466" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Trendminer: An architecture for real time analysis of social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samangooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gibbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Real-Time Analysis and Mining of Social Streams</title>
		<meeting>the workshop on Real-Time Analysis and Mining of Social Streams</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1524" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Earthquake shakes Twitter users: real-time event detection by social sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World Wide Web (WWW)</title>
		<meeting>the 19th international conference on World Wide Web (WWW)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="851" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Report: Twitter hits half a billion tweets a day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Terdiman</surname></persName>
		</author>
		<ptr target="http://news.cnet.com/8301-10233-57541566-93/report-twitter-hits-half-a-billion-tweets-a-day/" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Feature-rich part-of-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
