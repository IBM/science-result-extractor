As	O
shown	O
in	O
,	O
all	O
DNN	O
-	O
based	O
models	O
achieve	O
significant	O
improvements	O
compared	O
to	O
Random	O
guess	O
and	O
TF	O
-	O
IDF	O
,	O
which	O
implies	O
the	O
effectiveness	O
of	O
DNN	O
models	O
in	O
the	O
task	O
of	O
response	O
selection	O
.	O

IMDB	B-DATASET
and	O
Elec	O
are	O
for	O
sentiment	O
classification	O
(	O
positive	O
vs	O
.	O
negative	O
)	O
of	O
movie	O
reviews	O
and	O
Amazon	O
electronics	O
product	O
reviews	O
,	O
respectively	O
.	O

Several	O
large	O
cloze	O
-	O
style	O
context	O
-	O
question	O
-	O
answer	O
datasets	O
have	O
been	O
introduced	O
recently	O
:	O
the	O
CNN	B-DATASET
and	I-DATASET
Daily	I-DATASET
Mail	I-DATASET
news	I-DATASET
data	I-DATASET
and	O
the	O
Children	B-DATASET
'	I-DATASET
s	I-DATASET
Book	I-DATASET
Test	I-DATASET
.	O

In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
hierarchical	O
recurrent	O
neural	O
network	O
that	O
is	O
capable	O
of	O
extracting	O
information	O
from	O
raw	O
sentences	O
for	O
relation	B-TASK
classification	I-TASK
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
a	O
simple	O
method	O
for	O
common	B-TASK
sense	I-TASK
reasoning	I-TASK
with	O
neural	O
networks	O
,	O
using	O
unsupervised	O
learning	O
.	O

We	O
consider	O
the	O
problem	O
of	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
tagging	I-TASK
for	O
informal	O
,	O
online	O
conversational	O
text	O
.	O

We	O
evaluate	O
our	O
tagger	O
on	O
the	O
NPS	B-DATASET
Chat	I-DATASET
Corpus	I-DATASET
,	I-DATASET
a	I-DATASET
PTB	I-DATASET
-	I-DATASET
part	I-DATASET
-	I-DATASET
of	I-DATASET
-	I-DATASET
speech	I-DATASET
annotated	I-DATASET
dataset	I-DATASET
of	I-DATASET
Internet	I-DATASET
Relay	I-DATASET
Chat	I-DATASET
(	I-DATASET
IRC	I-DATASET
)	I-DATASET
room	I-DATASET
messages	I-DATASET
from	I-DATASET
2006	I-DATASET
.	O

In	O
order	O
to	O
learn	O
models	O
for	O
disambiguating	O
a	O
large	O
set	O
of	O
content	O
words	O
,	O
a	O
high	O
-	O
coverage	O
sense	O
-	O
annotated	O
corpus	O
is	O
required	O
.	O

Tracking	O
the	O
user	O
'	O
s	O
intention	O
throughout	O
the	O
course	O
of	O
a	O
dialog	O
,	O
called	O
dialog	B-TASK
state	I-TASK
tracking	I-TASK
,	O
is	O
an	O
important	O
component	O
of	O
any	O
dialog	O
system	O
.	O

We	O
consider	O
the	O
problem	O
of	O
adapting	O
neural	O
paragraph	B-TASK
-	I-TASK
level	I-TASK
question	I-TASK
answering	I-TASK
models	O
to	O
the	O
case	O
where	O
entire	O
documents	O
are	O
given	O
as	O
input	O
.	O

We	O
evaluate	O
our	O
approach	O
on	O
three	O
datasets	O
:	O
TriviaQA	O
unfiltered	O
(	O
,	O
a	O
dataset	O
of	O
questions	O
from	O
trivia	O
databases	O
paired	O
with	O
documents	O
found	O
by	O
completing	O
a	O
web	O
search	O
of	O
the	O
questions	O
;	O
TriviaQA	O
web	O
,	O
a	O
dataset	O
derived	O
from	O
TriviaQA	O
unfiltered	O
by	O
treating	O
each	O
question	O
document	O
pair	O
where	O
the	O
document	O
contains	O
the	O
question	O
answer	O
as	O
an	O
individual	O
training	O
point	O
;	O
and	O
SQuAD	O
(	O
,	O
a	O
collection	O
of	O
Wikipedia	O
articles	O
and	O
crowdsourced	O
questions	O
.	O

We	O
evaluate	O
our	O
system	O
on	O
two	O
data	O
sets	O
for	O
two	O
sequence	B-TASK
labeling	I-TASK
tasks	O
-	O
Penn	B-DATASET
Treebank	I-DATASET
WSJ	I-DATASET
corpus	I-DATASET
for	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
(	I-TASK
POS	I-TASK
)	I-TASK
tagging	I-TASK
and	O
CoNLL	B-DATASET
2003	I-DATASET
corpus	I-DATASET
for	O
named	B-TASK
entity	I-TASK
recognition	I-TASK
(	I-TASK
NER	I-TASK
)	I-TASK
.	O

Table	O
4	O
:	O
POS	B-TASK
tagging	I-TASK
accuracy	B-METRIC
of	O
our	O
model	O
on	O
test	O
data	O
from	O
WSJ	B-DATASET
proportion	O
of	O
PTB	B-METRIC
,	O
together	O
with	O
top	O
-	O
performance	O
systems	O
.	O

accuracy	B-METRIC
for	O
POS	B-TASK
tagging	I-TASK
and	O
91	O
.	O
21	O
%	O
F1	B-METRIC
for	O
NER	B-TASK

In	O
statistical	B-TASK
relational	I-TASK
learning	I-TASK
,	O
the	O
link	B-TASK
prediction	I-TASK
problem	O
is	O
key	O
to	O
automatically	O
understand	O
the	O
structure	O
of	O
large	O
knowledge	O
bases	O
.	O

Table	O
4	O
.	O
Filtered	B-METRIC
Mean	I-METRIC
Reciprocal	I-METRIC
Rank	I-METRIC
(	I-METRIC
MRR	I-METRIC
)	I-METRIC
for	O
the	O
models	O
tested	O
on	O
each	O
relation	O
of	O
the	O
Wordnet	B-DATASET
dataset	I-DATASET
(	I-DATASET
WN18	I-DATASET
)	I-DATASET
.	O

Based	O
on	O
stack	O
-	O
LSTM	O
,	O
our	O
psycholinguistically	O
motivated	O
constituent	B-TASK
parsing	I-TASK
system	O
achieves	O
91	O
.	O
8	O
F1	B-METRIC
on	O
the	O
WSJ	B-DATASET
benchmark	I-DATASET
.	O

We	O
improve	O
these	O
important	O
aspects	O
of	O
abstractive	B-TASK
summarization	I-TASK
via	O
multi	O
-	O
task	O
learning	O
with	O
the	O
auxiliary	O
tasks	O
of	O
question	B-TASK
generation	I-TASK
and	O
entailment	B-TASK
generation	I-TASK
,	O
where	O
the	O
former	O
teaches	O
the	O
summarization	O
model	O
how	O
to	O
look	O
for	O
salient	O
questioning	O
-	O
worthy	O
details	O
,	O
and	O
the	O
latter	O
teaches	O
the	O
model	O
how	O
to	O
rewrite	O
a	O
summary	O
which	O
is	O
a	O
directed	O
-	O
logical	O
subset	O
of	O
the	O
input	O
document	O
.	O

Table	O
1	O
:	O
CNN	B-DATASET
/	I-DATASET
DailyMail	I-DATASET
summarization	I-DATASET
results	O
.	O

For	O
the	O
Penn	B-DATASET
Treebank	I-DATASET
word	B-TASK
-	I-TASK
level	I-TASK
language	I-TASK
modeling	I-TASK
task	I-TASK
,	O
we	O
report	O
results	O
both	O
with	O
and	O
without	O
weighttying	B-METRIC
(	I-METRIC
WT	I-METRIC
)	I-METRIC
of	O
input	O
and	O
output	O
mappings	O
for	O
fair	O
comparisons	O
.	O

Table	O
1	O
:	O
Validation	O
and	O
test	O
set	O
perplexity	O
of	O
recent	O
state	O
of	O
the	O
art	O
word	O
-	O
level	O
language	O
models	O
on	O
the	O
Penn	B-DATASET
Treebank	I-DATASET
dataset	I-DATASET
.	O

Given	O
two	O
sets	O
of	O
annotations	O
(	O
e	O
.	O
g	O
.	O
,	O
one	O
each	O
from	O
two	O
time	O
normalization	O
systems	O
)	O
,	O
we	O
define	O
the	O
overall	O
precision	B-METRIC
,	O
P	O
,	O
as	O
the	O
average	O
of	O
interval	O
precisions	O
where	O
each	O
annotation	O
from	O
the	O
first	O
set	O
is	O
paired	O
with	O
all	O
annotations	O
that	O
textually	O
overlap	O
it	O
in	O
the	O
second	O
set	O
.	O

This	O
paper	O
presents	O
the	O
first	O
model	O
for	O
time	B-TASK
normalization	I-TASK
trained	O
on	O
the	O
SCATE	B-DATASET
corpus	I-DATASET
.	O

We	O
perform	O
experiments	O
on	O
two	O
tasks	O
:	O
transition	B-TASK
-	I-TASK
based	I-TASK
dependency	I-TASK
parsing	I-TASK
and	O
neural	B-TASK
machine	I-TASK
translation	I-TASK
.	O

Table	O
2	O
:	O
P	O
@	O
N	O
for	O
relation	B-TASK
extraction	I-TASK
using	O
variable	O
number	O
of	O
sentences	O
in	O
bags	O
(	O
with	O
more	O
than	O
one	O
sentence	O
)	O
in	O
Riedel	B-DATASET
dataset	I-DATASET
.	O

Our	O
parser	O
obtained	O
59	O
%	O
Smatch	B-METRIC
on	O
the	O
SemEval	B-DATASET
test	I-DATASET
set	I-DATASET
.	O

Oxford	O
at	O
SemEval	O
-	O
2017	O
Task	O
9	O
:	O
Neural	O
AMR	B-TASK
Parsing	I-TASK
with	O
Pointer	O
-	O
Augmented	O
Attention	O

For	O
AMR	B-TASK
parsing	I-TASK
,	O
our	O
model	O
achieves	O
competitive	O
results	O
of	O
62	O
.	O
1	O
SMATCH	B-METRIC
,	O
the	O
current	O
best	O
score	O
reported	O
without	O
significant	O
use	O
of	O
external	O
semantic	O
resources	O
.	O

We	O
show	O
that	O
these	O
representations	O
can	O
be	O
easily	O
added	O
to	O
existing	O
models	O
and	O
significantly	O
improve	O
the	O
state	O
of	O
the	O
art	O
across	O
six	O
challenging	O
NLP	O
problems	O
,	O
including	O
question	B-TASK
answering	I-TASK
,	O
textual	B-TASK
entailment	I-TASK
and	O
sentiment	B-TASK
analysis	I-TASK
.	O

The	O
fine	B-TASK
-	I-TASK
grained	I-TASK
sentiment	I-TASK
classification	I-TASK
task	O
in	O
the	O
Stanford	B-DATASET
Sentiment	I-DATASET
Treebank	I-DATASET
(	I-DATASET
SST	I-DATASET
-	I-DATASET
5	I-DATASET
;	I-DATASET
Socher	I-DATASET
et	I-DATASET
al	I-DATASET
.	I-DATASET
,	I-DATASET
2013	I-DATASET
)	I-DATASET
involves	O
selecting	O
one	O
of	O
five	O
labels	O
(	O
from	O
very	O
negative	O
to	O
very	O
positive	O
)	O
to	O
describe	O
a	O
sentence	O
from	O
a	O
movie	O
review	O
.	O

A	O
semantic	B-TASK
role	I-TASK
labeling	I-TASK
(	I-TASK
SRL	I-TASK
)	I-TASK
system	O
models	O
the	O
predicate	O
-	O
argument	O
structure	O
of	O
a	O
sentence	O
,	O
and	O
is	O
often	O
described	O
as	O
answering	O
"	O
Who	O
did	O
what	O
to	O
whom	O
"	O
.	O

We	O
apply	O
our	O
method	O
to	O
an	O
image	B-TASK
classification	I-TASK
task	I-TASK
with	O
CIFAR	B-DATASET
-	I-DATASET
10	I-DATASET
and	O
a	O
language	B-TASK
modeling	I-TASK
task	I-TASK
with	O
Penn	B-DATASET
Treebank	I-DATASET
,	O
two	O
of	O
the	O
most	O
benchmarked	O
datasets	O
in	O
deep	O
learning	O
.	O

Table	O
2	O
:	O
Single	O
model	O
perplexity	O
on	O
the	O
test	O
set	O
of	O
the	O
Penn	B-DATASET
Treebank	I-DATASET
language	I-DATASET
modeling	I-DATASET
task	I-DATASET
.	O

We	O
use	O
the	O
English	B-DATASET
coreference	I-DATASET
resolution	I-DATASET
data	I-DATASET
from	I-DATASET
the	I-DATASET
CoNLL	I-DATASET
-	I-DATASET
2012	I-DATASET
shared	I-DATASET
task	I-DATASET
in	O
our	O
experiments	O
.	O

Table	O
2	O
:	O
Dependency	B-TASK
parsing	I-TASK
results	O
for	O
English	O
and	O
Czech	O
.	O

Distantly	B-TASK
supervised	I-TASK
open	I-TASK
-	I-TASK
domain	I-TASK
question	I-TASK
answering	I-TASK
(	I-TASK
DS	I-TASK
-	I-TASK
QA	I-TASK
)	I-TASK
aims	O
to	O
find	O
answers	O
in	O
collections	O
of	O
unlabeled	O
text	O
.	O

Table	O
3	O
:	O
Comparison	O
of	O
F1	B-METRIC
for	O
relation	B-TASK
classification	I-TASK
on	O
SemEval	B-DATASET
-	I-DATASET
2010	I-DATASET
Task	I-DATASET
8	I-DATASET
.	O

In	O
this	O
paper	O
we	O
study	O
the	O
problem	O
of	O
answering	B-TASK
cloze	I-TASK
-	I-TASK
style	I-TASK
questions	I-TASK
over	I-TASK
documents	I-TASK
.	O

We	O
present	O
CATENA	O
,	O
a	O
sieve	O
-	O
based	O
system	O
to	O
perform	O
temporal	B-TASK
and	I-TASK
causal	I-TASK
relation	I-TASK
extraction	I-TASK
and	I-TASK
classification	I-TASK
from	O
English	O
texts	O
,	O
exploiting	O
the	O
interaction	O
between	O
the	O
temporal	O
and	O
the	O
causal	O
model	O
.	O

In	O
this	O
work	O
,	O
we	O
model	O
abstractive	B-TASK
text	I-TASK
summarization	I-TASK
using	O
Attentional	O
Encoder	O
-	O
Decoder	O
Recurrent	O
Neural	O
Networks	O
,	O
and	O
show	O
that	O
they	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
two	O
different	O
corpora	O
.	O

In	O
this	O
paper	O
we	O
benchmark	O
MARN	O
'	O
s	O
understanding	O
of	O
human	O
communication	O
on	O
three	O
tasks	O
:	O
1	O
)	O
multimodal	B-TASK
sentiment	I-TASK
analysis	I-TASK
,	O
2	O
)	O
multimodal	B-TASK
speaker	I-TASK
traits	I-TASK
recognition	I-TASK
and	O
3	O
)	O
multimodal	B-TASK
emotion	I-TASK
recognition	I-TASK
.	O

Our	O
model	O
achieves	O
significant	O
and	O
consistent	O
improvements	O
on	O
relation	B-TASK
extraction	I-TASK
as	O
compared	O
with	O
baselines	O
.	O

We	O
propose	O
a	O
novel	O
neural	O
network	O
model	O
for	O
joint	B-TASK
part	I-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
(	I-TASK
POS	I-TASK
)	I-TASK
tagging	I-TASK
and	O
dependency	B-TASK
parsing	I-TASK
.	O

We	O
also	O
use	O
DUC	B-DATASET
-	I-DATASET
2002	I-DATASET
,	O
which	O
is	O
also	O
a	O
long	O
-	O
paragraph	O
summarization	O
dataset	O
of	O
news	O
articles	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
variety	O
of	O
Long	O
Short	O
-	O
Term	O
Memory	O
(	O
LSTM	O
)	O
based	O
models	O
for	O
sequence	B-TASK
tagging	I-TASK
.	O

Table	O
2	O
:	O
Comparison	O
of	O
tagging	B-TASK
performance	O
on	O
POS	O
,	O
chunking	O
and	O
NER	O
tasks	O
for	O
various	O
models	O
.	O

We	O
show	O
that	O
adding	O
these	O
context	O
vectors	O
(	O
CoVe	O
)	O
improves	O
performance	O
over	O
using	O
only	O
unsupervised	O
word	O
and	O
character	O
vectors	O
on	O
a	O
wide	O
variety	O
of	O
common	O
NLP	O
tasks	O
:	O
sentiment	B-TASK
analysis	I-TASK
(	I-TASK
SST	I-TASK
,	O
IMDb	O
)	O
,	O
question	B-TASK
classification	I-TASK
(	I-TASK
TREC	I-TASK
)	I-TASK
,	O
entailment	O
(	O
SNLI	O
)	O
,	O
and	O
question	B-TASK
answering	I-TASK
(	I-TASK
SQuAD	I-TASK
)	I-TASK
.	O

We	O
train	O
our	O
model	O
separately	O
on	O
two	O
sentiment	O
analysis	O
datasets	O
:	O
the	O
Stanford	B-DATASET
Sentiment	I-DATASET
Treebank	I-DATASET
(	I-DATASET
SST	I-DATASET
)	I-DATASET
and	O
the	O
IMDb	B-DATASET
dataset	I-DATASET
.	O

In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
model	O
on	O
the	O
task	O
of	O
question	B-TASK
answering	I-TASK
using	O
the	O
recently	O
released	O
SQuAD	O
.	O

The	O
experimental	O
results	O
on	O
the	O
SemEval	B-TASK
-	I-TASK
2010	I-TASK
relation	I-TASK
classification	I-TASK
task	I-TASK
show	O
that	O
our	O
method	O
outperforms	O
most	O
of	O
the	O
existing	O
methods	O
,	O
with	O
only	O
word	O
vectors	O
.	O

Table	O
3	O
:	O
AMR	B-TASK
parsing	I-TASK
Smatch	O
scores	O
for	O
the	O
experiments	O
in	O
this	O
work	O
.	O

Specifically	O
,	O
one	O
of	O
the	O
proposed	O
models	O
achieves	O
highest	O
accuracy	B-METRIC
on	O
Stanford	O
Sentiment	B-TASK
Treebank	I-TASK
binary	I-TASK
classification	I-TASK
and	O
fine	B-TASK
-	I-TASK
grained	I-TASK
classification	I-TASK
tasks	O
.	O

Previously	O
,	O
neural	O
methods	O
in	O
grammatical	B-TASK
error	I-TASK
correction	I-TASK
(	I-TASK
GEC	I-TASK
)	I-TASK
did	O
not	O
reach	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
compared	O
to	O
phrase	B-TASK
-	I-TASK
based	I-TASK
statistical	I-TASK
machine	I-TASK
translation	I-TASK
(	I-TASK
SMT	I-TASK
)	I-TASK
baselines	O
.	O

We	O
used	O
IMDB	B-DATASET
,	O
Elec	O
,	O
and	O
RCV1	O
for	O
our	O
semi	O
-	O
supervised	O
experiments	O
.	O

We	O
used	O
four	O
datasets	O
:	O
IMDB	O
,	O
Elec	O
,	O
RCV1	O
(	O
second	O
-	O
level	O
topics	O
)	O
,	O
and	O
20	O
-	O
newsgroup	O
(	O
20NG	O
)	O
3	O
,	O
to	O
facilitate	O
direct	O
comparison	O
with	O
JZ15	B-DATASET
and	O
DL15	O
.	O

Experimental	O
results	O
on	O
the	O
SemEval	B-DATASET
-	I-DATASET
2010	I-DATASET
Task	I-DATASET
8	I-DATASET
dataset	I-DATASET
demonstrate	O
that	O
our	O
model	O
is	O
comparable	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
without	O
using	O
any	O
hand	O
-	O
crafted	O
features	O
.	O

In	O
our	O
experiments	O
,	O
we	O
evaluate	O
our	O
model	O
on	O
the	O
SemEval	B-DATASET
-	I-DATASET
2010	I-DATASET
Task	I-DATASET
8	I-DATASET
dataset	I-DATASET
,	O
which	O
is	O
one	O
of	O
the	O
most	O
widely	O
used	O
benchmarks	O
for	O
relation	B-TASK
classification	I-TASK
.	O

We	O
conduct	O
experiments	O
to	O
evaluate	O
our	O
methods	O
on	O
two	O
tasks	O
:	O
Pronoun	B-TASK
Disambiguation	I-TASK
Problems	O
and	O
Winograd	O
Schema	O
Challenge	O
.	O

Table	O
5	O
:	O
Accuracy	B-METRIC
on	O
Winograd	B-DATASET
Schema	I-DATASET
Challenge	I-DATASET
,	O
making	O
use	O
of	O
STORIES	B-DATASET
corpus	I-DATASET
.	O

IRC	B-DATASET
is	O
another	O
medium	O
of	O
online	O
conversational	O
text	O
,	O
with	O
similar	O
emoticons	O
,	O
misspellings	O
,	O
abbreviations	O
and	O
acronyms	O
as	O
Twitter	O
data	O
.	O

Table	O
5	O
:	O
F1	B-METRIC
performance	O
of	O
different	O
models	O
on	O
the	O
Senseval	B-DATASET
-	I-DATASET
2	I-DATASET
English	I-DATASET
Lexical	I-DATASET
Sample	I-DATASET
task	I-DATASET
.	O

Tracking	O
the	O
user	O
'	O
s	O
intention	O
throughout	O
the	O
course	O
of	O
a	O
dialog	O
,	O
called	O
dialog	B-TASK
state	I-TASK
tracking	I-TASK
,	O
is	O
an	O
important	O
component	O
of	O
any	O
dialog	O
system	O
.	O

We	O
evaluate	O
our	O
system	O
on	O
two	O
data	O
sets	O
for	O
two	O
sequence	B-TASK
labeling	I-TASK
tasks	O
-	O
Penn	B-DATASET
Treebank	I-DATASET
WSJ	I-DATASET
corpus	I-DATASET
for	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
(	I-TASK
POS	I-TASK
)	I-TASK
tagging	I-TASK
and	O
CoNLL	B-DATASET
2003	I-DATASET
corpus	I-DATASET
for	O
named	B-TASK
entity	I-TASK
recognition	I-TASK
(	I-TASK
NER	I-TASK
)	I-TASK
.	O

Table	O
4	O
.	O
Filtered	B-METRIC
Mean	I-METRIC
Reciprocal	I-METRIC
Rank	I-METRIC
(	I-METRIC
MRR	I-METRIC
)	I-METRIC
for	O
the	O
models	O
tested	O
on	O
each	O
relation	O
of	O
the	O
Wordnet	B-DATASET
dataset	I-DATASET
(	I-DATASET
WN18	I-DATASET
)	I-DATASET
.	O

Table	O
2	O
.	O
Filtered	B-METRIC
and	I-METRIC
Raw	I-METRIC
Mean	I-METRIC
Reciprocal	I-METRIC
Rank	I-METRIC
(	I-METRIC
MRR	I-METRIC
)	I-METRIC
for	O
the	O
models	O
tested	O
on	O
the	O
FB15K	B-DATASET
and	O
WN18	B-DATASET
datasets	I-DATASET
.	O

Table	O
2	O
:	O
f	O
-	O
scores	O
from	O
evaluating	O
the	O
rerank	O
-	O
ing	O
parser	O
on	O
three	O
held	O
-	O
out	O
sections	O
after	O
adding	O
reranked	O
sentences	O
from	O
NANC	O
to	O
WSJ	B-DATASET
training	O
.	O

We	O
evaluate	O
the	O
proposed	O
method	O
on	O
Senseval	O
-	O
2	O
,	O
Senseval	B-DATASET
-	I-DATASET
3	I-DATASET
,	O
SemEval	O
-	O
2007	O
,	O
SemEval	O
-	O
2013	O
and	O
SemEval	B-DATASET
-	I-DATASET
2015	I-DATASET
English	I-DATASET
All	I-DATASET
-	I-DATASET
Word	I-DATASET
WSD	I-DATASET
datasets	I-DATASET
and	O
show	O
that	O
it	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
unsupervised	O
knowledge	O
-	O
based	O
WSD	B-TASK
system	O
by	O
a	O
significant	O
margin	O
.	O

Table	O
3	O
:	O
Entropy	B-METRIC
in	I-METRIC
Bits	I-METRIC
Per	I-METRIC
Character	I-METRIC
(	I-METRIC
BPC	I-METRIC
)	I-METRIC
on	O
the	O
text8	B-DATASET
test	I-DATASET
set	I-DATASET
(	O
results	O
under	O
1	O
.	O
5	O
BPC	O
&	O
without	O
dynamic	O
evaluation	O
)	O
.	O

We	O
train	O
and	O
evaluate	O
our	O
models	O
on	O
the	O
SCATE	B-DATASET
corpus	I-DATASET
described	O
in	O
Section	O
4	O
.	O

Experimental	O
results	O
show	O
that	O
our	O
method	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
on	O
the	O
SemEval	B-DATASET
-	I-DATASET
2010	I-DATASET
Task	I-DATASET
8	I-DATASET
dataset	I-DATASET
.	O

We	O
train	O
our	O
models	O
with	O
the	O
two	O
AMR	O
datasets	O
provided	O
for	O
the	O
shared	O
task	O
:	O
LDC2016E25	O
,	O
a	O
large	O
corpus	O
of	O
newswire	O
,	O
weblog	O
and	O
discussion	O
forum	O
text	O
with	O
a	O
training	O
set	O
of	O
35	O
,	O
498	O
sentences	O
,	O
and	O
a	O
smaller	O
dataset	O
in	O
the	O
biomedical	O
domain	O
(	O
Bio	B-DATASET
AMR	I-DATASET
Corpus	I-DATASET
)	I-DATASET
with	O
5	O
,	O
542	O
training	O
sentences	O
.	O

Evaluation	O
was	O
performed	O
on	O
the	O
well	O
-	O
established	O
CoNLL	B-DATASET
-	I-DATASET
2003	I-DATASET
NER	I-DATASET
shared	I-DATASET
task	I-DATASET
dataset	I-DATASET
)	O
and	O
the	O
much	O
larger	O
but	O
less	O
-	O
studied	O
OntoNotes	B-DATASET
5	I-DATASET
.	I-DATASET
0	I-DATASET
dataset	I-DATASET
.	O

In	O
this	O
section	O
,	O
we	O
conduct	O
several	O
experiments	O
on	O
two	O
public	O
DA	O
datasets	O
SwDA	O
and	O
MRDA	O
,	O
and	O
show	O
the	O
effectiveness	O
of	O
our	O
approach	O
CRF	O
-	O
ASN	O
for	O
dialogue	B-TASK
act	I-TASK
recognition	I-TASK
.	O

The	O
parser	O
achieves	O
the	O
best	O
reported	O
results	O
on	O
the	O
standard	O
benchmark	O
(	O
74	O
.	O
4	O
%	O
on	O
LDC2016E25	O
)	O
.	O

To	O
evaluate	O
the	O
performance	O
of	O
our	O
proposed	O
method	O
,	O
we	O
use	O
the	O
SemEval	B-DATASET
-	I-DATASET
2010	I-DATASET
Task	I-DATASET
8	I-DATASET
dataset	I-DATASET
.	O

We	O
show	O
that	O
this	O
improves	O
tracking	O
of	O
rare	O
states	O
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
WoZ	B-DATASET
and	O
DSTC2	B-TASK
state	I-TASK
tracking	I-TASK
tasks	O
.	O

In	O
our	O
experiments	O
,	O
we	O
evaluate	O
the	O
VNER	O
model	O
on	O
two	O
benchmark	O
datasets	O
for	O
Vietnamese	O
NER	B-TASK
which	O
are	O
VLSP	B-TASK
-	I-TASK
2016	I-TASK
NER	I-TASK
task	I-TASK
and	O
VLSP	B-TASK
-	I-TASK
2018	I-TASK
NER	I-TASK
task	I-TASK
.	O

In	O
addition	O
to	O
the	O
model	O
,	O
we	O
release	O
WikiSQL	O
,	O
a	O
dataset	O
of	O
80654	O
hand	O
-	O
annotated	O
examples	O
of	O
questions	O
and	O
SQL	O
queries	O
distributed	O
across	O
24241	O
tables	O
from	O
Wikipedia	O
that	O
is	O
an	O
order	O
of	O
magnitude	O
larger	O
than	O
comparable	O
datasets	O
.	O

To	O
create	O
a	O
dataset	O
without	O
this	O
property	O
,	O
Toutanova	O
and	O
Chen	O
(	O
2015	O
)	O
introduced	O
FB15k	B-DATASET
-	I-DATASET
237	I-DATASET
-	O
a	O
subset	O
of	O
FB15k	B-DATASET
where	O
inverse	O
relations	O
are	O
removed	O
.	O

For	O
fair	O
comparison	O
,	O
we	O
use	O
the	O
benchmark	O
datasets	O
proposed	O
by	O
which	O
includes	O
five	O
standard	O
all	O
-	O
words	O
fine	O
-	O
grained	O
WSD	B-DATASET
datasets	I-DATASET
from	I-DATASET
the	I-DATASET
Senseval	I-DATASET
and	O
SemEval	O
competitions	O
.	O

They	O
are	O
Senseval	O
-	O
2	O
(	O
SE2	O
)	O
,	O
Senseval	O
-	O
3	O
task	O
1	O
(	O
SE3	O
)	O
,	O
SemEval	O
-	O
07	O
task	O
17	O
(	O
SE7	O
)	O
,	O
SemEval	O
-	O
13	O
task	O
12	O
(	O
SE13	O
)	O
,	O
and	O
SemEval	B-TASK
-	I-TASK
15	I-TASK
task	I-TASK
13	I-TASK
(	O
SE15	O
)	O
.	O

For	O
instance	O
,	O
we	O
achieve	O
absolute	O
improvements	O
of	O
8	O
.	O
9	O
%	O
on	O
commonsense	B-TASK
reasoning	I-TASK
(	O
Stories	B-DATASET
Cloze	I-DATASET
Test	I-DATASET
)	I-DATASET
,	O
5	O
.	O
7	O
%	O
on	O
question	B-TASK
answering	I-TASK
(	I-TASK
RACE	I-TASK
)	I-TASK
,	O
and	O
1	O
.	O
5	O
%	O
on	O
textual	O
entailment	O
(	O
MultiNLI	O
)	O
.	O

Our	O
model	O
achieves	O
28	O
.	O
4	O
BLEU	B-METRIC
on	O
the	O
WMT	B-TASK
2014	I-TASK
English	I-TASK
-	I-TASK
to	I-TASK
-	I-TASK
German	I-TASK
translation	I-TASK
task	I-TASK
,	O
improving	O
over	O
the	O
existing	O
best	O
results	O
,	O
including	O
ensembles	O
,	O
by	O
over	O
2	O
BLEU	B-METRIC
.	O

Accuracy	O
on	O
3	O
-	O
class	O
prediction	O
about	O
SemEval	B-TASK
2014	I-TASK
Task	I-TASK
4	I-TASK
which	O
includes	O
restaurants	O
and	O
laptops	O
.	O

The	O
SemEval	B-DATASET
2014	I-DATASET
dataset	I-DATASET
is	O
composed	O
of	O
reviews	O
in	O
two	O
categories	O
:	O
Restaurant	O
and	O
Laptop	O
.	O

This	O
paper	O
provides	O
evidence	O
that	O
the	O
use	O
of	O
more	O
unlabeled	O
data	O
in	O
semi	O
-	O
supervised	O
learning	O
can	O
improve	O
the	O
performance	O
of	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
tasks	O
,	O
such	O
as	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
tagging	I-TASK
,	O
syntactic	B-TASK
chunking	I-TASK
,	O
and	O
named	B-TASK
entity	I-TASK
recognition	I-TASK
.	O

Then	O
,	O
we	O
describe	O
experiments	O
performed	O
on	O
widely	O
used	O
test	O
collections	O
,	O
namely	O
,	O
PTB	B-DATASET
III	I-DATASET
data	I-DATASET
,	O
CoNLL	B-DATASET
'	I-DATASET
00	I-DATASET
and	O
'	O
03	O
shared	O
task	O
data	O
for	O
the	O
above	O
three	O
NLP	O
tasks	O
,	O
respectively	O
.	O

This	O
paper	O
describes	O
300	O
-	O
sparsans	O
'	O
participation	O
in	O
SemEval	B-TASK
-	I-TASK
2018	I-TASK
Task	I-TASK
9	I-TASK
:	O
Hypernym	B-TASK
Discovery	I-TASK
,	O
with	O
a	O
system	O
based	O
on	O
sparse	O
coding	O
and	O
a	O
formal	O
concept	O
hierarchy	O
obtained	O
from	O
word	O
embeddings	O
.	O

This	O
paper	O
presents	O
the	O
participation	O
of	O
Apollo	O
'	O
s	O
team	O
in	O
the	O
SemEval	B-TASK
-	I-TASK
2018	I-TASK
Task	I-TASK
9	I-TASK
"	I-TASK
Hypernym	I-TASK
Discovery	I-TASK
"	I-TASK
,	O
Subtask	O
1	O
:	O
"	O
Gen	O
-	O
eral	O
-	O
Purpose	O
Hypernym	O
Discovery	O
"	O
,	O
which	O
tries	O
to	O
produce	O
a	O
ranked	O
list	O
of	O
hypernyms	O
for	O
a	O
specific	O
term	O
.	O

For	O
MRPC	O
and	O
STSB	O
we	O
consider	O
only	O
the	O
F1	B-METRIC
score	I-METRIC
and	O
Spearman	O
correlations	O
respectively	O
and	O
we	O
also	O
multiply	O
the	O
SICK	B-METRIC
-	I-METRIC
R	I-METRIC
scores	O
by	O
100	O
to	O
have	O
all	O
differences	O
in	O
the	O
same	O
scale	O
.	O

We	O
propose	O
a	O
simple	O
and	O
effective	O
method	O
to	O
address	O
this	O
issue	O
,	O
and	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
perplexities	O
on	O
Penn	B-DATASET
Treebank	I-DATASET
and	O
WikiText	B-DATASET
-	I-DATASET
2	I-DATASET
to	O
47	O
.	O
69	O
and	O
40	O
.	O
68	O
respectively	O
.	O

It	O
obtains	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
eleven	O
natural	O
language	O
processing	O
tasks	O
,	O
including	O
pushing	O
the	O
GLUE	O
benchmark	O
to	O
80	O
.	O
4	O
%	O
(	O
7	O
.	O
6	O
%	O
absolute	O
improvement	O
)	O
,	O
MultiNLI	O
accuracy	B-METRIC
to	O
86	O
.	O
7	O
%	O
(	O
5	O
.	O
6	O
%	O
absolute	O
improvement	O
)	O
and	O
the	O
SQuAD	B-DATASET
v1	I-DATASET
.	I-DATASET
1	I-DATASET
question	I-DATASET
answering	I-DATASET
Test	I-DATASET
F1	I-DATASET
to	O
93	O
.	O
2	O
(	O
1	O
.	O
5	O
absolute	O
improvement	O
)	O
,	O
outperforming	O
human	O
performance	O
by	O
2	O
.	O
0	O
.	O

We	O
conduct	O
all	O
experiments	O
on	O
the	O
AMR	B-DATASET
corpus	I-DATASET
used	I-DATASET
in	I-DATASET
SemEval	I-DATASET
-	I-DATASET
2016	I-DATASET
Task	I-DATASET
8	I-DATASET
(	I-DATASET
LDC2015E86	I-DATASET
)	I-DATASET
,	O
which	O
contains	O
16	O
,	O
833	O
/	O
1	O
,	O
368	O
/	O
1	O
,	O
371	O
train	O
/	O
dev	O
/	O
test	O
examples	O
.	O

Additionally	O
,	O
we	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
SoTA	O
)	O
results	O
of	O
bpc	O
/	O
perplexity	O
from	O
1	O
.	O
06	O
to	O
0	O
.	O
99	O
on	O
enwiki8	B-DATASET
,	O
from	O
1	O
.	O
13	O
to	O
1	O
.	O
08	O
on	O
text8	B-DATASET
,	O
from	O
20	O
.	O
5	O
to	O
18	O
.	O
3	O
on	O
WikiText	B-DATASET
-	I-DATASET
103	I-DATASET
,	O
from	O
23	O
.	O
7	O
to	O
21	O
.	O
8	O
on	O
One	B-DATASET
Billion	I-DATASET
Word	I-DATASET
,	O
and	O
from	O
55	O
.	O
3	O
to	O
54	O
.	O
5	O
on	O
Penn	B-DATASET
Treebank	I-DATASET
(	O
without	O
finetuning	O
)	O
.	O

Finally	O
,	O
DCU	O
-	O
LSTM	O
significantly	O
outperforms	O
all	O
models	O
in	O
terms	O
of	O
ROUGE	B-METRIC
-	I-METRIC
L	I-METRIC
,	O
including	O
BiDAF	B-METRIC
on	O
this	O
dataset	O
.	O

There	O
are	O
two	O
subsets	O
of	O
RACE	O
,	O
namely	O
RACE	O
-	O
M	O
(	O
Middle	O
school	O
)	O
and	O
RACE	B-METRIC
-	I-METRIC
H	I-METRIC
(	O
High	O
school	O
)	O
.	O

We	O
also	O
propose	O
the	O
AUC	B-METRIC
(	O
area	O
under	O
the	O
ROC	O
curve	O
)	O
metric	O
for	O
both	O
aspect	O
and	O
sentiment	B-TASK
detection	I-TASK
tasks	I-TASK
.	O

The	O
numbers	O
in	O
the	O
y	O
-	O
axes	O
are	O
accuracies	O
for	O
POS	B-TASK
tagging	I-TASK
,	O
and	O
chunk	B-METRIC
-	I-METRIC
level	I-METRIC
F1	I-METRIC
scores	I-METRIC
for	O
chunking	O
and	O
NER	B-TASK
.	O

We	O
report	O
ROUGE	B-METRIC
-	I-METRIC
1	I-METRIC
(	I-METRIC
R1	I-METRIC
)	I-METRIC
,	O
ROUGE	B-METRIC
-	I-METRIC
2	I-METRIC
(	I-METRIC
R2	I-METRIC
)	I-METRIC
,	O
and	O
ROUGE	B-METRIC
-	I-METRIC
L	I-METRIC
(	I-METRIC
RL	I-METRIC
)	I-METRIC
F1	I-METRIC
scores	I-METRIC
.	O

Our	O
parser	O
gets	O
state	O
of	O
the	O
art	O
or	O
near	O
state	O
of	O
the	O
art	O
performance	O
on	O
standard	O
treebanks	O
for	O
six	O
different	O
languages	O
,	O
achieving	O
95	O
.	O
7	O
%	O
UAS	B-METRIC
and	O
94	O
.	O
1	O
%	O
LAS	B-METRIC
on	O
the	O
most	O
popular	O
English	B-DATASET
PTB	I-DATASET
dataset	I-DATASET
.	O

Table	O
3	O
:	O
AMR	B-TASK
parsing	I-TASK
performance	O
on	O
the	O
news	B-DATASET
wire	I-DATASET
test	I-DATASET
set	I-DATASET
of	I-DATASET
LDC2013E117	I-DATASET
.	O

shows	O
an	O
example	O
of	O
this	O
word	B-TASK
overlap	I-TASK
problem	O
from	O
the	O
NTCIR	B-DATASET
-	I-DATASET
8	I-DATASET
ACLIA2	I-DATASET
Japanese	I-DATASET
question	I-DATASET
answering	I-DATASET
test	I-DATASET
collection	I-DATASET
.	O

Methods	O
based	O
on	O
word	O
strings	O
(	O
e	O
.	O
g	O
.	O
,	O
BLEU	B-METRIC
(	O
)	O
,	O
NIST	O
)	O
,	O
METEOR	B-METRIC
(	O
)	O
,	O
ROUGE	B-METRIC
-	I-METRIC
L	I-METRIC
(	O
)	O
,	O
and	O
IMPACT	O
)	O
calculate	O
matching	O
scores	O
using	O
only	O
common	O
words	O
between	O
MT	O
outputs	O
and	O
references	O
from	O
bilingual	O
humans	O
.	O

The	O
system	O
based	O
on	O
our	O
method	O
obtained	O
the	O
evaluation	O
scores	O
for	O
1	O
,	O
200	O
English	O
output	O
sentences	O
related	O
to	O
the	O
patent	O
sentences	O
.	O

Moreover	O
,	O
three	O
human	O
judges	O
evaluated	O
1	O
,	O
200	O
English	O
output	O
sentences	O
from	O
the	O
perspective	O
of	O
adequacy	O
and	O
fluency	O
on	O
a	O
scale	O
of	O
1	O
-	O
5	O
.	O

Experimental	O
results	O
on	O
large	O
scale	O
data	O
show	O
that	O
the	O
proposed	O
approach	O
improves	O
upon	O
existing	O
methods	O
in	O
terms	O
of	O
accuracy	B-METRIC
in	O
different	O
settings	O
.	O
.	O

There	O
are	O
two	O
fundamental	O
problems	O
in	O
research	O
on	O
approximate	B-TASK
string	I-TASK
search	I-TASK
:	O
(	O
1	O
)	O
how	O
to	O
build	O
a	O
model	O
that	O
can	O
archive	O
both	O
high	O
accuracy	B-METRIC
and	O
efficiency	O
,	O
and	O
(	O
2	O
)	O
how	O
to	O
develop	O
a	O
data	O
structure	O
and	O
algorithm	O
that	O
can	O
facilitate	O
efficient	O
retrieval	O
of	O
the	O
top	O
k	O
candidates	O
.	O

However	O
,	O
the	O
drop	O
of	O
accuracy	B-METRIC
by	O
our	O
method	O
is	O
much	O
smaller	O
than	O
that	O
by	O
generative	O
,	O
which	O
means	O
our	O
method	O
is	O
more	O
powerful	O
when	O
the	O
vocabulary	O
is	O
large	O
,	O
e	O
.	O
g	O
.	O
,	O
for	O
web	O
search	O
.	O

Syntax	B-TASK
-	I-TASK
to	I-TASK
-	I-TASK
Morphology	I-TASK
Mapping	I-TASK
in	I-TASK
Factored	I-TASK
Phrase	I-TASK
-	I-TASK
Based	I-TASK
Statistical	I-TASK
Machine	I-TASK
Translation	I-TASK
from	O
English	O
to	O
Turkish	O

Our	O
approach	O
relies	O
on	O
syntactic	O
analysis	O
on	O
the	O
source	O
side	O
(	O
English	O
)	O
and	O
then	O
encodes	O
a	O
wide	O
variety	O
of	O
local	O
and	O
non	O
-	O
local	O
syntactic	O
structures	O
as	O
complex	O
structural	O
tags	O
which	O
appear	O
as	O
additional	O
factors	O
in	O
the	O
training	O
data	O
.	O

On	O
the	O
target	O
side	O
(	O
Turkish	O
)	O
,	O
we	O
only	O
perform	O
morphological	O
analysis	O
and	O
disam	O
-	O
biguation	O
but	O
treat	O
the	O
complete	O
complex	O
morphological	O
tag	O
as	O
a	O
factor	O
,	O
instead	O
of	O
separating	O
morphemes	O
.	O

Earlier	O
work	O
on	O
translation	B-TASK
from	I-TASK
English	I-TASK
to	O
Turkish	O
has	O
used	O
an	O
approach	O
which	O
relied	O
on	O
identifying	O
the	O
contextually	O
correct	O
parts	O
-	O
of	O
-	O
speech	O
,	O
roots	O
and	O
any	O
morphemes	O
on	O
the	O
English	O
side	O
,	O
and	O
the	O
complete	O
sequence	O
of	O
roots	O
and	O
overt	O
derivational	O
and	O
inflectional	O
morphemes	O
for	O
each	O
word	O
on	O
the	O
Turkish	O
side	O
.	O

Ave	O
:	O
BLEU	B-METRIC
scores	O
of	O
after	O
reordering	O
transformations	O
Factored	O
phrase	O
-	O
based	O
SMT	B-TASK
allows	O
the	O
use	O
of	O
multiple	O
language	O
models	O
for	O
the	O
target	O
side	O
,	O
for	O
different	O
factors	O
during	O
decoding	O
.	O

We	O
used	O
the	O
English	O
portion	O
of	O
the	O
TDT5	B-DATASET
corpora	I-DATASET
(	I-DATASET
LDC2006T18	I-DATASET
)	I-DATASET
as	O
our	O
unlabeled	O
data	O
for	O
inducing	O
word	O
clusters	O
.	O

For	O
relation	B-TASK
extraction	I-TASK
,	O
we	O
used	O
the	O
benchmark	O
ACE	B-DATASET
2004	I-DATASET
training	I-DATASET
data	I-DATASET
.	O

Preprocessing	O
of	O
the	O
ACE	O
documents	O
:	O
We	O
used	O
the	O
Stanford	O
parser	O
6	O
for	O
syntactic	O
and	O
dependency	B-TASK
parsing	I-TASK
.	O

We	O
present	O
a	O
novel	O
approach	O
to	O
the	O
automatic	O
acquisition	O
of	O
a	O
Verbnet	O
like	O
classification	O
of	O
French	O
verbs	O
which	O
involves	O
the	O
use	O
(	O
i	O
)	O
of	O
a	O
neural	O
clustering	O
method	O
which	O
associates	O
clusters	O
with	O
features	O
,	O
(	O
ii	O
)	O
of	O
several	O
supervised	O
and	O
unsupervised	O
evaluation	O
metrics	O
and	O
(	O
iii	O
)	O
of	O
various	O
existing	O
syntactic	O
and	O
semantic	O
lexical	O
resources	O
.	O

While	O
there	O
has	O
been	O
much	O
work	O
on	O
automatically	O
acquiring	O
verb	O
classes	O
for	O
English	O
(	O
and	O
to	O
a	O
lesser	O
extent	O
for	O
German	O
(	O
;	O
Schulte	O
im	O
)	O
,	O
Japanese	O
)	O
and	O
Italian	O
(	O
)	O
,	O
few	O
studies	O
have	O
been	O
conducted	O
on	O
the	O
automatic	O
classification	O
of	O
French	O
verbs	O
.	O

We	O
show	O
that	O
the	O
approach	O
yields	O
promising	O
results	O
(	O
F	B-METRIC
-	I-METRIC
measure	I-METRIC
of	O
70	O
%	O
)	O
and	O
that	O
the	O
clustering	O
produced	O
systematically	O
associates	O
verbs	O
with	O
syntactic	O
frames	O
and	O
thematic	O
grids	O
thereby	O
providing	O
an	O
interesting	O
basis	O
for	O
the	O
creation	O
and	O
evaluation	O
of	O
a	O
Verbnet	O
-	O
like	O
classification	O
.	O

With	O
the	O
development	O
of	O
Web	O
2	O
.	O
0	O
,	O
community	B-TASK
question	I-TASK
answering	I-TASK
(	I-TASK
CQA	I-TASK
)	I-TASK
services	O
like	O
Yahoo	O
!	O

Although	O
exploited	O
bilingual	O
translation	O
for	O
question	B-TASK
retrieval	I-TASK
and	O
obtained	O
the	O
better	O
performance	O
than	O
traditional	O
monolingual	O
translation	O
models	O
.	O

Evaluation	O
Metrics	O
:	O
We	O
evaluate	O
the	O
performance	O
of	O
question	B-TASK
retrieval	I-TASK
using	O
the	O
following	O
metrics	O
:	O
Mean	B-METRIC
Average	I-METRIC
Precision	I-METRIC
(	I-METRIC
MAP	I-METRIC
)	I-METRIC
and	O
.	O

sentences	O
and	O
part	O
-	O
of	O
-	O
speech	O
tags	O
)	O
,	O
and	O
is	O
much	O
cheaper	O
than	O
the	O
syntactically	O
annotated	O
data	O
required	O
for	O
supervised	O
training	O
.	O

However	O
,	O
because	O
the	O
model	O
is	O
formulated	O
within	O
the	O
Adaptor	O
Grammar	O
framework	O
,	O
the	O
time	O
complexity	O
of	O
its	O
inference	O
algorithm	O
is	O
cubic	O
in	O
the	O
length	O
of	O
each	O
text	O
fragment	O
,	O
and	O
so	O
it	O
is	O
not	O
feasible	O
to	O
apply	O
the	O
AG	O
-	O
colloc	O
model	O
to	O
large	O
collections	O
of	O
text	O
documents	O
.	O

In	O
the	O
classification	B-TASK
task	I-TASK
,	O
we	O
used	O
three	O
datasets	O
:	O
the	O
movie	B-DATASET
review	I-DATASET
dataset	I-DATASET
(	I-DATASET
Pang	I-DATASET
and	I-DATASET
Lee	I-DATASET
,	I-DATASET
2012	I-DATASET
)	I-DATASET
(	O
MReviews	B-DATASET
)	I-DATASET
,	O
the	O
20	B-DATASET
Newsgroups	I-DATASET
dataset	I-DATASET
,	O
and	O
the	O
Reuters	B-DATASET
-	I-DATASET
21578	I-DATASET
dataset	I-DATASET
.	O

The	O
20	B-DATASET
Newsgroups	I-DATASET
dataset	I-DATASET
is	O
organised	O
:	O
Comparison	O
of	O
all	O
models	O
in	O
the	O
classification	B-TASK
task	I-TASK
(	O
accuracy	B-METRIC
in	O
%	O
)	O
and	O
the	O
information	B-TASK
retrieval	I-TASK
task	I-TASK
(	O
MAP	O
scores	O
in	O
%	O
)	O
on	O
small	O
corpora	O
.	O

The	O
AG	O
-	O
colloc	O
model	O
yields	O
the	O
highest	O
classification	B-TASK
accuracy	B-METRIC
,	O
and	O
our	O
TCM	O
with	O
/	O
without	O
sparsity	O
performs	O
as	O
well	O
as	O
the	O
AG	O
-	O
colloc	O
model	O
according	O
to	O
the	O
Wilcoxon	O
signed	O
rank	O
test	O
.	O

shows	O
the	O
classification	B-TASK
accuracy	B-METRIC
of	O
those	O
three	O
models	O
on	O
the	O
larger	O
datasets	O
,	O
i	O
.	O
e	O
.	O
,	O
the	O
20	B-DATASET
Newsgroups	I-DATASET
dataset	I-DATASET
,	O
and	O
the	O
Reuters	B-DATASET
-	I-DATASET
21578	I-DATASET
dataset	I-DATASET
.	O

Table	O
1	O
:	O
Comparison	O
of	O
all	O
models	O
in	O
the	O
classi	O
-	O
fication	O
task	O
(	O
accuracy	B-METRIC
in	O
%	O
)	O
and	O
the	O
information	B-TASK
retrieval	I-TASK
task	I-TASK
(	O
MAP	O
scores	O
in	O
%	O
)	O
on	O
small	O
corpora	O
.	O

Table	O
3	O
:	O
Mean	B-METRIC
average	I-METRIC
Precision	I-METRIC
(	I-METRIC
MAP	I-METRIC
in	I-METRIC
%	I-METRIC
)	I-METRIC
scores	O
in	O
the	O
information	B-TASK
retrieval	I-TASK
task	I-TASK
.	O

As	O
training	O
data	O
,	O
we	O
use	O
both	O
labeled	O
and	O
unlabeled	O
data	O
,	O
utilizing	O
an	O
expectation	O
maximization	O
algorithm	O
for	O
parameter	O
estimation	O
.	O

It	O
uses	O
diverse	O
types	O
of	O
semantic	O
knowledge	O
,	O
a	O
mixture	O
of	O
labeled	O
and	O
unlabeled	O
data	O
for	O
training	O
data	O
,	O
a	O
logistic	O
regression	O
classi	O
-	O
fier	O
,	O
and	O
expectation	B-METRIC
maximization	I-METRIC
(	I-METRIC
EM	I-METRIC
)	I-METRIC
for	O
parameter	O
estimation	O
2	O
)	O
Collins	O
is	O
the	O
established	O
baseline	O
among	O
PP	B-TASK
attachment	I-TASK
algorithms	O
.	O

Our	O
parser	O
is	O
also	O
able	O
to	O
generalize	O
well	O
across	O
languages	O
with	O
little	O
tuning	O
:	O
it	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
multilingual	B-TASK
parsing	I-TASK
,	O
scoring	O
higher	O
than	O
the	O
best	O
single	O
-	O
parser	O
system	O
from	O
the	O
SPMRL	B-TASK
2013	I-TASK
Shared	I-TASK
Task	I-TASK
on	O
a	O
range	O
of	O
languages	O
,	O
as	O
well	O
as	O
on	O
the	O
competition	O
'	O
s	O
average	O
F1	B-METRIC
metric	I-METRIC
.	O

Table	O
1	O
:	O
Results	O
for	O
the	O
Penn	B-DATASET
Treebank	I-DATASET
development	I-DATASET
set	I-DATASET
,	O
reported	O
in	O
F1	B-METRIC
on	O
sentences	O
of	O
length	O
โค	O
40	O
on	O
Section	B-DATASET
22	I-DATASET
,	O
for	O
a	O
number	O
of	O
incrementally	O
growing	O
feature	O
sets	O
.	O

Table	O
5	O
:	O
Fine	B-TASK
-	I-TASK
grained	I-TASK
sentiment	I-TASK
analysis	I-TASK
results	O
on	O
the	O
Stanford	B-DATASET
Sentiment	I-DATASET
Treebank	I-DATASET
of	I-DATASET
Socher	I-DATASET
et	I-DATASET
al	I-DATASET
.	I-DATASET

Knowledge	O
of	O
temporal	O
counterparts	O
can	O
help	O
to	O
alleviate	O
the	O
problem	O
of	O
terminology	O
gap	O
for	O
users	O
searching	O
within	O
temporal	O
document	O
collections	O
such	O
as	O
archives	O
.	O

We	O
demonstrate	O
that	O
derived	O
constraints	O
aid	O
grammar	B-TASK
induction	I-TASK
by	O
training	O
Klein	O
and	O
Manning	O
'	O
s	O
Dependency	O
Model	O
with	O
Valence	O
(	O
DMV	O
)	O
on	O
this	O
data	O
set	O
:	O
parsing	B-TASK
accuracy	B-METRIC
on	O
Section	O
23	O
(	O
all	O
sentences	O
)	O
of	O
the	O
Wall	B-DATASET
Street	I-DATASET
Journal	I-DATASET
corpus	I-DATASET
jumps	O
to	O
50	O
.	O
4	O
%	O
,	O
beating	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
more	O
than	O
5	O
%	O
.	O

Unsupervised	O
learning	O
of	O
hierarchical	O
syntactic	O
structure	O
from	O
free	O
-	O
form	O
natural	O
language	O
text	O
is	O
a	O
hard	O
problem	O
whose	O
eventual	O
solution	O
promises	O
to	O
benefit	O
applications	O
ranging	O
from	O
question	B-TASK
answering	I-TASK
to	O
speech	B-TASK
recognition	I-TASK
and	O
machine	B-TASK
translation	I-TASK
.	O

This	O
conditioning	O
on	O
partial	O
parses	O
addressed	O
all	O
three	O
problems	O
,	O
leading	O
to	O
:	O
(	O
i	O
)	O
linguistically	O
reasonable	O
constituent	O
boundaries	O
and	O
induced	O
grammars	O
more	O
likely	O
to	O
agree	O
with	O
qualitative	O
judgments	O
of	O
sentence	O
structure	O
,	O
which	O
is	O
underdetermined	O
by	O
unannotated	O
text	O
;	O
(	O
ii	O
)	O
fewer	O
iterations	O
needed	O
to	O
reach	O
a	O
good	O
grammar	O
,	O
countering	O
convergence	O
properties	O
that	O
sharply	O
deteriorate	O
with	O
the	O
number	O
of	O
non	O
-	O
terminal	O
symbols	O
,	O
due	O
to	O
a	O
proliferation	O
of	O
local	O
maxima	O
;	O
and	O
(	O
iii	O
)	O
better	O
(	O
in	O
the	O
best	O
case	O
,	O
linear	O
)	O
time	O
complexity	O
per	O
iteration	O
,	O
versus	O
running	O
time	O
that	O
is	O
ordinarily	O
cubic	O
in	O
both	O
sentence	O
length	O
and	O
the	O
total	O
number	O
of	O
non	O
-	O
terminals	O
,	O
rendering	O
sufficiently	O
large	O
grammars	O
computationally	O
impractical	O
.	O

We	O
judged	O
each	O
one	O
by	O
its	O
accuracy	B-METRIC
on	O
WSJ45	B-DATASET
,	O
using	O
standard	O
directed	O
scoring	O
-	O
the	O
fraction	O
of	O
correct	O
dependencies	O
over	O
randomized	O
"	O
best	O
"	O
parse	O
trees	O
.	O

Since	O
we	O
cannot	O
graph	O
the	O
full	O
(	O
six	O
-	O
dimensional	O
)	O
set	O
of	O
results	O
,	O
we	O
begin	O
with	O
a	O
simple	O
linear	O
regression	O
,	O
using	O
accuracy	B-METRIC
on	O
WSJ45	B-DATASET
as	O
the	O
dependent	O
variable	O
.	O

To	O
evaluate	O
our	O
metric	O
we	O
first	O
present	O
a	O
number	O
of	O
synthetic	O
experiments	O
to	O
better	O
control	O
the	O
sources	O
of	O
noise	O
and	O
gauge	O
the	O
metric	O
'	O
s	O
responses	O
,	O
before	O
finally	O
contrasting	O
the	O
behaviour	O
of	O
our	O
chance	O
-	O
corrected	O
metric	O
with	O
that	O
of	O
un	O
-	O
corrected	O
parser	O
evaluation	O
metrics	O
on	O
real	O
corpora	O
.	O

For	O
this	O
reason	O
efforts	O
to	O
gauge	O
the	O
quality	O
of	O
syntactic	O
annotation	O
are	O
hampered	O
by	O
the	O
need	O
to	O
fallback	O
to	O
simple	O
accuracy	B-METRIC
measures	O
.	O

Next	O
,	O
we	O
present	O
a	O
number	O
of	O
synthetic	O
experiments	O
performed	O
in	O
order	O
to	O
find	O
the	O
best	O
distance	O
function	O
for	O
this	O
kind	O
of	O
annotation	O
;	O
finally	O
we	O
contrast	O
our	O
new	O
metric	O
and	O
simple	O
accuracy	B-METRIC
scores	O
as	O
applied	O
to	O
real	O
-	O
world	O
corpora	O
before	O
concluding	O
and	O
presenting	O
some	O
potential	O
avenues	O
for	O
future	O
work	O
.	O

We	O
report	O
a	O
0	O
.	O
9	O
point	O
improvement	O
in	O
terms	O
of	O
BLEU	B-METRIC
score	I-METRIC
on	O
English	O
-	O
Chinese	O
technical	O
documents	O
.	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
method	O
for	O
discovering	O
matches	O
between	O
problem	O
reports	O
and	O
aid	O
messages	O
.	O

The	O
2011	O
Great	O
East	O
Japan	O
Earthquake	O
in	O
March	O
11	O
,	O
2011	O
killed	O
15	O
,	O
883	O
people	O
and	O
destroyed	O
over	O
260	O
,	O
000	O
households	O
(	O
National	B-DATASET
Police	I-DATASET
Agency	I-DATASET
of	I-DATASET
Japan	I-DATASET
,	I-DATASET
2013	I-DATASET
)	I-DATASET
.	O

Just	O
after	O
the	O
disaster	O
,	O
many	O
people	O
used	O
Twitter	O
for	O
posting	O
problem	O
reports	O
and	O
aid	O
messages	O
as	O
it	O
functioned	O
while	O
most	O
communication	O
channels	O
suffered	O
disruptions	O
)	O
.	O

We	O
developed	O
methods	O
for	O
recognizing	O
problem	O
reports	O
and	O
aid	O
messages	O
in	O
tweets	O
and	O
finding	O
proper	O
matches	O
between	O
them	O
.	O

We	O
used	O
600	O
million	O
Web	O
pages	O
for	O
this	O
similarity	B-TASK
estimation	I-TASK
.	O

Currently	O
,	O
workflows	O
for	O
annotating	O
monolingual	O
and	O
bilingual	O
resources	O
of	O
various	O
formats	O
are	O
provided	O
(	O
e	O
.	O
g	O
.	O

Context	B-TASK
Vector	I-TASK
Disambiguation	I-TASK
for	O
Bilingual	B-TASK
Lexicon	I-TASK
Extraction	I-TASK
from	I-TASK
Comparable	I-TASK
Corpora	I-TASK

This	O
paper	O
presents	O
an	O
approach	O
that	O
extends	O
the	O
standard	O
approach	O
used	O
for	O
bilingual	B-TASK
lexicon	I-TASK
extraction	I-TASK
from	O
comparable	O
corpora	O
.	O

Over	O
the	O
years	O
,	O
bilingual	B-TASK
lexicon	I-TASK
extraction	I-TASK
from	O
comparable	O
corpora	O
has	O
attracted	O
a	O
wealth	O
of	O
research	O
works	O
.	O

The	O
so	O
-	O
called	O
standard	O
approach	O
to	O
bilingual	B-TASK
lexicon	I-TASK
extraction	I-TASK
from	O
comparable	O
corpora	O
is	O
based	O
on	O
the	O
characterization	O
and	O
comparison	O
of	O
context	O
vectors	O
of	O
source	O
and	O
target	O
words	O
.	O

The	O
polysemy	O
rate	O
indicates	O
how	O
much	O
words	O
in	O
the	O
comparable	O
corpora	O
are	O
associated	O
to	O
more	O
than	O
one	O
translation	O
in	O
the	O
seed	O
bilingual	O
dictionary	O
.	O

In	O
bilingual	O
terminology	B-TASK
extraction	I-TASK
from	O
com	O
-	O
parable	O
corpora	O
,	O
a	O
reference	O
list	O
is	O
required	O
to	O
evaluate	O
the	O
performance	O
of	O
the	O
alignment	O
.	O

Specifically	O
,	O
given	O
a	O
corpus	O
consisting	O
of	O
both	O
machine	O
-	O
translated	O
English	O
text	O
(	O
English	O
being	O
the	O
target	O
language	O
)	O
and	O
native	O
English	O
text	O
(	O
not	O
necessarily	O
the	O
reference	O
translation	O
of	O
the	O
machine	O
-	O
translated	O
text	O
)	O
,	O
we	O
measure	O
the	O
accuracy	B-METRIC
of	O
the	O
system	O
in	O
classifying	O
the	O
sentences	O
in	O
the	O
corpus	O
as	O
machine	O
-	O
translated	O
or	O
not	O
.	O

To	O
do	O
this	O
,	O
we	O
use	O
the	O
French	B-DATASET
-	I-DATASET
English	I-DATASET
data	I-DATASET
from	I-DATASET
the	I-DATASET
8th	I-DATASET
Workshop	I-DATASET
on	I-DATASET
Statistical	I-DATASET
Machine	I-DATASET
Translation	I-DATASET
-	I-DATASET
WMT13	I-DATASET
'	I-DATASET
MT	I-DATASET
Engine	I-DATASET
Example	I-DATASET
Google	I-DATASET
Translate	I-DATASET
"	O
These	O
days	O
,	O
all	O
but	O
one	O
were	O
subject	O
to	O
a	O
vote	O
,	O
and	O
all	O
had	O
a	O
direct	O
link	O
to	O
the	O
post	O
September	O
11th	O
.	O
"	O

We	O
explore	O
using	O
relevant	O
tweets	O
of	O
a	O
given	O
news	O
article	O
to	O
help	O
sentence	O
compression	O
for	O
generating	O
compressive	O
news	O
highlights	O
.	O

The	O
experimental	O
results	O
on	O
a	O
public	O
corpus	O
that	O
contains	O
both	O
news	O
articles	O
and	O
relevant	O
tweets	O
show	O
that	O
our	O
proposed	O
tweets	O
guided	O
sentence	B-TASK
compression	I-TASK
method	O
can	O
improve	O
the	O
summarization	B-TASK
performance	O
significantly	O
compared	O
to	O
the	O
baseline	O
generic	O
sentence	O
compression	O
method	O
.	O
.	O

Instead	O
of	O
using	O
a	O
manually	O
generated	O
corpus	O
,	O
we	O
investigate	O
using	O
existing	O
external	O
sources	O
to	O
guide	O
sentence	O
compression	O
for	O
the	O
purpose	O
of	O
compressive	B-TASK
news	I-TASK
highlights	I-TASK
generation	I-TASK
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
use	O
relevant	O
tweets	O
of	O
a	O
news	O
article	O
to	O
guide	O
the	O
sentence	B-TASK
compression	I-TASK
process	O
in	O
a	O
pipeline	O
framework	O
for	O
generating	O
compressive	O
news	O
highlights	O
.	O

This	O
is	O
a	O
pioneer	O
study	O
for	O
using	O
such	O
parallel	O
data	O
to	O
guide	O
sentence	B-TASK
compression	I-TASK
for	O
document	B-TASK
summarization	I-TASK
.	O

The	O
result	O
shows	O
that	O
generic	O
compression	O
hurts	O
the	O
performance	O
of	O
highlights	B-TASK
generation	I-TASK
,	O
while	O
sentence	O
compression	O
guided	O
by	O
relevant	O
tweets	O
of	O
the	O
news	O
article	O
can	O
improve	O
the	O
performance	O
.	O

In	O
the	O
first	O
mode	O
of	O
operation	O
,	O
we	O
provide	O
afield	O
linguist	O
with	O
tools	O
for	O
running	O
custom	O
elicitation	O
sessions	O
based	O
on	O
a	O
collection	O
of	O
3D	O
scenes	O
.	O

We	O
will	O
demonstrate	O
the	O
features	O
of	O
WELT	O
for	O
use	O
in	O
fieldwork	O
,	O
including	O
designing	O
elicitation	O
sessions	O
,	O
building	O
scenes	O
,	O
recording	O
audio	O
,	O
and	O
adding	O
descriptions	O
and	O
glosses	O
to	O
a	O
scene	O
.	O

In	O
this	O
study	O
,	O
although	O
there	O
is	O
still	O
room	O
for	O
improvement	O
on	O
performance	O
with	O
more	O
feature	O
engineering	O
,	O
we	O
obtain	O
better	O
results	O
on	O
Turkish	B-DATASET
IMST	I-DATASET
treebank	I-DATASET
between	O
static	O
and	O
dynamic	O
oracles	O
with	O
our	O
newly	O
proposed	O
method	O
for	O
parsing	B-TASK
DAGs	I-TASK
.	O

Con	O
-	O
textualized	O
word	O
vectors	O
constructed	O
from	O
the	O
GigaWord	B-DATASET
Corpus	I-DATASET
provide	O
a	O
method	O
for	O
implicit	O
Word	B-TASK
Sense	I-TASK
Disambiguation	I-TASK
(	I-TASK
WSD	I-TASK
)	I-TASK
,	O
whose	O
reliability	O
helps	O
this	O
system	O
outperform	O
baselines	O
and	O
achieve	O
comparable	O
results	O
to	O
those	O
of	O
systems	O
with	O
full	O
WSD	O
modules	O
.	O

In	O
this	O
paper	O
,	O
we	O
investigate	O
the	O
importance	O
of	O
proper	O
word	O
sense	O
decisions	O
for	O
PP	B-TASK
-	I-TASK
attachment	I-TASK
disambiguation	I-TASK
,	O
and	O
describe	O
a	O
highly	O
-	O
accurate	O
system	O
that	O
encodes	O
sense	O
information	O
in	O
contextualized	O
distributional	O
data	O
.	O

An	O
easy	O
-	O
to	O
-	O
use	O
web	O
interface	O
empowers	O
users	O
to	O
participate	O
in	O
data	O
collection	O
and	O
MT	B-TASK
customisation	I-TASK
to	O
increase	O
the	O
quality	O
,	O
domain	O
coverage	O
,	O
and	O
usage	O
of	O
MT	B-TASK
.	O

For	O
evaluation	B-TASK
of	I-TASK
English	I-TASK
-	I-TASK
Latvian	I-TASK
translation	I-TASK
,	O
TILDE	O
created	O
a	O
MT	B-TASK
system	O
using	O
a	O
significantly	O
larger	O
corpus	O
of	O
5	O
.	O
37M	O
parallel	O
sentence	O
pairs	O
,	O
including	O
1	O
.	O
29M	O
pairs	O
in	O
the	O
IT	O
domain	O
.	O

First	O
,	O
we	O
show	O
that	O
for	O
frame	B-TASK
identification	I-TASK
on	O
the	O
FrameNet	B-DATASET
corpus	I-DATASET
(	O
,	O
we	O
outperform	O
the	O
prior	O
state	O
of	O
the	O
art	O
(	O
)	O
.	O

10	O
10	O
Note	O
that	O
describe	O
the	O
state	O
of	O
the	O
art	O
in	O
FrameNet	O
-	O
based	O
analysis	O
,	O
but	O
their	O
argument	B-TASK
identification	I-TASK
strategy	O
considered	O
all	O
possible	O
dependency	O
subtrees	O
in	O
Frame	O
Lexicon	O
In	O
our	O
experimental	O
setup	O
,	O
we	O
scanned	O
the	O
XML	O
files	O
in	O
the	O
"	O
frames	O
"	O
directory	O
of	O
the	O
FrameNet	B-DATASET
1	I-DATASET
.	I-DATASET
5	I-DATASET
release	I-DATASET
,	O
which	O
lists	O
all	O
the	O
frames	O
,	O
the	O
corresponding	O
roles	O
and	O
the	O
associated	O
lexical	O
units	O
,	O
and	O
created	O
a	O
frame	O
lexicon	O
to	O
be	O
used	O
in	O
our	O
frame	O
and	O
argument	O
identification	O
models	O
.	O

a	O
parse	O
,	O
resulting	O
in	O
a	O
much	O
larger	O
search	O
space	O
.	O
:	O
Full	O
frame	B-TASK
-	I-TASK
structure	I-TASK
prediction	I-TASK
results	O
for	O
Propbank	B-DATASET
.	O

presents	O
results	O
on	O
the	O
full	O
frame	B-TASK
-	I-TASK
semantic	I-TASK
parsing	I-TASK
task	I-TASK
(	O
measured	O
by	O
a	O
reimplementation	O
of	O
the	O
SemEval	O
2007	O
shared	O
task	O
evaluation	O
script	O
)	O
when	O
our	O
argument	O
identification	O
model	O
(	O
ยง	O
4	O
)	O
is	O
used	O
after	O
frame	O
identification	O
.	O

Table	O
2	O
:	O
Frame	B-TASK
identification	I-TASK
results	O
for	O
FrameNet	B-DATASET
.	O

Table	O
3	O
:	O
Full	B-TASK
structure	I-TASK
prediction	I-TASK
results	O
for	O
FrameNet	B-DATASET
;	O
this	O
reports	O
frame	O
and	O
argument	O
identification	O
performance	O
jointly	O
.	O

Table	O
4	O
:	O
Frame	B-TASK
identification	I-TASK
accuracy	B-METRIC
results	O
for	O
PropBank	B-DATASET
.	O

Table	O
6	O
:	O
Argument	O
only	O
evaluation	O
(	O
semantic	O
role	O
labeling	O
metrics	O
)	O
using	O
the	O
CoNLL	B-DATASET
2005	I-DATASET
shared	I-DATASET
task	I-DATASET
evaluation	I-DATASET
script	I-DATASET
(	O
Carreras	O
and	O
M	O
`	O
arquez	O
,	O
2005	O
)	O
.	O

We	O
address	O
the	O
issue	O
of	O
automatically	B-TASK
identifying	I-TASK
and	I-TASK
resolving	I-TASK
implicit	I-TASK
arguments	I-TASK
in	I-TASK
Chinese	I-TASK
discourse	I-TASK
.	O

Data	O
:	O
Experimental	O
data	O
set	O
comes	O
from	O
Semantic	O
Computing	O
and	O
Chinese	B-DATASET
FrameNet	I-DATASET
Research	I-DATASET
Centor	I-DATASET
of	O
Shanxi	O
University	O
.	O

Our	O
164	O
discourses	O
had	O
been	O
annotated	O
by	O
one	O
person	O
(	O
to	O
make	O
it	O
consistent	O
)	O
,	O
and	O
they	O
consist	O
of	O
57	O
discourses	O
from	O
People	B-DATASET
'	I-DATASET
s	I-DATASET
Daily	I-DATASET
and	O
107	O
discourses	O
from	O
Chinese	O
reading	O
comprehension	O
,	O
which	O
cover	O
technology	O
,	O
healthcare	O
,	O
social	O
,	O
geography	O
and	O
other	O
fields	O
.	O

Null	B-TASK
Instantiation	I-TASK
Detection	I-TASK
gives	O
the	O
performance	O
of	O
NI	B-TASK
detection	I-TASK
,	O
which	O
achieves	O
72	O
.	O
71	O
%	O
,	O
86	O
.	O
12	O
%	O
and	O
78	O
.	O
84	O
%	O
in	O
precision	B-METRIC
,	O
recall	B-METRIC
and	O
F	B-METRIC
-	I-METRIC
score	I-METRIC
,	O
respectively	O
.	O

It	O
shows	O
that	O
DNI	B-TASK
identification	I-TASK
based	O
on	O
maximum	O
entropy	O
model	O
achieves	O
the	O
performance	O
of	O
67	O
.	O
86	O
%	O
,	O
69	O
.	O
93	O
%	O
and	O
68	O
.	O
88	O
%	O
in	O
terms	O
of	O
precision	B-METRIC
,	O
recall	B-METRIC
and	O
F	B-METRIC
-	I-METRIC
score	I-METRIC
respectively	O
,	O
which	O
are	O
better	O
than	O
the	O
results	O
using	O
SVM	O
classifier	O
,	O
as	O
well	O
as	O
the	O
results	O
employing	O
Lei	O
et	O
al	O
.	O
'	O
s	O
method	O
on	O
our	O
data	O
.	O

Hence	O
,	O
document	O
representations	O
that	O
reveal	O
information	O
about	O
writing	O
style	O
are	O
required	O
to	O
achieve	O
good	O
accuracy	B-METRIC
in	O
AA	B-TASK
.	O

Also	O
,	O
we	O
experimented	O
with	O
reducedimbalanced	O
data	O
sets	O
using	O
the	O
same	O
imbalance	O
rates	O
reported	O
in	O
(	O
Plakias	O
and	O
Stamatatos	O
,	O
2008b	O
;	O
Plakias	O
and	O
Stamatatos	O
,	O
2008a	O
)	O
:	O
we	O
tried	O
settings	O
2	O
โ	O
10	O
,	O
5	O
โ	O
10	O
,	O
and	O
10	O
โ	O
20	O
,	O
where	O
,	O
for	O
example	O
,	O
setting	O
2	O
-	O
10	O
means	O
that	O
we	O
use	O
at	O
least	O
2	O
and	O
at	O
most	O
10	O
documents	O
per	O
author	O
(	O
we	O
call	O
this	O
setting	O
IRBC	O
)	O
.	O

However	O
,	O
the	O
diffusion	O
kernel	O
outperformed	O
most	O
of	O
the	O
results	O
obtained	O
with	O
other	O
kernels	O
;	O
confirming	O
the	O
results	O
obtained	O
by	O
other	O
researchers	O
(	O
:	O
Authorship	O
attribution	O
accuracy	B-METRIC
when	O
using	O
bags	O
of	O
local	O
histograms	O
and	O
different	O
kernels	O
for	O
word	O
-	O
based	O
and	O
character	O
-	O
based	O
representations	O
.	O

The	O
benefits	O
of	O
such	O
expansion	O
become	O
more	O
notorious	O
as	O
the	O
number	O
of	O
available	O
documents	O
per	O
author	O
decreases	O
.	O
:	O
AA	B-METRIC
accuracy	B-METRIC
in	O
RBC	O
(	O
columns	O
2	O
-	O
6	O
)	O
and	O
IRBC	O
(	O
columns	O
7	O
-	O
9	O
)	O
data	O
sets	O
when	O
using	O
words	O
as	O
terms	O
.	O

For	O
reference	O
(	O
last	O
row	O
)	O
,	O
we	O
also	O
include	O
the	O
best	O
result	O
reported	O
in	O
)	O
,	O
when	O
available	O
,	O
for	O
each	O
configuration	O
.	O
:	O
AA	B-METRIC
accuracy	B-METRIC
in	O
the	O
RBC	O
and	O
IRBC	B-DATASET
data	I-DATASET
sets	I-DATASET
when	O
using	O
character	O
n	O
-	O
grams	O
as	O
terms	O
.	O

Table	O
3	O
:	O
Authorship	B-TASK
attribution	I-TASK
accuracy	B-METRIC
when	O
using	O
bags	O
of	O
local	O
histograms	O
and	O
different	O
kernels	O
for	O
word	O
-	O
based	O
and	O
character	O
-	O
based	O
representations	O
.	O

Table	O
5	O
:	O
AA	B-METRIC
accuracy	B-METRIC
in	O
RBC	O
(	O
columns	O
2	O
-	O
6	O
)	O
and	O
IRBC	O
(	O
columns	O
7	O
-	O
9	O
)	O
data	O
sets	O
when	O
using	O
words	O
as	O
terms	O
.	O

Table	O
6	O
:	O
AA	B-METRIC
accuracy	B-METRIC
in	O
the	O
RBC	B-DATASET
and	I-DATASET
IRBC	I-DATASET
data	I-DATASET
sets	I-DATASET
when	O
using	O
character	O
n	O
-	O
grams	O
as	O
terms	O
.	O

Distinguishing	O
between	O
the	O
two	O
argument	O
types	O
has	O
been	O
discussed	O
extensively	O
in	O
various	O
formulations	O
in	O
the	O
NLP	O
literature	O
,	O
notably	O
in	O
PP	B-TASK
attachment	I-TASK
,	O
semantic	B-TASK
role	I-TASK
labeling	I-TASK
(	I-TASK
SRL	I-TASK
)	I-TASK
and	O
subcategorization	B-TASK
acquisition	I-TASK
.	O

This	O
scenario	O
decouples	O
the	O
accuracy	B-METRIC
of	O
the	O
algorithm	O
from	O
the	O
quality	O
of	O
the	O
unsupervised	O
POS	B-TASK
tagging	I-TASK
.	O

We	O
see	O
accuracy	B-METRIC
as	O
important	O
on	O
its	O
own	O
right	O
since	O
increasing	O
coverage	O
is	O
often	O
straightforward	O
given	O
easily	O
obtainable	O
larger	O
training	O
corpora	O
.	O

Machine	B-TASK
translation	I-TASK
suffers	O
acutely	O
from	O
the	O
domain	O
-	O
mismatch	O
problem	O
caused	O
by	O
microblog	O
text	O
.	O

This	O
paper	O
introduces	O
a	O
method	O
for	O
finding	O
naturally	O
occurring	O
parallel	O
microblog	O
text	O
,	O
which	O
helps	O
address	O
the	O
domain	O
-	O
mismatch	O
problem	O
.	O

We	O
report	O
on	O
machine	B-TASK
translation	I-TASK
experiments	O
using	O
our	O
harvested	O
data	O
in	O
two	O
domains	O
:	O
edited	O
news	O
and	O
microblogs	O
.	O

We	O
obtain	O
statistically	O
significant	O
improvements	O
across	O
4	O
different	O
language	O
pairs	O
with	O
English	O
as	O
source	O
,	O
mounting	O
up	O
to	O
+	O
1	O
.	O
92	O
BLEU	B-METRIC
for	O
Chinese	O
as	O
target	O
.	O
.	O

The	O
data	O
for	O
the	O
English	O
to	O
Chinese	O
task	O
is	O
composed	O
of	O
parliament	O
proceedings	O
and	O
news	O
articles	O
.	O

BLEU	B-METRIC
scores	O
for	O
200K	O
and	O
400K	O
training	O
sentence	O
pairs	O
.	O

Automatic	O
processing	O
of	O
metaphor	O
can	O
be	O
clearly	O
divided	O
into	O
two	O
subtasks	O
:	O
metaphor	B-TASK
recognition	I-TASK
(	O
distinguishing	O
between	O
literal	O
and	O
metaphorical	O
language	O
in	O
a	O
text	O
)	O
and	O
metaphor	B-TASK
interpretation	I-TASK
(	O
iden	O
-	O
tifying	O
the	O
intended	O
literal	O
meaning	O
of	O
a	O
metaphorical	O
expression	O
)	O
.	O

There	O
are	O
,	O
however	O
,	O
inherent	O
problems	O
in	O
the	O
entity	O
repositories	O
:	O
(	O
a	O
)	O
coverage	O
:	O
although	O
coverage	O
of	O
head	O
entity	O
types	O
is	O
often	O
reliable	O
,	O
the	O
tail	O
can	O
be	O
sparse	O
;	O
(	O
b	O
)	O
noise	O
:	O
created	O
by	O
spammers	O
,	O
extraction	O
errors	O
or	O
errors	O
in	O
crowdsourced	O
content	O
;	O
(	O
c	O
)	O
ambiguity	O
:	O
multiple	O
types	O
or	O
entity	O
identifiers	O
are	O
often	O
associated	O
with	O
the	O
same	O
surface	O
string	O
;	O
and	O
(	O
d	O
)	O
over	O
-	O
expression	O
:	O
many	O
entities	O
have	O
types	O
that	O
are	O
never	O
used	O
in	O
the	O
context	O
of	O
Web	O
search	O
.	O

In	O
the	O
related	O
field	O
of	O
web	B-TASK
search	I-TASK
ranking	I-TASK
,	O
automatically	O
learned	O
non	O
-	O
linear	O
features	O
have	O
brought	O
dramatic	O
improvements	O
in	O
quality	O
(	O
;	O
Wu	O
*	O
This	O
research	O
was	O
conducted	O
during	O
the	O
author	O
'	O
s	O
internship	O
at	O
Microsoft	B-DATASET
Research	I-DATASET
et	I-DATASET
al	I-DATASET
.	I-DATASET
,	O
2010	O
)	O
.	O

For	O
Chinese	O
-	O
English	O
,	O
the	O
training	O
corpus	O
consists	O
of	O
approximately	O
one	O
million	O
sentence	O
pairs	O
from	O
the	O
FBIS	B-DATASET
and	O
HongKong	O
portions	O
of	O
the	O
LDC	O
data	O
for	O
the	O
NIST	B-TASK
MT	I-TASK
evaluation	O
and	O
the	O
Dev	O
-	O
Train	O
and	O
Test	O
sets	O
are	O
from	O
NIST	B-DATASET
competitions	O
.	O

In	O
conclusion	O
,	O
we	O
proposed	O
anew	O
method	O
to	O
induce	O
feature	O
combinations	O
for	O
machine	B-TASK
translation	I-TASK
,	O
which	O
do	O
not	O
increase	O
the	O
decoding	O
complexity	O
.	O

An	O
empirical	O
evaluation	O
on	O
a	O
widely	O
used	O
sentiment	O
corpus	O
shows	O
an	O
improvement	O
of	O
1	O
.	O
45	O
point	O
inaccuracy	O
over	O
the	O
baseline	O
resulting	O
from	O
a	O
combination	O
of	O
bag	O
-	O
of	O
-	O
words	O
and	O
high	O
-	O
impact	O
parse	O
features	O
(	O
Section	O
4	O
)	O
.	O

We	O
tackle	O
these	O
issues	O
by	O
making	O
the	O
following	O
contributions	O
:	O
โข	O
we	O
introduce	O
Topic	O
-	O
Driven	O
Relevance	O
Models	O
,	O
a	O
model	O
-	O
based	O
feedback	O
approach	O
)	O
for	O
integrating	O
topic	O
models	O
into	O
relevance	O
models	O
by	O
learning	O
topics	O
on	O
pseudo	O
-	O
relevant	O
feedback	O
documents	O
(	O
as	O
opposed	O
to	O
the	O
entire	O
document	O
collection	O
)	O
,	O
โข	O
we	O
explore	O
the	O
coherence	O
of	O
those	O
generated	O
topics	O
using	O
the	O
queries	O
of	O
two	O
major	O
and	O
well	O
-	O
established	O
TREC	O
test	O
collections	O
,	O
โข	O
we	O
evaluate	O
the	O
effects	O
coherent	O
topics	O
have	O
on	O
ad	O
hoc	O
IR	O
using	O
the	O
same	O
test	O
collections	O
.	O

For	O
summarization	B-TASK
of	I-TASK
spontaneous	I-TASK
speech	I-TASK
,	O
sentence	B-TASK
compression	I-TASK
is	O
especially	O
important	O
,	O
since	O
unlike	O
fluent	O
and	O
wellstructured	O
written	O
text	O
,	O
spontaneous	O
speech	O
contains	O
a	O
lot	O
of	O
disfluencies	O
and	O
much	O
redundancy	O
.	O

BLEU	B-METRIC
is	O
a	O
widely	O
used	O
metric	O
in	O
evaluating	O
machine	B-TASK
translation	I-TASK
systems	O
that	O
often	O
use	O
multiple	O
references	O
.	O

Since	O
there	O
is	O
a	O
great	O
variation	O
inhuman	O
compression	O
results	O
,	O
and	O
we	O
have	O
8	O
reference	O
compressions	O
,	O
we	O
explore	O
using	O
BLEU	B-METRIC
for	O
our	O
sentence	B-TASK
compression	I-TASK
task	O
.	O

Regarding	O
the	O
two	O
training	O
settings	O
in	O
reranking	O
,	O
we	O
find	O
that	O
there	O
is	O
no	O
gain	O
from	O
reranking	O
when	O
using	O
only	O
one	O
best	O
compression	O
,	O
however	O
,	O
training	O
with	O
multiple	O
references	O
improves	O
BLEU	B-METRIC
scores	O
.	O

This	O
indicates	O
the	O
discriminative	O
training	O
used	O
in	O
maximum	O
entropy	O
reranking	O
is	O
consistent	O
with	O
the	O
performance	O
metrics	O
.	O

This	O
provides	O
some	O
insight	O
into	O
the	O
evalb	O
scores	O
,	O
and	O
the	O
problem	O
of	O
domain	B-TASK
adaptation	I-TASK
with	O
the	O
web	O
data	O
.	O

In	O
this	O
paper	O
we	O
present	O
a	O
novel	O
algorithm	O
for	O
rapidly	O
prototyping	O
virtual	O
instructors	O
from	O
human	O
-	O
human	O
corpora	O
without	O
manual	O
annotation	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
novel	O
a	O
algorithm	O
for	O
generating	O
virtual	O
instructors	O
from	O
automatically	O
annotated	O
human	O
-	O
human	O
corpora	O
.	O

Currently	O
,	O
WebLicht	O
offers	O
LRT	O
services	O
that	O
were	O
developed	O
independently	O
at	O
the	O
Institut	O
f	O
รผ	O
r	O
Informatik	O
,	O
Abteilung	O
Automatische	O
Sprachverarbeitung	O
at	O
the	O
University	O
of	O
Leipzig	O
(	O
tokenizer	O
,	O
lemmatizer	O
,	O
co	O
-	O
occurrence	O
extraction	O
,	O
and	O
frequency	O
analyzer	O
)	O
,	O
at	O
the	O
Institut	O
f	O
รผ	O
r	O
Maschinelle	O
Sprachverarbeitung	O
at	O
the	O
University	O
of	O
Stuttgart	O
(	O
tokenizer	O
,	O
tagger	O
/	O
lemmatizer	O
,	O
German	B-TASK
morphological	I-TASK
analyser	I-TASK
SMOR	I-TASK
,	O
constituent	O
and	O
dependency	O
parsers	O
)	O
,	O
at	O
the	O
Berlin	O
Brandenburgische	O
Akademie	O
der	O
Wissenschaften	O
(	O
conversion	O
of	O
plain	O
text	O
to	O
D	O
-	O
Spin	O
format	O
,	O
tokenizer	O
,	O
taggers	O
,	O
NE	O
recog	O
-	O
.	O

This	O
paper	O
presents	O
an	O
effective	O
algorithm	O
of	O
annotation	B-TASK
adaptation	I-TASK
for	O
constituency	O
treebanks	O
,	O
which	O
transforms	O
a	O
treebank	O
from	O
one	O
annotation	O
guideline	O
to	O
another	O
with	O
an	O
iterative	O
optimization	O
procedure	O
,	O
thus	O
to	O
build	O
a	O
much	O
larger	O
treebank	O
to	O
train	O
an	O
enhanced	O
parser	O
without	O
increasing	O
model	O
complexity	O
.	O

Annotated	O
data	O
have	O
become	O
an	O
indispensable	O
resource	O
for	O
many	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
applications	O
.	O

On	O
one	O
hand	O
,	O
the	O
amount	O
of	O
existing	O
labeled	O
data	O
is	O
not	O
sufficient	O
;	O
on	O
the	O
other	O
hand	O
,	O
however	O
there	O
exists	O
multiple	O
annotated	O
data	O
with	O
incompatible	O
annotation	O
guidelines	O
for	O
the	O
same	O
NLP	O
task	O
.	O

For	O
example	O
,	O
the	O
People	B-DATASET
'	I-DATASET
s	I-DATASET
Daily	I-DATASET
corpus	I-DATASET
(	O
)	O
and	O
Chinese	B-DATASET
Penn	I-DATASET
Treebank	I-DATASET
(	I-DATASET
CTB	I-DATASET
)	I-DATASET
(	O
)	O
are	O
publicly	O
available	O
for	O
Chinese	B-TASK
segmentation	I-TASK
.	O

In	O
addition	O
to	O
the	O
most	O
popular	O
CTB	O
,	O
Tsinghua	B-DATASET
Chinese	I-DATASET
Treebank	I-DATASET
(	I-DATASET
TC	I-DATASET
-	I-DATASET
T	I-DATASET
)	I-DATASET
)	O
is	O
another	O
real	O
large	O
-	O
scale	O
treebank	O
for	O
Chinese	B-TASK
constituent	I-TASK
parsing	I-TASK
.	O

The	O
transformed	O
treebank	O
is	O
used	O
to	O
provide	O
better	O
annotation	O
guideline	O
for	O
the	O
parallel	O
training	O
data	O
of	O
next	O
iteration	O
.	O

In	O
contrast	O
to	O
such	O
data	O
-	O
independent	O
hashing	O
schemes	O
,	O
recent	O
research	O
has	O
been	O
geared	O
to	O
studying	O
data	O
-	O
dependent	O
hashing	O
through	O
learning	O
compact	O
hash	O
codes	O
from	O
a	O
training	O
dataset	O
.	O

Despite	O
achieving	O
data	O
-	O
dependent	O
hash	O
codes	O
,	O
most	O
of	O
these	O
"	O
learning	O
to	O
hash	O
"	O
methods	O
cannot	O
guarantee	O
a	O
high	O
success	O
rate	O
of	O
looking	O
a	O
query	O
code	O
up	O
in	O
a	O
hash	O
table	O
(	O
referred	O
to	O
as	O
hash	O
table	O
lookup	O
in	O
literature	O
)	O
,	O
which	O
is	O
critical	O
to	O
the	O
high	O
efficacy	O
of	O
exploiting	O
hashing	O
in	O
practical	O
uses	O
.	O

As	O
we	O
know	O
,	O
document	B-TASK
summarization	I-TASK
is	O
a	O
very	O
useful	O
means	O
for	O
people	O
to	O
quickly	O
read	O
and	O
browse	O
news	O
articles	O
in	O
the	O
big	O
data	O
era	O
.	O

The	O
results	O
demonstrate	O
that	O
BrailleSUM	O
can	O
produce	O
much	O
shorter	O
braille	O
summaries	O
while	O
not	O
sacrificing	O
the	O
summaries	O
'	O
content	O
quality	O
.	O

Unfortunately	O
,	O
the	O
reliance	O
on	O
role	O
-	O
annotated	O
data	O
which	O
is	O
expensive	O
and	O
time	O
-	O
consuming	O
to	O
produce	O
for	O
every	O
language	O
and	O
domain	O
,	O
presents	O
a	O
major	O
bottleneck	O
to	O
the	O
widespread	O
application	O
of	O
semantic	B-TASK
role	I-TASK
labeling	I-TASK
.	O

We	O
test	O
this	O
model	O
on	O
a	O
set	O
of	O
ciphers	O
developed	O
from	O
various	O
web	O
sites	O
,	O
and	O
find	O
that	O
our	O
algorithm	O
has	O
the	O
potential	O
to	O
be	O
a	O
viable	O
,	O
practical	O
method	O
for	O
efficiently	O
solving	O
decipherment	O
problems	O
.	O
.	O

Table	O
1	O
:	O
Time	B-METRIC
consumption	I-METRIC
and	O
accuracy	B-METRIC
on	O
a	O
sample	O
of	O
10	O
6000	O
-	O
character	O
texts	O
.	O

Unsupervised	B-TASK
Discovery	I-TASK
of	I-TASK
Domain	I-TASK
-	I-TASK
Specific	I-TASK
Knowledge	I-TASK
from	I-TASK
Text	I-TASK

American	O
football	O
was	O
the	O
first	O
official	O
evaluation	O
domain	O
in	O
the	O
DARPA	O
-	O
sponsored	O
Machine	O
Reading	O
program	O
,	O
and	O
provides	O
the	O
background	O
fora	O
number	O
of	O
LbR	O
systems	O
.	O

Experiment	O
on	O
the	O
SANCL	B-DATASET
2012	I-DATASET
shared	I-DATASET
task	I-DATASET
show	O
that	O
our	O
approach	O
achieves	O
93	O
.	O
15	O
%	O
average	O
tagging	B-TASK
accuracy	B-METRIC
,	O
which	O
is	O
the	O
best	O
accuracy	B-METRIC
reported	O
so	O
far	O
on	O
this	O
data	O
set	O
,	O
higher	O
than	O
those	O
given	O
by	O
ensembled	O
syntactic	O
parsers	O
.	O
.	O

However	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
POS	B-TASK
taggers	I-TASK
in	O
the	O
literature	O
are	O
mainly	O
optimized	O
on	O
the	O
the	O
Penn	B-DATASET
Treebank	I-DATASET
(	I-DATASET
PTB	I-DATASET
)	I-DATASET
,	O
and	O
when	O
shifted	O
to	O
web	O
data	O
,	O
tagging	O
accuracies	O
drop	O
significantly	O
(	O
)	O
.	O

The	O
problem	O
we	O
face	O
here	O
can	O
be	O
considered	O
as	O
a	O
special	O
case	O
of	O
domain	B-TASK
adaptation	I-TASK
,	O
where	O
we	O
have	O
access	O
to	O
labelled	O
data	O
on	O
the	O
source	O
domain	O
(	O
PTB	O
)	O
and	O
unlabelled	O
data	O
on	O
the	O
target	O
domain	O
(	O
web	O
data	O
)	O
.	O

Exploiting	O
useful	O
information	O
from	O
the	O
web	O
data	O
can	O
be	O
the	O
key	O
to	O
improving	O
web	B-TASK
domain	I-TASK
tagging	I-TASK
.	O

In	O
the	O
pre	O
-	O
training	O
phase	O
,	O
we	O
learn	O
an	O
encoder	O
that	O
converts	O
the	O
web	O
text	O
into	O
an	O
intermediate	O
representation	O
,	O
which	O
acts	O
as	O
useful	O
features	O
for	O
prediction	O
tasks	O
.	O

We	O
show	O
why	O
such	O
a	O
paradigm	O
represents	O
a	O
promising	O
direction	O
and	O
present	O
some	O
recent	O
progress	O
on	O
the	O
development	O
of	O
effective	O
methods	O
for	O
construction	O
and	O
mining	O
of	O
structured	O
heterogeneous	O
information	O
networks	O
from	O
text	O
data	O
.	O

In	O
the	O
context	O
of	O
the	O
simplification	B-TASK
task	I-TASK
however	O
,	O
the	O
automatically	O
generated	O
sentences	O
are	O
not	O
necessarily	O
well	O
formed	O
so	O
that	O
the	O
FKG	O
index	O
reduces	O
to	O
a	O
measure	O
of	O
the	O
sentence	O
length	O
(	O
in	O
terms	O
of	O
words	O
and	O
syllables	O
)	O
approximating	O
the	O
simplicity	O
level	O
of	O
an	O
output	O
sentence	O
irrespective	O
of	O
the	O
length	O
of	O
the	O
corresponding	O
input	O
.	O

To	O
assess	O
simplification	O
,	O
we	O
instead	O
use	O
metrics	O
that	O
are	O
directly	O
related	O
to	O
the	O
simplification	O
task	O
namely	O
,	O
the	O
number	O
of	O
splits	O
in	O
the	O
overall	O
(	O
test	O
and	O
training	O
)	O
data	O
and	O
in	O
average	O
per	O
sentences	O
;	O
the	O
number	O
of	O
generated	O
sentences	O
with	O
no	O
edits	O
i	O
.	O
e	O
.	O
,	O
which	O
are	O
identical	O
to	O
the	O
original	O
,	O
complex	O
one	O
;	O
and	O
the	O
average	O
Levenshtein	O
distance	O
between	O
the	O
system	O
'	O
s	O
output	O
and	O
both	O
the	O
complex	O
and	O
the	O
simple	O
reference	O
sentences	O
.	O

Table	O
3	O
:	O
Proportion	O
of	O
Split	O
Sentences	O
(	O
%	O
split	O
)	O
in	O
the	O
training	O
/	O
test	O
data	O
and	O
in	O
average	B-METRIC
per	I-METRIC
sen	I-METRIC
-	I-METRIC
tence	I-METRIC
(	O
average	O
split	O
/	O
sentence	O
)	O
.	O

Although	O
there	O
is	O
a	O
growing	O
interest	O
in	O
automatically	O
constructing	O
knowledge	O
graphs	O
,	O
e	O
.	O
g	O
.	O
,	O
from	O
unstructured	O
web	O
data	O
(	O
,	O
the	O
problem	O
of	O
providing	O
evidence	O
on	O
why	O
two	O
entities	O
are	O
related	O
in	O
a	O
knowledge	O
graph	O
remains	O
largely	O
unaddressed	O
.	O

Our	O
main	O
contributions	O
area	O
robust	O
and	O
effective	O
method	O
for	O
explaining	O
entity	O
relationships	O
,	O
detailed	O
insights	O
into	O
the	O
performance	O
of	O
our	O
method	O
and	O
features	O
,	O
and	O
a	O
manually	O
annotated	O
dataset	O
.	O

In	O
this	O
section	O
we	O
describe	O
the	O
dataset	O
,	O
manual	O
annotations	O
,	O
learning	O
to	O
rank	O
algorithm	O
,	O
and	O
evaluation	O
metrics	O
that	O
we	O
use	O
to	O
answer	O
our	O
research	O
questions	O
.	O

Recent	O
studies	O
in	O
the	O
difficult	O
task	O
of	O
Word	B-TASK
Sense	I-TASK
Disambiguation	I-TASK
,	I-TASK
WSD	I-TASK
)	I-TASK
have	O
shown	O
the	O
impact	O
of	O
the	O
amount	O
and	O
quality	O
of	O
lexical	O
knowledge	O
(	O
Cuadros	O
and	O
)	O
:	O
richer	O
knowledge	O
sources	O
can	O
be	O
of	O
great	O
benefit	O
to	O
both	O
knowledge	O
-	O
lean	O
systems	O
and	O
supervised	O
classifiers	O
(	O
)	O
.	O

But	O
while	O
a	O
great	O
deal	O
of	O
work	O
has	O
been	O
recently	O
devoted	O
to	O
the	O
automatic	O
extraction	O
of	O
structured	O
information	O
from	O
Wikipedia	O
(	O
,	O
inter	O
alia	O
)	O
,	O
the	O
knowledge	O
extracted	O
is	O
organized	O
in	O
a	O
looser	O
way	O
than	O
in	O
a	O
computational	O
lexicon	O
such	O
as	O
WordNet	B-DATASET
.	O

The	O
average	O
polysemy	B-METRIC
is	O
1	O
.	O
3	O
and	O
2	O
.	O
5	O
for	O
WordNet	O
senses	O
and	O
Wikipages	O
,	O
respectively	O
(	O
2	O
.	O
8	O
and	O
4	O
.	O
7	O
when	O
excluding	O
monosemous	O
words	O
)	O
.	O

The	O
results	O
show	O
that	O
the	O
different	O
regions	O
of	O
BabelNet	O
contain	O
translations	O
of	O
different	O
quality	O
:	O
while	O
on	O
average	O
translations	O
for	O
WordNet	O
-	O
only	O
synsets	O
have	O
a	O
precision	B-METRIC
around	O
72	O
%	O
,	O
when	O
Wikipedia	O
comes	O
into	O
play	O
the	O
performance	O
increases	O
considerably	O
(	O
around	O
80	O
%	O
in	O
the	O
intersection	O
and	O
95	O
%	O
with	O
Wikipedia	O
-	O
only	O
translations	O
)	O
.	O

The	O
challenges	O
of	O
Named	B-TASK
Entities	I-TASK
Recognition	I-TASK
(	I-TASK
NER	I-TASK
)	I-TASK
for	O
tweets	O
lie	O
in	O
the	O
insufficient	O
information	O
in	O
a	O
tweet	O
and	O
the	O
unavailabil	O
-	O
ity	O
of	O
training	O
data	O
.	O

For	O
example	O
,	O
the	O
average	O
F1	B-METRIC
of	O
the	O
Stanford	B-DATASET
NER	I-DATASET
(	O
)	O
,	O
which	O
is	O
trained	O
on	O
the	O
CoNLL03	B-DATASET
shared	I-DATASET
task	I-DATASET
data	I-DATASET
set	I-DATASET
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
that	O
task	O
,	O
drops	O
from	O
90	O
.	O
8	O
%	O
)	O
to	O
45	O
.	O
8	O
%	O
on	O
tweets	O
.	O

Firstly	O
,	O
a	O
K	O
-	O
Nearest	O
Neighbors	O
(	O
KNN	O
)	O
based	O
classifier	O
is	O
adopted	O
to	O
conduct	O
word	B-TASK
level	I-TASK
classification	I-TASK
,	O
leveraging	O
the	O
similar	O
and	O
recently	O
labeled	O
tweets	O
.	O

For	O
every	O
type	O
of	O
named	O
entity	O
,	O
Precision	B-METRIC
(	I-METRIC
Pre	I-METRIC
.	I-METRIC
)	I-METRIC
,	O
recall	B-METRIC
(	I-METRIC
Rec	I-METRIC
.	I-METRIC
)	I-METRIC
and	O
F1	B-METRIC
are	O
used	O
as	O
the	O
evaluation	O
metrics	O
.	O

Precision	B-METRIC
is	O
a	O
measure	O
of	O
what	O
percentage	O
the	O
output	O
labels	O
are	O
correct	O
,	O
and	O
recall	B-METRIC
tells	O
us	O
to	O
what	O
percentage	O
the	O
labels	O
in	O
the	O
gold	O
-	O
standard	O
data	O
set	O
are	O
correctly	O
labeled	O
,	O
while	O
F1	B-METRIC
is	O
the	O
harmonic	O
mean	O
of	O
precision	B-METRIC
and	O
recall	B-METRIC
.	O

The	O
experimental	O
results	O
on	O
three	O
NIST	B-DATASET
evaluation	I-DATASET
test	I-DATASET
sets	I-DATASET
show	O
that	O
our	O
method	O
leads	O
to	O
significant	O
improvements	O
in	O
translation	B-TASK
accuracy	B-METRIC
over	O
the	O
baseline	O
systems	O
.	O
.	O

The	O
data	O
set	O
used	O
for	O
weight	O
training	O
in	O
boostingbased	O
system	O
combination	O
comes	O
from	O
NIST	B-DATASET
MT03	I-DATASET
evaluation	I-DATASET
set	I-DATASET
.	O

Moreover	O
,	O
ILP	O
scale	O
doubles	O
recall	B-METRIC
comparing	O
to	O
the	O
rules	O
from	O
the	O
Sherlock	O
resource	O
,	O
while	O
maintaining	O
comparable	O
precision	B-METRIC
.	O

Though	O
recent	O
knowledge	O
graph	O
embeddings	O
(	O
)	O
integrate	O
the	O
relational	O
structure	O
among	O
entities	O
,	O
they	O
primarily	O
target	O
at	O
link	B-TASK
prediction	I-TASK
and	O
lack	O
an	O
explicit	O
relatedness	O
measure	O
.	O

In	O
the	O
entity	B-TASK
linking	I-TASK
task	I-TASK
,	O
our	O
approach	O
improves	O
the	O
F1	B-METRIC
score	I-METRIC
by	O
10	O
%	O
over	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O

We	O
show	O
that	O
including	O
N	O
-	O
gram	O
count	O
features	O
can	O
advance	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-METRIC
on	O
standard	O
data	O
sets	O
for	O
adjective	B-TASK
ordering	I-TASK
,	O
spelling	B-TASK
correction	I-TASK
,	O
noun	B-TASK
compound	I-TASK
bracketing	I-TASK
,	O
and	O
verb	B-TASK
part	I-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
dis	I-TASK
-	I-TASK
ambiguation	I-TASK
.	O

We	O
address	O
these	O
questions	O
on	O
two	O
generation	O
and	O
two	O
analysis	O
tasks	O
,	O
using	O
both	O
existing	O
N	O
-	O
gram	O
data	O
and	O
a	O
novel	O
web	O
-	O
scale	O
N	O
-	O
gram	O
corpus	O
that	O
includes	O
part	O
-	O
of	O
-	O
speech	O
information	O
(	O
Section	O
2	O
)	O
.	O

Systems	O
trained	O
on	O
labeled	O
data	O
can	O
learn	O
the	O
domain	O
usage	O
and	O
leverage	O
other	O
regularities	O
,	O
such	O
as	O
suffixes	O
and	O
transitivity	O
for	O
adjective	O
ordering	O
.	O

With	O
these	O
benefits	O
,	O
systems	O
trained	O
on	O
labeled	O
data	O
have	O
become	O
the	O
dominant	O
technology	O
in	O
academic	O
NLP	O
.	O

Our	O
results	O
show	O
that	O
using	O
web	O
-	O
scale	O
N	O
-	O
gram	O
data	O
in	O
supervised	O
systems	O
advances	O
the	O
state	O
-	O
ofthe	O
-	O
art	O
performance	O
on	O
standard	O
analysis	O
and	O
generation	O
tasks	O
.	O

We	O
evaluate	O
the	O
benefit	O
of	O
N	O
-	O
gram	O
data	O
on	O
multiclass	B-TASK
classification	I-TASK
problems	O
.	O

We	O
plot	O
learning	O
curves	O
to	O
measure	O
the	O
accuracy	B-METRIC
of	O
the	O
classifier	O
when	O
the	O
number	O
of	O
labeled	O
training	O
examples	O
varies	O
.	O

In	O
an	O
experimental	O
evaluation	O
on	O
the	O
tasks	O
of	O
synonym	B-TASK
extraction	I-TASK
and	O
bilingual	B-TASK
lexicon	I-TASK
extraction	I-TASK
,	O
CoSimRank	O
is	O
faster	O
or	O
more	O
accurate	O
than	O
previous	O
approaches	O
.	O
.	O

This	O
is	O
a	O
crucial	O
task	O
for	O
financial	O
and	O
security	O
analysts	O
who	O
are	O
interested	O
in	O
pulling	O
together	O
relevant	O
information	O
from	O
unstructured	O
and	O
noisy	O
data	O
streams	O
.	O

We	O
employ	O
the	O
post	O
-	O
ordering	O
framework	O
proposed	O
by	O
(	O
Sudoh	O
et	O
al	O
.	O
,	O
2011b	O
)	O
for	O
Japanese	B-TASK
to	I-TASK
English	I-TASK
translation	I-TASK
and	O
improve	O
upon	O
the	O
reordering	O
method	O
.	O

The	O
word	B-TASK
reordering	I-TASK
problem	O
is	O
a	O
challenging	O
one	O
when	O
translating	O
between	O
languages	O
with	O
widely	O
different	O
word	O
orders	O
such	O
as	O
Japanese	O
and	O
English	O
.	O

In	O
English	B-TASK
-	I-TASK
Japanese	I-TASK
translation	I-TASK
,	O
proposed	O
a	O
simple	O
pre	O
-	O
ordering	O
method	O
that	O
achieved	O
the	O
best	O
quality	O
inhuman	O
evaluations	O
,	O
which	O
were	O
conducted	O
for	O
the	O
NTCIR	B-TASK
-	I-TASK
9	I-TASK
patent	I-TASK
machine	I-TASK
translation	I-TASK
task	I-TASK
(	O
)	O
.	O

Pre	O
-	O
ordering	O
using	O
the	O
head	B-TASK
finalization	I-TASK
rule	O
naturally	O
cannot	O
be	O
applied	O
to	O
Japanese	B-TASK
-	I-TASK
English	I-TASK
translation	I-TASK
,	O
because	O
English	O
is	O
not	O
a	O
head	O
-	O
final	O
language	O
.	O

2	O
Post	O
-	O
ordering	O
for	O
Japanese	O
to	O
English	O
proposed	O
a	O
post	O
-	O
ordering	O
method	O
for	O
Japanese	B-TASK
-	I-TASK
English	I-TASK
translation	I-TASK
.	O

Using	O
Anaphora	O
Resolution	O
to	O
Improve	B-TASK
Opinion	I-TASK
Target	I-TASK
Identification	I-TASK
in	I-TASK
Movie	I-TASK
Reviews	I-TASK

Our	O
experiments	O
on	O
a	O
movie	B-DATASET
review	I-DATASET
corpus	I-DATASET
demonstrate	O
,	O
that	O
an	O
unsupervised	O
anaphora	O
resolution	O
algorithm	O
significantly	O
improves	O
the	O
opinion	B-TASK
target	I-TASK
extraction	I-TASK
.	O

This	O
paper	O
is	O
structured	O
as	O
follows	O
:	O
Section	O
2	O
discusses	O
the	O
related	O
work	O
on	O
opinion	B-TASK
target	I-TASK
identification	I-TASK
and	O
OM	B-TASK
on	I-TASK
movie	I-TASK
reviews	I-TASK
.	O

Over	O
four	O
different	O
datasets	O
spanning	O
from	O
the	O
product	O
review	O
to	O
the	O
essay	O
domain	O
,	O
we	O
demonstrate	O
that	O
features	O
driven	O
from	O
Context	O
Free	O
Grammar	O
(	O
CFG	O
)	O
parse	O
trees	O
consistently	O
improve	O
the	O
detection	O
performance	O
over	O
several	O
baselines	O
that	O
are	O
based	O
only	O
on	O
shallow	O
lexico	O
-	O
syntactic	O
features	O
.	O

Our	O
results	O
improve	O
the	O
best	O
published	O
result	O
on	O
the	O
hotel	B-DATASET
review	I-DATASET
data	I-DATASET
(	I-DATASET
Ott	I-DATASET
et	I-DATASET
al	I-DATASET
.	I-DATASET
,	I-DATASET
2011	I-DATASET
)	I-DATASET
reaching	O
91	O
.	O
2	O
%	O
accuracy	B-METRIC
with	O
14	O
%	O
error	B-METRIC
reduction	I-METRIC
.	O
.	O

Over	O
four	O
different	O
datasets	O
spanning	O
from	O
the	O
product	O
review	O
domain	O
to	O
the	O
essay	O
domain	O
,	O
we	O
find	O
that	O
features	O
driven	O
from	O
Context	O
Free	O
Grammar	O
(	O
CFG	O
)	O
parse	O
trees	O
consistently	O
improve	O
the	O
detection	O
performance	O
over	O
several	O
baselines	O
that	O
are	O
based	O
only	O
on	O
shallow	O
lexico	O
-	O
syntactic	O
features	O
.	O

Our	O
results	O
improve	O
the	O
best	O
published	O
result	O
on	O
the	O
hotel	B-DATASET
review	I-DATASET
data	I-DATASET
of	O
reaching	O
91	O
.	O
2	O
%	O
accuracy	B-METRIC
with	O
14	O
%	O
error	B-METRIC
reduction	I-METRIC
.	O

We	O
also	O
achieve	O
substantial	O
improvement	O
over	O
the	O
essay	O
data	O
of	O
,	O
obtaining	O
upto	O
85	O
.	O
0	O
%	O
accuracy	B-METRIC
.	O

For	O
Chinese	O
,	O
we	O
use	O
CTB	B-DATASET
5	I-DATASET
.	I-DATASET
1	I-DATASET
and	O
the	O
split	O
suggested	O
by	O
)	O
for	O
both	O
tagging	B-TASK
and	O
dependency	B-TASK
parsing	I-TASK
.	O

Table	O
5	O
:	O
Parsing	B-TASK
results	O
on	O
CTB	B-DATASET
test	I-DATASET
set	I-DATASET
.	O

Part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
Speech	I-TASK
Tagging	I-TASK
for	O
Twitter	O
:	O
Annotation	O
,	O
Features	O
,	O
and	O
Experiments	O

We	O
address	O
the	O
problem	O
of	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
tagging	I-TASK
for	O
English	O
data	O
from	O
the	O
popular	O
micro	O
-	O
blogging	O
service	O
Twitter	O
.	O

We	O
develop	O
a	O
tagset	O
,	O
annotate	O
data	O
,	O
develop	O
features	O
,	O
and	O
report	O
tagging	O
results	O
nearing	O
90	O
%	O
accuracy	B-METRIC
.	O

The	O
data	O
and	O
tools	O
have	O
been	O
made	O
available	O
to	O
the	O
research	O
community	O
with	O
the	O
goal	O
of	O
enabling	O
richer	O
text	O
analysis	O
of	O
Twitter	O
and	O
related	O
social	O
media	O
data	O
sets	O
.	O
.	O

Tagging	O
performance	O
degrades	O
on	O
out	O
-	O
of	O
-	O
domain	O
data	O
,	O
and	O
Twitter	O
poses	O
additional	O
challenges	O
due	O
to	O
the	O
conversational	O
nature	O
of	O
the	O
text	O
,	O
the	O
lack	O
of	O
conventional	O
orthography	O
,	O
and	O
140	O
-	O
character	O
limit	O
of	O
each	O
message	O
(	O
"	O
tweet	O
"	O
)	O
.	O

Our	O
contributions	O
are	O
as	O
follows	O
:	O
โข	O
we	O
developed	O
a	O
POS	O
tagset	O
for	O
Twitter	O
,	O
โข	O
we	O
manually	O
tagged	O
1	O
,	O
827	O
tweets	O
,	O
โข	O
we	O
developed	O
features	O
for	O
Twitter	O
POS	O
tagging	O
and	O
conducted	O
experiments	O
to	O
evaluate	O
them	O
,	O
and	O
โข	O
we	O
provide	O
our	O
annotated	O
corpus	O
and	O
trained	O
POS	O
tagger	O
to	O
the	O
research	O
community	O
.	O

The	O
success	O
of	O
this	O
approach	O
demonstrates	O
that	O
with	O
careful	O
design	O
,	O
supervised	O
machine	O
learning	O
can	O
be	O
applied	O
to	O
rapidly	O
produce	O
effective	O
language	O
technology	O
in	O
new	O
domains	O
.	O

Our	O
evaluation	O
was	O
designed	O
to	O
test	O
the	O
efficacy	O
of	O
this	O
feature	O
set	O
for	O
part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
speech	I-TASK
tagging	I-TASK
given	O
limited	O
training	O
data	O
.	O

Table	O
2	O
:	O
Memory	B-METRIC
usage	I-METRIC
and	O
average	O
per	O
-	O
sentence	O
running	O
time	O
,	O
in	O
seconds	O
,	O
for	O
decoding	O
a	O
Chinese	O
-	O
English	O
test	O
set	O
.	O

In	O
this	O
paper	O
we	O
quantify	O
and	O
disentangle	O
the	O
impact	O
of	O
genre	O
and	O
topic	O
differences	O
on	O
translation	O
quality	O
by	O
introducing	O
anew	O
data	O
set	O
that	O
has	O
controlled	O
topic	O
and	O
genre	O
distributions	O
.	O

Training	O
corpora	O
for	O
statistical	B-TASK
machine	I-TASK
translation	I-TASK
(	I-TASK
SMT	I-TASK
)	I-TASK
are	O
typically	O
collected	O
from	O
a	O
wide	O
variety	O
of	O
sources	O
and	O
therefore	O
have	O
varying	O
textual	O
characteristics	O
such	O
as	O
writing	O
style	O
and	O
vocabulary	O
.	O

Since	O
most	O
work	O
on	O
domain	B-TASK
adaptation	I-TASK
in	O
SMT	B-TASK
uses	O
in	O
-	O
domain	O
and	O
out	O
-	O
of	O
-	O
domain	O
data	O
that	O
differ	O
on	O
both	O
the	O
topic	O
and	O
the	O
genre	O
level	O
,	O
it	O
is	O
unclear	O
whether	O
the	O
proposed	O
solutions	O
address	O
topic	O
or	O
genre	O
differences	O
.	O

We	O
demonstrate	O
that	O
statistics	O
over	O
discourse	O
relations	O
,	O
collected	O
via	O
explicit	O
discourse	O
markers	O
as	O
proxies	O
,	O
can	O
be	O
utilized	O
as	O
salient	O
indicators	O
for	O
paradig	O
-	O
matic	O
relations	O
in	O
multiple	O
languages	O
,	O
out	O
-	O
performing	O
patterns	O
in	O
terms	O
of	O
recall	B-METRIC
and	O
F	B-METRIC
1	I-METRIC
-	I-METRIC
score	I-METRIC
.	O

In	O
almost	O
all	O
classification	O
tasks	O
,	O
our	O
markerbased	O
model	O
achieves	O
a	O
higher	O
recall	B-METRIC
and	O
F	B-METRIC
1	I-METRIC
-	I-METRIC
score	I-METRIC
than	O
the	O
pattern	O
-	O
based	O
approach	O
.	O

in	O
recall	B-METRIC
and	O
F	B-METRIC
1	I-METRIC
-	I-METRIC
score	I-METRIC
,	O
leading	O
to	O
the	O
best	O
3	O
-	O
way	O
classification	O
results	O
.	O

A	O
System	O
for	O
Summarizing	B-TASK
Scientific	I-TASK
Topics	I-TASK
Starting	O
from	O
Keywords	O

We	O
discuss	O
the	O
issues	O
of	O
robust	O
evaluation	O
of	O
such	O
systems	O
and	O
describe	O
an	O
evaluation	O
corpus	O
we	O
generated	O
by	O
manually	O
extracting	O
factoids	O
,	O
or	O
information	O
units	O
,	O
from	O
47	O
gold	O
standard	O
documents	O
(	O
surveys	O
and	O
tutorials	O
)	O
on	O
seven	O
topics	O
in	O
Natural	O
Language	O
Processing	O
.	O

We	O
built	O
a	O
factoid	O
inventory	O
for	O
seven	O
topics	O
in	O
NLP	O
based	O
on	O
manual	O
written	O
surveys	O
in	O
the	O
following	O
way	O

As	O
compared	O
to	O
the	O
previous	O
works	O
,	O
our	O
method	O
takes	O
advantage	O
of	O
both	O
the	O
in	O
-	O
domain	O
monolingual	O
corpora	O
and	O
the	O
out	O
-	O
of	O
-	O
domain	O
bilingual	O
corpus	O
to	O
incorporate	O
the	O
topic	O
information	O
into	O
our	O
translation	O
model	O
,	O
thus	O
breaking	O
down	O
the	O
corpus	O
barrier	O
for	O
translation	O
quality	O
improvement	O
.	O

On	O
general	O
domain	O
and	O
speech	B-TASK
translation	I-TASK
tasks	O
where	O
test	O
conditions	O
substantially	O
differ	O
from	O
standard	O
government	O
and	O
news	O
training	O
text	O
,	O
web	O
-	O
mined	O
training	O
data	O
improves	O
performance	O
substantially	O
,	O
resulting	O
in	O
improvements	O
of	O
up	O
to	O
1	O
.	O
5	O
BLEU	B-METRIC
on	O
standard	O
test	O
sets	O
,	O
and	O
5	O
BLEU	B-METRIC
on	O
test	O
sets	O
outside	O
of	O
the	O
news	O
domain	O
.	O

2	O
Edit	O
rate	O
for	O
paraphrase	B-TASK
alignment	I-TASK
TER	B-METRIC
-	I-METRIC
PLUS	I-METRIC
(	I-METRIC
Translation	I-METRIC
Edit	I-METRIC
Rate	I-METRIC
Plus	I-METRIC
)	I-METRIC
)	O
is	O
a	O
score	O
designed	O
for	O
evaluation	O
of	O
Machine	B-TASK
Translation	I-TASK
(	I-TASK
MT	I-TASK
)	I-TASK
output	O
.	O

In	O
selecting	O
high	O
-	O
quality	O
training	O
data	O
,	O
it	O
is	O
important	O
to	O
take	O
two	O
aspects	O
of	O
data	O
into	O
consideration	O
:	O
quantity	O
and	O
quality	O
.	O

We	O
present	O
Conditional	O
Random	O
Fields	O
based	O
approaches	O
for	O
detecting	B-TASK
agreement	I-TASK
/	I-TASK
disagreement	I-TASK
between	I-TASK
speakers	I-TASK
in	I-TASK
English	I-TASK
broadcast	I-TASK
conversation	I-TASK
shows	I-TASK
.	O

When	O
reduced	O
to	O
a	O
binary	O
classification	O
evaluation	O
using	O
the	O
VU	B-DATASET
Amsterdam	I-DATASET
Metaphor	I-DATASET
Corpus	I-DATASET
,	O
the	O
system	O
achieves	O
an	O
F	B-METRIC
-	I-METRIC
Measure	I-METRIC
of	O
0	O
.	O
608	O
,	O
slightly	O
lower	O
than	O
the	O
comparable	O
binary	O
classification	O
system	O
'	O
s	O
0	O
.	O
638	O
and	O
competitive	O
with	O
existing	O
approaches	O
.	O
.	O

(	O
i	O
)	O
we	O
present	O
anew	O
framework	O
of	O
Scalable	O
Online	O
Learning	O
Algorithms	O
for	O
Ranking	O
,	O
which	O
tackles	O
the	O
pairwise	O
learning	O
to	O
ranking	O
problem	O
via	O
a	O
scalable	O
online	O
learning	O
approach	O
;	O

(	O
ii	O
)	O
we	O
present	O
two	O
SOLAR	O
algorithms	O
:	O
a	O
first	O
-	O
order	O
learning	O
algorithm	O
(	O
SOLAR	O
-	O
I	O
)	O
and	O
a	O
second	O
-	O
order	O
learning	O
algorithm	O
(	O
SOLAR	O
-	O
II	O
)	O
;	O

(	O
iii	O
)	O
we	O
analyze	O
the	O
theoretical	O
bounds	O
of	O
the	O
proposed	O
algorithms	O
in	O
terms	O
of	O
standard	O
IR	O
performance	O
measures	O
;	O

and	O
(	O
iv	O
)	O
finally	O
we	O
examine	O
the	O
efficacy	O
of	O
the	O
proposed	O
algorithms	O
by	O
an	O
extensive	O
set	O
of	O
empirical	O
studies	O
on	O
benchmark	O
datasets	O
.	O

Recently	O
,	O
these	O
cleanup	O
templates	O
have	O
been	O
used	O
for	O
automatically	O
identifying	O
articles	O
with	O
particular	O
quality	O
flaws	O
in	O
order	O
to	O
support	O
Wikipedia	O
'	O
s	O
quality	O
assurance	O
process	O
in	O
Wikipedia	O
.	O

Hierarchies	O
can	O
combat	O
data	O
sparsity	O
:	O
if	O
data	O
is	O
too	O
sparse	O
to	O
place	O
the	O
term	O
"	O
Pau	O
Gasol	O
"	O
within	O
the	O
Chicago	O
Bulls	O
topic	O
,	O
perhaps	O
it	O
can	O
be	O
appropriately	O
modeled	O
at	O
somewhat	O
less	O
precision	O
within	O
the	O
Basketball	O
topic	O
.	O

Motivated	O
by	O
the	O
idea	O
of	O
using	O
topic	O
model	O
and	O
external	O
knowledge	O
mentioned	O
above	O
,	O
we	O
present	O
an	O
LDA	O
-	O
based	O
enriching	O
method	O
using	O
the	O
news	O
corpus	O
,	O
and	O
apply	O
it	O
to	O
the	O
task	O
of	O
microblog	B-TASK
classification	I-TASK
.	O

Prior	O
research	O
on	O
language	B-TASK
identification	I-TASK
focused	O
primarily	O
on	O
text	O
and	O
speech	O
.	O

Treebanks	O
,	O
sets	O
of	O
parsed	O
sentences	O
annotated	O
with	O
a	O
sytactic	O
structure	O
,	O
are	O
an	O
important	O
resource	O
in	O
NLP	O
.	O

Bilingual	B-TASK
sentence	I-TASK
alignment	I-TASK
is	O
a	O
fundamental	O
task	O
to	O
undertake	O
for	O
the	O
purpose	O
of	O
facilitating	O
many	O
important	O
natural	O
language	O
processing	O
applications	O
such	O
as	O
statistical	B-TASK
machine	I-TASK
translation	I-TASK
(	O
,	O
bilingual	O
lexicography	O
(	O
,	O
and	O
cross	B-TASK
-	I-TASK
language	I-TASK
information	I-TASK
retrieval	I-TASK
)	O
.	O

Although	O
our	O
framework	O
requires	O
labeled	O
training	O
data	O
for	O
each	O
type	O
of	O
focused	O
summary	O
(	O
decisions	O
,	O
problems	O
,	O
etc	O
.	O
)	O
,	O
we	O
also	O
make	O
initial	O
tries	O
for	O
domain	O
adaptation	O
so	O
that	O
our	O
summarization	O
method	O
does	O
not	O
need	O
human	O
-	O
written	O
abstracts	O
for	O
each	O
new	O
meeting	O
domain	O
(	O
e	O
.	O
g	O
.	O

This	O
means	O
that	O
users	O
cannot	O
switch	O
between	O
information	O
and	O
navigation	O
tasks	O
in	O
a	O
natural	O
and	O
fluid	O
manner	O
.	O
:	O
An	O
example	O
interaction	O
with	O
the	O
evaluated	O
system	O
In	O
contrast	O
to	O
many	O
existing	O
mobile	O
apps	O
,	O
Spacebook	O
has	O
a	O
speech	O
-	O
only	O
interface	O
and	O
addresses	O
both	O
problems	O
in	O
an	O
integrated	O
way	O
.	O

Past	O
work	O
,	O
e	O
.	O
g	O
.	O
,	O
generally	O
focuses	O
on	O
semi	O
-	O
automatic	O
acquisition	O
of	O
the	O
remaining	O
members	O
of	O
the	O
set	O
by	O
mining	O
large	O
amounts	O
of	O
unlabeled	O
data	O
.	O

We	O
present	O
a	O
set	O
of	O
dependency	O
-	O
based	O
pre	O
-	O
ordering	O
rules	O
which	O
improved	O
the	O
BLEU	B-METRIC
score	O
by	O
1	O
.	O
61	O
on	O
the	O
NIST	B-DATASET
2006	I-DATASET
evaluation	I-DATASET
data	I-DATASET
.	O

Experiments	O
on	O
Chinese	O
-	O
to	O
-	O
English	O
show	O
that	O
our	O
RST	O
-	O
based	O
approach	O
achieves	O
improvements	O
of	O
2	O
.	O
3	O
/	O
0	O
.	O
77	O
/	O
1	O
.	O
43	O
BLEU	B-METRIC
points	O
on	O
NIST04	B-DATASET
/	O
NIST05	B-DATASET
/	I-DATASET
CWMT2008	I-DATASET
respectively	O
.	O

As	O
such	O
,	O
we	O
have	O
begun	O
to	O
see	O
some	O
research	O
efforts	O
in	O
mining	O
experience	O
-	O
related	O
attributes	O
such	O
as	O
time	O
,	O
location	O
,	O
topic	O
,	O
and	O
experiencer	O
,	O
and	O
their	O
relations	O
from	O
weblogs	O
.	O

On	O
the	O
Wikipedia	B-DATASET
development	I-DATASET
data	I-DATASET
,	O
we	O
annotated	O
500	O
logical	O
forms	O
,	O
underspecified	O
logical	O
forms	O
and	O
constant	O
mappings	O
for	O
ontology	B-TASK
matching	I-TASK
.	O

We	O
perform	O
all	O
of	O
our	O
experiments	O
on	O
en	O
-	O
ja	O
and	O
ja	O
-	O
en	O
translation	O
over	O
data	O
from	O
the	O
NTCIR	B-DATASET
PatentMT	I-DATASET
task	I-DATASET
)	O
,	O
the	O
most	O
standard	O
benchmark	O
task	O
for	O
these	O
language	O
pairs	O
.	O

Summarisation	O
of	O
time	O
-	O
series	O
data	O
refers	O
to	O
the	O
task	O
of	O
automatically	O
generating	O
text	O
from	O
variables	O
whose	O
values	O
changeover	O
time	O
.	O

In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
methodological	O
approach	O
to	O
temporal	B-TASK
anchoring	I-TASK
of	I-TASK
relations	I-TASK
automatically	I-TASK
extracted	I-TASK
from	I-TASK
unrestricted	I-TASK
text	I-TASK
.	O

This	O
demonstrates	O
that	O
,	O
bilingual	O
active	O
learning	O
with	O
jointly	O
selecting	O
the	O
unlabeled	O
instances	O
cannot	O
only	O
enhance	O
relation	B-TASK
classification	I-TASK
for	O
its	O
own	O
language	O
,	O
but	O
also	O
help	O
relation	B-TASK
classification	I-TASK
for	O
the	O
other	O
language	O
due	O
to	O
the	O
complementary	O
nature	O
of	O
relation	O
instances	O
between	O
Chinese	O
and	O
English	O
.	O

We	O
evaluate	O
our	O
parsers	O
on	O
the	O
Penn	B-DATASET
Tree	I-DATASET
-	I-DATASET
bank	I-DATASET
and	O
Prague	B-DATASET
Dependency	I-DATASET
Treebank	I-DATASET
,	O
achieving	O
unlabeled	B-METRIC
attachment	I-METRIC
scores	I-METRIC
of	O
93	O
.	O
04	O
%	O
and	O
87	O
.	O
38	O
%	O
,	O
respectively	O
.	O
.	O

When	O
updating	O
models	O
overtime	O
based	O
on	O
Twitter	O
,	O
we	O
find	O
that	O
political	O
preference	O
can	O
be	O
often	O
be	O
predicted	O
using	O
roughly	O
100	O
tweets	O
,	O
depending	O
on	O
the	O
context	O
of	O
user	O
selection	O
,	O
where	O
this	O
could	O
mean	O
hours	O
,	O
or	O
weeks	O
,	O
based	O
on	O
the	O
author	O
'	O
s	O
tweeting	O
frequency	O
.	O
.	O

Table	O
6	O
:	O
Average	O
accuracy	B-METRIC
and	O
oracle	O
scores	O
on	O
development	O
data	O
in	O
various	O
system	O
settings	O
.	O

For	O
discontinuous	B-TASK
parsing	I-TASK
,	O
we	O
surpass	O
the	O
current	O
state	O
of	O
the	O
art	O
by	O
a	O
wide	O
margin	O
on	O
two	O
German	O
datasets	O
(	O
TIGER	O
and	O
NEGRA	B-DATASET
)	O
,	O
while	O
achieving	O
fast	O
parsing	B-TASK
speeds	O
.	O

Our	O
approach	O
achieves	O
the	O
best	O
ever	O
performance	O
on	O
the	O
2007	B-DATASET
Medical	I-DATASET
NLP	I-DATASET
Challenge	I-DATASET
test	I-DATASET
set	I-DATASET
,	O
with	O
an	O
F	B-METRIC
-	I-METRIC
measure	I-METRIC
of	O
89	O
.	O
84	O
.	O
.	O

Taking	O
sentiment	O
analysis	O
for	O
dialogues	O
as	O
an	O
example	O
,	O
the	O
topic	O
of	O
the	O
document	O
and	O
the	O
author	O
'	O
s	O
identity	O
are	O
both	O
valuable	O
for	O
mining	O
user	O
'	O
s	O
opinions	O
in	O
the	O
conversation	O
.	O

For	O
Spanish	O
,	O
we	O
removed	O
workers	O
who	O
disagreed	O
with	O
the	O
majority	O
more	O
than	O
50	O
%	O
of	O
the	O
time	O
(	O
83	O
deletions	O
)	O
,	O
leaving	O
6	O
.	O
5	O
annotations	O
for	O
each	O
alignment	O
(	O
85	O
.	O
47	O
%	O
inter	O
-	O
annotator	O
agreement	O
.	O
)	O

Most	O
of	O
them	O
have	O
been	O
proposed	O
in	O
order	O
to	O
make	O
translation	B-TASK
systems	O
perform	O
better	O
for	O
resource	O
-	O
scarce	O
domains	O
when	O
most	O
training	O
data	O
comes	O
from	O
resourcerich	O
domains	O
,	O
and	O
ignore	O
performance	O
on	O
a	O
more	O
generic	O
domain	O
without	O
domain	O
bias	O
(	O
.	O

Mining	O
Informal	O
Language	O
from	O
Chinese	O
Microtext	O
:	O
Joint	O
Word	B-TASK
Recognition	I-TASK
and	I-TASK
Segmentation	I-TASK

We	O
integrate	O
the	O
two	O
proposed	O
models	O
into	O
phrase	B-TASK
-	I-TASK
based	I-TASK
statistical	I-TASK
machine	I-TASK
translation	I-TASK
and	O
conduct	O
experiments	O
on	O
large	O
-	O
scale	O
training	O
data	O
to	O
investigate	O
their	O
effectiveness	O
.	O

The	O
automatically	O
-	O
converted	O
corpus	O
would	O
be	O
of	O
use	O
fora	O
wide	O
variety	O
of	O
NLP	O
tasks	O
.	O

Third	O
,	O
we	O
show	O
that	O
dialectal	O
data	O
can	O
be	O
handled	O
in	O
the	O
framework	O
of	O
domain	O
adaptation	O
.	O

4	O
.	O
1	O
)	O
in	O
its	O
pre	O
-	O
processing	O
module	O
but	O
MARS	B-DATASET
is	O
replaced	O
by	O
a	O
previously	O
developed	O
system	O
)	O
for	O
pronominal	B-TASK
anaphora	I-TASK
resolution	I-TASK
in	O
Bengali	O
.	O

However	O
,	O
as	O
observe	O
,	O
because	O
only	O
5	O
.	O
9	O
%	O
of	O
words	O
in	O
the	O
Switchboard	B-DATASET
corpus	I-DATASET
are	O
"	O
edited	O
"	O
,	O
the	O
trivial	O
baseline	O
classifier	O
which	O
assigns	O
all	O
words	O
the	O
"	O
not	O
edited	O
"	O
label	O
achieves	O
a	O
labelling	O
accuracy	B-METRIC
of	O
94	O
.	O
1	O
%	O
.	O

We	O
propose	O
an	O
automatic	O
standardization	O
for	O
the	O
construction	O
of	O
cross	O
-	O
lingual	O
similarity	O
datasets	O
,	O
and	O
provide	O
an	O
evaluation	O
,	O
demonstrating	O
its	O
reliability	O
and	O
robustness	O
.	O

Our	O
research	O
contributions	O
are	O
as	O
follows	O
:	O
(	O
1	O
)	O
we	O
propose	O
concurrent	O
learning	O
using	O
multi	O
-	O
agent	O
RL	O
as	O
away	O
to	O
deal	O
with	O
some	O
of	O
the	O
issues	O
of	O
current	O
approaches	O
to	O
dialogue	B-TASK
policy	I-TASK
learning	I-TASK
(	O
i	O
.	O
e	O
.	O
,	O
the	O
need	O
for	O
SUs	O
and	O
corpora	O
)	O
,	O
which	O
may	O
also	O
potentially	O
prove	O
useful	O
for	O
learning	O
via	O
live	O
interaction	O
with	O
human	O
users	O
;	O

(	O
2	O
)	O
we	O
show	O
that	O
concurrent	O
learning	O
can	O
address	O
changes	O
in	O
user	O
behavior	O
overtime	O
,	O
and	O
requires	O
multi	O
-	O
agent	O
RL	O
techniques	O
and	O
variable	O
exploration	O
rates	O
;	O

(	O
3	O
)	O
to	O
our	O
knowledge	O
this	O
is	O
the	O
first	O
time	O
that	O
PHC	O
and	O
PHCWoLF	O
are	O
used	O
for	O
learning	O
dialogue	O
policies	O
;	O

In	O
recent	O
years	O
,	O
a	O
number	O
of	O
works	O
(	O
)	O
attempted	O
to	O
build	O
segmentation	O
models	O
for	O
SMT	B-TASK
based	O
on	O
bilingual	O
unsegmented	O
data	O
,	O
instead	O
of	O
monolingual	O
segmented	O
data	O
.	O

Based	O
on	O
the	O
following	O
criteria	O
we	O
selected	O
the	O
maximum	O
number	O
of	O
proposals	O
allowed	O
:	O
1	O
)	O
Quality	O
:	O
the	O
content	O
and	O
scope	O
of	O
the	O
proposal	O
,	O
and	O
the	O
competence	O
and	O
experience	O
of	O
the	O
presenters	O
;	O
2	O
)	O
Diversity	O
:	O
We	O
sought	O
a	O
range	O
of	O
different	O
topics	O
and	O
approaches	O
;	O
3	O
)	O
Appeal	O
:	O
Whether	O
the	O
tutorial	O
topic	O
would	O
be	O
likely	O
to	O
attract	O
a	O
reasonable	O
number	O
of	O
participants	O
;	O
and	O
4	O
)	O
Novelty	O
:	O
Tutorial	O
topics	O
featured	O
at	O
very	O
recent	O
ACL	O
events	O
were	O
dispreferred	O
(	O
unless	O
the	O
content	O
was	O
clearly	O
novel	O
and	O
different	O
)	O
.	O

We	O
evaluate	O
its	O
performance	O
on	O
a	O
creative	O
sentence	B-TASK
generation	I-TASK
task	I-TASK
,	O
showing	O
its	O
capability	O
of	O
generating	O
well	O
-	O
formed	O
,	O
catchy	O
and	O
effective	O
sentences	O
that	O
have	O
all	O
the	O
good	O
qualities	O
of	O
slogans	O
produced	O
by	O
human	O
copywriters	O
.	O
.	O

Unsupervised	O
induction	O
and	O
bilingual	O
projection	O
run	O
according	O
to	O
totally	O
different	O
principles	O
,	O
the	O
former	O
mines	O
the	O
underlying	O
structure	O
of	O
the	O
monolingual	O
language	O
,	O
while	O
the	O
latter	O
leverages	O
the	O
syntactic	O
knowledge	O
of	O
the	O
parsed	O
counter	O
-	O
part	O
language	O
.	O

Beyond	O
reproducing	O
the	O
categorical	O
data	O
in	O
WALS	B-TASK
and	O
extending	O
it	O
to	O
hundreds	O
of	O
other	O
languages	O
,	O
we	O
also	O
provide	O
quantitative	O
data	O
for	O
the	O
relative	O
frequencies	O
of	O
different	O
word	O
orders	O
,	O
and	O
show	O
the	O
usefulness	O
of	O
this	O
for	O
language	O
comparison	O
.	O

This	O
paper	O
presents	O
an	O
unsupervised	O
approach	O
to	O
learning	B-TASK
translation	I-TASK
span	I-TASK
alignments	I-TASK
from	O
parallel	O
data	O
that	O
improves	O
syntactic	B-TASK
rule	I-TASK
extraction	I-TASK
by	O
deleting	O
spurious	O
word	O
alignment	O
links	O
and	O
adding	O
new	O
valuable	O
links	O
based	O
on	O
bilingual	O
translation	O
span	O
correspondences	O
.	O

For	O
example	O
with	O
Spanish	O
-	O
English	O
,	O
by	O
using	O
context	O
-	O
vector	O
similarity	O
only	O
,	O
we	O
obtained	O
very	O
high	O
recall	B-METRIC
/	O
precision	B-METRIC
for	O
the	O
classification	O
of	O
"	O
Non	O
-	O
Translation	O
"	O
,	O
but	O
null	O
precision	B-METRIC
/	O
recall	B-METRIC
for	O
the	O
classification	O
of	O
"	O
Translation	O
"	O
.	O

The	O
comprehensiveness	O
of	O
Wikipedia	O
has	O
made	O
the	O
on	O
-	O
line	O
encyclopedia	O
an	O
increasingly	O
popular	O
target	O
for	O
disambiguation	O
.	O

Second	O
,	O
the	O
original	O
and	O
opposite	O
training	O
samples	O
are	O
used	O
together	O
for	O
training	O
a	O
sentiment	O
classifier	O
(	O
called	O
dual	O
training	O
)	O
,	O
and	O
the	O
original	O
and	O
opposite	O
test	O
samples	O
are	O
used	O
together	O
for	O
prediction	O
(	O
called	O
dual	O
prediction	O
)	O
.	O

We	O
present	O
in	O
this	O
paper	O
the	O
embedding	O
models	O
that	O
achieve	O
an	O
F	B-METRIC
-	I-METRIC
score	I-METRIC
of	O
92	O
%	O
on	O
the	O
widely	O
-	O
used	O
,	O
publicly	O
available	O
dataset	O
,	O
the	O
GRE	O
"	O
most	O
contrasting	O
word	O
"	O
questions	O
(	O
Mohammad	O
et	O
al	O
.	O
,	O
2008	O
)	O
.	O

Preposition	O
attachment	O
mistakes	O
are	O
particularly	O
bad	O
when	O
translating	O
into	O
Japanese	O
(	O
)	O
which	O
uses	O
a	O
different	O
postposition	O
for	O
different	O
attachments	O
;	O
conjunction	O
mistakes	O
can	O
cause	O
word	O
ordering	O
mistakes	O
when	O
translating	O
into	O
Chinese	O
.	O

A	O
typical	O
knowledge	B-TASK
-	I-TASK
based	I-TASK
question	I-TASK
answering	I-TASK
(	I-TASK
KB	I-TASK
-	I-TASK
QA	I-TASK
)	I-TASK
system	O
faces	O
two	O
challenges	O
:	O
one	O
is	O
to	O
transform	O
natural	O
language	O
questions	O
into	O
their	O
meaning	O
representations	O
(	O
MRs	O
)	O
;	O
the	O
other	O
is	O
to	O
retrieve	O
answers	O
from	O
knowledge	O
bases	O
(	O
KBs	O
)	O
using	O
generated	O
MRs	O
.	O

In	O
particular	O
,	O
we	O
discover	O
three	O
new	O
challenges	O
on	O
using	O
temporality	O
for	O
relation	B-TASK
understanding	I-TASK
in	O
comparable	O
corpora	O
,	O
which	O
we	O
discuss	O
in	O
detail	O
in	O
Section	O
3	O
.	O
2	O
.	O

The	O
entity	B-TASK
set	I-TASK
expansion	I-TASK
problem	O
is	O
defined	O
as	O
follows	O
:	O
Given	O
a	O
set	O
S	O
of	O
seed	O
entities	O
of	O
a	O
particular	O
class	O
,	O
and	O
a	O
set	O
D	O
of	O
candidate	O
entities	O
(	O
e	O
.	O
g	O
.	O
,	O
extracted	O
from	O
a	O
text	O
corpus	O
)	O
,	O
we	O
wish	O
to	O
determine	O
which	O
of	O
the	O
entities	O
in	O
D	O
belong	O
to	O
S	O
.	O

Tri	O
-	O
Training	O
for	O
Authorship	B-TASK
Attribution	I-TASK
with	O
Limited	O
Training	O
Data	O

We	O
conduct	O
experiments	O
on	O
the	O
data	O
from	O
the	O
task	O
B	O
of	O
Sentiment	B-TASK
Analysis	I-TASK
in	I-TASK
Twitter	I-TASK
in	I-TASK
SemEval	I-TASK
-	I-TASK
2013	I-TASK
.	O

Unsupervised	O
Part	B-TASK
-	I-TASK
of	I-TASK
-	I-TASK
Speech	I-TASK
Tagging	I-TASK
with	O
Bilingual	O
Graph	O
-	O
Based	O
Projections	O

Some	O
of	O
the	O
future	O
research	O
directions	O
of	O
semantic	B-TASK
parsing	I-TASK
with	O
potentially	O
large	O
impacts	O
include	O
mapping	O
entire	O
natural	O
language	O
documents	O
into	O
machine	O
processable	O
form	O
to	O
enable	O
automated	O
reasoning	O
about	O
them	O
and	O
to	O
convert	O
natural	O
language	O
web	O
pages	O
into	O
machine	O
processable	O
representations	O
for	O
the	O
Semantic	O
Web	O
to	O
support	O
automated	O
high	O
-	O
end	O
web	O
applications	O
.	O

Comparing	O
Multi	B-TASK
-	I-TASK
label	I-TASK
Classification	I-TASK
with	O
Reinforcement	O
Learning	O
for	O
Summarisation	B-TASK
of	I-TASK
Time	I-TASK
-	I-TASK
series	I-TASK
Data	O

Applying	O
our	O
label	O
candidate	O
generation	O
methodology	O
to	O
these	O
228	O
topics	O
produced	O
approximately	O
6000	O
labels	O
-	O
an	O
average	O
of	O
27	O
labels	O
per	O
topic	O
.	O
:	O
A	O
screenshot	O
of	O
the	O
topic	B-TASK
label	I-TASK
evaluation	I-TASK
task	I-TASK
on	O
Amazon	B-DATASET
Mechanical	I-DATASET
Turk	I-DATASET
.	O

To	O
date	O
,	O
the	O
conventional	O
wisdom	O
in	O
the	O
error	B-TASK
detection	I-TASK
community	O
has	O
been	O
to	O
avoid	O
the	O
use	O
of	O
statistical	O
parsers	O
under	O
the	O
belief	O
that	O
a	O
WSJ	O
trained	O
parser	O
'	O
s	O
performance	O
would	O
degrade	O
too	O
much	O
on	O
noisy	O
learner	O
texts	O
and	O
that	O
the	O
traditionally	O
hard	O
problem	O
of	O
prepositional	B-TASK
phrase	I-TASK
attachment	I-TASK
would	O
be	O
even	O
harder	O
when	O
parsing	B-TASK
ESL	I-TASK
writing	I-TASK
.	O

Topic	O
model	O
based	O
algorithms	O
applied	O
to	O
social	O
media	O
data	O
have	O
become	O
a	O
mainstream	O
technique	O
in	O
performing	O
various	O
tasks	O
including	O
sentiment	B-TASK
analysis	I-TASK
and	O
event	B-TASK
detection	I-TASK
(	O
)	O
.	O

Table	O
1	O
:	O
Statistics	O
for	O
the	O
bilingual	O
training	O
,	O
development	O
and	O
evaluation	O
datasets	O
.	O

Zero	O
-	O
shot	O
cross	O
-	O
space	O
mapping	O
methods	O
hold	O
great	O
promise	O
as	O
away	O
to	O
scale	O
up	O
annotation	O
tasks	O
well	O
beyond	O
the	O
labels	O
in	O
the	O
training	O
data	O
(	O
e	O
.	O
g	O
.	O
,	O
recognizing	O
objects	O
that	O
were	O
never	O
seen	O
in	O
training	O
)	O
.	O

We	O
also	O
compare	O
different	O
approaches	O
for	O
topic	B-TASK
modeling	I-TASK
,	O
such	O
as	O
cross	B-TASK
-	I-TASK
domain	I-TASK
topic	I-TASK
identification	I-TASK
by	O
utilizing	O
data	O
from	O
newswire	O
domain	O
.	O

Table	O
1	O
:	O
Example	O
German	O
-	O
English	O
translations	O
showing	O
the	O
effect	O
of	O
relaxed	O
matching	O
in	O
the	O
1	B-METRIC
-	I-METRIC
mNCD	I-METRIC
score	I-METRIC
(	O
for	O
rows	O
S	O
)	O
compared	O
with	O
METEOR	B-METRIC
using	O
the	O
exact	O
module	O
only	O
,	O
since	O
the	O
modules	O
stem	O
and	O
synonym	O
are	O
already	O
used	O
in	O
the	O
similarized	O
reference	O
.	O

Wikipedia	B-DATASET
,	O
WordNet	B-DATASET
)	O
for	O
supporting	O
the	O
automatic	O
labelling	O
of	O
topics	O
by	O
deriving	O
candidate	O
labels	O
by	O
means	O
of	O
lexical	O
(	O
or	O
graphbased	O
(	O
)	O
algorithms	O
applied	O
on	O
these	O
sources	O
.	O

ConceptResolver	O
performs	O
both	O
word	B-TASK
sense	I-TASK
induction	I-TASK
and	O
synonym	B-TASK
resolution	I-TASK
on	O
relations	O
extracted	O
from	O
text	O
using	O
an	O
ontology	O
and	O
a	O
small	O
amount	O
of	O
labeled	O
data	O
.	O

In	O
machine	O
learning	O
,	O
there	O
is	O
a	O
class	O
of	O
semisupervised	O
learning	O
algorithms	O
that	O
learns	O
from	O
positive	O
and	O
unlabeled	O
examples	O
(	O
PU	O
learning	O
for	O
short	O
)	O
.	O

To	O
our	O
knowledge	O
,	O
related	O
research	O
has	O
not	O
studied	O
the	O
task	O
of	O
identifying	B-TASK
double	I-TASK
entendres	I-TASK
in	I-TASK
text	I-TASK
or	I-TASK
speech	I-TASK
.	O

A	O
comprehensive	O
CTH	O
is	O
believed	O
to	O
be	O
more	O
useful	O
for	O
information	B-TASK
browsing	I-TASK
,	O
document	B-TASK
organization	I-TASK
and	O
topic	B-TASK
extraction	I-TASK
in	O
new	O
text	O
corpus	O
(	O
)	O
.	O

Precision	B-METRIC
is	O
the	O
fraction	O
of	O
correct	O
alignment	O
judgments	O
returned	O
by	O
the	O
system	O
and	O
recall	B-METRIC
is	O
the	O
fraction	O
of	O
alignment	O
judgments	O
in	O
the	O
gold	O
standard	O
dataset	O
that	O
are	O
correctly	O
returned	O
by	O
the	O
system	O
.	O

Also	O
,	O
CluewebMapping	O
gives	O
reasonably	O
good	O
precision	B-METRIC
on	O
its	O
prediction	O
,	O
despite	O
the	O
noisy	O
nature	O
of	O
web	O
data	O
.	O

Most	O
early	O
works	O
in	O
this	O
area	O
were	O
designed	O
for	O
supervised	O
Information	B-TASK
Extraction	I-TASK
competitions	O
such	O
as	O
MUC	B-DATASET
)	O
and	O
ACE	O
)	O
,	O
which	O
rely	O
on	O
the	O
availability	O
of	O
annotated	O
data	O
.	O

This	O
dataset	O
is	O
used	O
,	O
instead	O
of	O
a	O
more	O
recent	O
one	O
,	O
because	O
no	O
human	O
judgments	O
on	O
adequacy	O
and	O
fluency	O
have	O
been	O
conducted	O
in	O
WMT	B-TASK
after	O
year	O
2007	O
,	O
and	O
human	O
evaluation	O
data	O
is	O
not	O
freely	O
available	O
from	O
MetricsMATR	O
.	O

Currently	O
most	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
Chinese	B-TASK
word	I-TASK
segmentation	I-TASK
(	I-TASK
CWS	I-TASK
)	I-TASK
are	O
based	O
on	O
supervised	O
learning	O
,	O
which	O
depend	O
on	O
large	O
scale	O
annotated	O
corpus	O
.	O

By	O
experimenting	O
on	O
Wikipedia	O
articles	O
to	O
extract	O
the	O
facts	O
in	O
Freebase	B-DATASET
(	O
the	O
top	O
92	O
relations	O
)	O
,	O
we	O
show	O
the	O
impact	O
of	O
these	O
three	O
factors	O
on	O
the	O
accuracy	B-METRIC
of	O
DS	O
and	O
the	O
remarkable	O
improvement	O
led	O
by	O
the	O
proposed	O
approach	O
.	O
.	O

Our	O
aim	O
in	O
this	O
paper	O
is	O
this	O
task	O
of	O
lexical	B-TASK
normalisation	I-TASK
of	I-TASK
noisy	I-TASK
English	I-TASK
text	I-TASK
,	O
with	O
a	O
particular	O
focus	O
on	O
Twitter	O
and	O
SMS	O
messages	O
.	O

These	O
two	O
aspects	O
are	O
not	O
only	O
important	O
from	O
the	O
perspective	O
of	O
developing	O
computer	O
applications	O
for	O
natural	O
languages	O
but	O
also	O
form	O
the	O
key	O
components	O
of	O
language	O
evolution	O
and	O
change	O
.	O

We	O
compared	O
the	O
four	O
systems	O
on	O
datasets	O
used	O
in	O
previous	O
language	B-TASK
identification	I-TASK
research	O
)	O
(	O
EUROGOV	O
,	O
TCL	O
,	O
WIKIPEDIA	O
)	O
,	O
as	O
well	O
as	O
an	O
extract	O
from	O
a	O
biomedical	B-DATASET
parallel	I-DATASET
corpus	I-DATASET
(	I-DATASET
Tiedemann	I-DATASET
,	I-DATASET
2009	I-DATASET
)	I-DATASET
(	I-DATASET
EMEA	I-DATASET
)	I-DATASET
and	O
a	O
corpus	O
of	O
samples	O
from	O
the	O
Europarl	B-DATASET
Parallel	I-DATASET
Corpus	I-DATASET
(	O
)	O
(	O
EUROPARL	O
)	O
.	O

We	O
evaluate	O
against	O
current	O
unsupervised	O
segmentation	O
models	O
to	O
show	O
that	O
including	O
person	O
-	O
specific	O
information	O
improves	O
segmentation	O
performance	O
on	O
meeting	O
corpora	O
and	O
on	O
political	O
debates	O
.	O

Given	O
that	O
turkers	O
annotated	O
answers	O
based	O
on	O
the	O
topic	O
page	O
via	O
a	O
browser	O
,	O
this	O
supports	O
the	O
assumption	O
that	O
the	O
same	O
answer	O
would	O
be	O
located	O
in	O
the	O
topic	O
graph	O
,	O
which	O
is	O
then	O
passed	O
to	O
the	O
QA	O
engine	O
for	O
feature	B-TASK
extraction	I-TASK
and	O
classification	O
.	O

According	O
to	O
the	O
statistics	O
of	O
the	O
bilingual	O
discourse	O
annotation	O
in	O
progress	O
,	O
about	O
1	O
/	O
4	O
of	O
the	O
Chinese	B-TASK
implicit	I-TASK
DCs	I-TASK
are	O
translated	O
to	O
explicit	O
DCs	O
in	O
English	O
.	O

Furthermore	O
,	O
unlike	O
supervised	O
learning	O
methods	O
which	O
require	O
a	O
large	O
corpus	O
of	O
expert	O
adaptive	O
behaviour	O
to	O
train	O
on	O
,	O
we	O
show	O
that	O
effective	O
adaptive	O
policies	O
can	O
be	O
learned	O
from	O
a	O
small	O
dialogue	O
corpus	O
of	O
non	O
-	O
adaptive	O
human	O
-	O
machine	O
interaction	O
,	O
by	O
using	O
a	O
RL	O
framework	O
and	O
a	O
statistical	O
user	O
simulation	O
.	O

Several	O
studies	O
have	O
already	O
shown	O
the	O
validity	O
of	O
using	O
parallel	O
corpora	O
for	O
sense	B-TASK
discrimination	I-TASK
(	O
e	O
.	O
g	O
.	O

Wiktionary	O
paradigm	O
table	O
formats	O
,	O
however	O
,	O
are	O
often	O
complex	O
,	O
nested	O
,	O
2	O
-	O
3	O
dimensional	O
structures	O
intended	O
for	O
human	O
readability	O
rather	O
than	O
machine	O
parsing	O
,	O
and	O
are	O
broadly	O
inconsistent	O
across	O
languages	O
and	O
Wiktionary	O
editions	O
.	O

We	O
present	O
an	O
intrinsic	O
evaluation	O
of	O
the	O
extraction	O
components	O
,	O
and	O
of	O
the	O
informativeness	O
of	O
the	O
summaries	O
;	O
and	O
a	O
user	O
study	O
of	O
the	O
impact	O
of	O
the	O
song	O
review	O
summaries	O
on	O
users	O
'	O
decision	O
making	O
processes	O
.	O

In	O
automatic	O
processing	O
of	O
such	O
multilingual	O
texts	O
,	O
they	O
must	O
first	O
be	O
segmented	O
by	O
language	O
,	O
and	O
the	O
language	O
of	O
each	O
segment	O
must	O
be	O
identified	O
,	O
since	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
NLP	O
applications	O
are	O
built	O
by	O
learning	O
a	O
gold	O
standard	O
for	O
one	O
specific	O
language	O
.	O

Specifically	O
,	O
we	O
propose	O
a	O
novel	O
non	O
-	O
linear	O
distribution	B-TASK
spreading	I-TASK
algorithm	O
,	O
which	O
first	O
uses	O
Delta	O
IDF	O
technique	O
(	O
)	O
to	O
weight	O
features	O
,	O
and	O
then	O
leverages	O
the	O
distribution	O
of	O
Delta	O
IDF	O
scores	O
of	O
a	O
feature	O
across	O
different	O
classes	O
to	O
efficiently	O
recognize	O
discriminative	O
features	O
for	O
the	O
classification	O
task	O
in	O
the	O
presence	O
of	O
mislabeled	O
data	O
.	O

The	O
proposed	O
models	O
are	O
trained	O
on	O
a	O
public	O
Wikipedia	O
corpus	O
,	O
and	O
the	O
learned	O
representations	O
are	O
evaluated	O
on	O
word	B-TASK
analogy	I-TASK
and	O
word	O
similarity	O
tasks	O
.	O

Our	O
main	O
contributions	O
include	O
:	O
โข	O
A	O
news	O
event	O
knowledge	O
base	O
,	O
Storybase	B-DATASET
,	O
with	O
a	O
search	O
interface	O
for	O
news	O
storylines	O
;	O

The	O
introduction	O
of	O
Wikipedia	O
current	O
events	O
as	O
resources	O
for	O
building	O
event	O
knowledge	O
bases	O
and	O
as	O
datasets	O
for	O
event	B-TASK
detection	I-TASK
and	O
storyline	B-TASK
construction	I-TASK
;	O

New	O
approaches	O
for	O
event	B-TASK
clustering	I-TASK
and	O
chaining	O
with	O
experimental	O
comparisons	O
to	O
other	O
baselines	O
.	O

Overall	O
process	O
of	O
building	O
Storybase	O
2	O
Overview	O
and	O
Definitions	O
shows	O
the	O
overall	O
process	O
for	O
building	O
Storybase	O
.	O

The	O
filtered	O
corpus	O
is	O
used	O
for	O
training	O
phrase	O
-	O
based	O
translation	O
models	O
,	O
which	O
can	O
be	O
used	O
directly	O
in	O
translation	O
tasks	O
or	O
combined	O
with	O
base	O
-	O
line	O
models	O
.	O

For	O
this	O
language	O
pair	O
,	O
we	O
evaluate	O
alignment	B-METRIC
error	I-METRIC
rate	I-METRIC
using	O
the	O
manual	O
alignment	O
corpus	O
described	O
by	O
.	O

The	O
lower	O
precision	B-METRIC
for	O
the	O
Blog	B-DATASET
corpus	I-DATASET
appears	O
to	O
be	O
due	O
to	O
the	O
text	O
not	O
being	O
as	O
clean	O
as	O
NYT	B-DATASET
,	O
introducing	O
parser	O
errors	O
.	O

Our	O
approach	O
gives	O
an	O
18	O
%	O
relative	O
BLEU	B-METRIC
gain	O
for	O
Levantine	O
dialectal	O
Arabic	O
.	O

For	O
example	O
one	O
of	O
the	O
results	O
for	O
the	O
query	O
"	O
bell	O
helmet	O
"	O
had	O
a	O
snippet	O
containing	O
"	O
Bell	O
cycling	O
helmets	O
"	O
and	O
we	O
failed	O
to	O
match	O
helmet	O
to	O
helmets	O
.	O
:	O
Precision	B-METRIC
and	O
recall	B-METRIC
of	O
the	O
NNP	O
tag	O
on	O
the	O
longtail	B-DATASET
data	I-DATASET
for	O
the	O
best	O
baseline	O
method	O
and	O
the	O
three	O
transfer	O
methods	O
using	O
that	O
baseline	O
.	O

The	O
most	O
obvious	O
example	O
of	O
this	O
lies	O
in	O
languages	O
that	O
do	O
not	O
separate	O
words	O
with	O
white	O
space	O
such	O
as	O
Chinese	O
,	O
Japanese	O
,	O
or	O
Thai	O
,	O
in	O
which	O
the	O
choice	O
of	O
a	O
segmentation	O
standard	O
has	O
a	O
large	O
effect	O
on	O
translation	B-TASK
accuracy	B-METRIC
(	O
.	O

We	O
used	O
four	O
standard	O
text	O
datasets	O
:	O
two	O
for	O
multiclass	O
document	O
categorization	O
(	O
WebKB	O
and	O
R8	O
)	O
,	O
one	O
for	O
spam	B-TASK
detection	I-TASK
(	O
LingSpam	O
)	O
and	O
one	O
for	O
opinion	B-TASK
mining	I-TASK
(	O
Amazon	O
)	O
so	O
as	O
to	O
coverall	O
the	O
main	O
subtasks	O
of	O
text	B-TASK
categorization	I-TASK
:	O
โข	O
WebKB	O
:	O
4	O
most	O
frequent	O
categories	O
among	O
labeled	O
webpages	O
from	O
various	O
CS	O
departments	O
-	O
split	O
into	O
2	O
,	O
803	O
for	O
training	O
and	O
1	O
,	O
396	O
for	O
test	O
)	O
.	O

The	O
decipherment	O
approach	O
for	O
MT	B-TASK
has	O
recently	O
gained	O
popularity	O
for	O
training	O
and	O
adapting	O
translation	O
models	O
using	O
only	O
monolingual	O
data	O
.	O

We	O
present	O
a	O
reformulation	O
of	O
the	O
word	O
pair	O
features	O
typically	O
used	O
for	O
the	O
task	O
of	O
disambiguating	O
implicit	O
relations	O
in	O
the	O
Penn	B-DATASET
Discourse	I-DATASET
Treebank	I-DATASET
.	O

Table	O
4	O
:	O
Results	O
(	O
BLEU	B-METRIC
%	O
)	O
of	O
Chinese	B-DATASET
-	I-DATASET
to	I-DATASET
-	I-DATASET
English	I-DATASET
large	I-DATASET
data	I-DATASET
(	I-DATASET
CE	I-DATASET
_	I-DATASET
LD	I-DATASET
)	I-DATASET
and	O
small	O
data	O
(	O
CE	O
_	O
SD	O
)	O
NIST	O
task	O
by	O
applying	O
one	O
feature	O
.	O

Experiments	O
on	O
Chinese	B-TASK
-	I-TASK
English	I-TASK
translation	I-TASK
on	O
four	O
NIST	B-DATASET
MT	I-DATASET
test	I-DATASET
sets	I-DATASET
show	O
that	O
the	O
HD	O
-	O
HPB	O
model	O
significantly	O
outperforms	O
Chiang	O
'	O
s	O
model	O
with	O
average	O
gains	O
of	O
1	O
.	O
91	O
points	O
absolute	O
in	O
BLEU	B-METRIC
.	O
.	O

In	O
large	O
-	O
scale	O
experiments	O
for	O
patent	B-TASK
prior	I-TASK
art	I-TASK
search	I-TASK
and	O
cross	B-TASK
-	I-TASK
lingual	I-TASK
retrieval	I-TASK
in	O
Wikipedia	O
,	O
our	O
approach	O
yields	O
considerable	O
improvements	O
over	O
learning	O
-	O
to	O
-	O
rank	O
with	O
either	O
only	O
dense	O
or	O
only	O
sparse	O
features	O
,	O
and	O
over	O
very	O
competitive	O
baselines	O
that	O
combine	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
machine	B-TASK
translation	I-TASK
and	O
retrieval	O
.	O
.	O

This	O
shows	O
the	O
adequacy	O
of	O
the	O
PCFG	O
-	O
LA	O
methodology	O
for	O
parsing	O
the	O
Hebrew	O
treebank	O
,	O
but	O
also	O
goes	O
to	O
show	O
the	O
highly	O
ambiguous	O
nature	O
of	O
the	O
tagging	O
.	O

Although	O
HILDA	O
'	O
s	O
bottom	O
-	O
up	O
approach	O
is	O
aimed	O
at	O
building	O
a	O
discourse	O
tree	O
for	O
the	O
full	O
text	O
,	O
it	O
does	O
not	O
explicitly	O
employ	O
different	O
strategies	O
for	O
withinsentence	O
text	O
spans	O
and	O
cross	B-TASK
-	I-TASK
sentence	I-TASK
text	I-TASK
spans	I-TASK
.	O

A	O
few	O
annotated	O
corpora	O
exist	O
,	O
but	O
they	O
are	O
relatively	O
small	O
and	O
most	O
were	O
developed	O
for	O
broad	O
coverage	O
NLP	O
.	O

Note	O
that	O
we	O
do	O
not	O
use	O
GEOQUERY	B-DATASET
test	I-DATASET
data	I-DATASET
in	O
SMT	B-TASK
training	O
.	O

As	O
we	O
are	O
not	O
really	O
interested	O
in	O
predicting	O
something	O
on	O
the	O
language	O
created	O
by	O
the	O
translator	O
,	O
but	O
rather	O
on	O
the	O
real	O
one	O
,	O
it	O
maybe	O
better	O
to	O
further	O
diminish	O
the	O
role	O
of	O
the	O
translated	O
texts	O
in	O
the	O
learning	O
process	O
.	O

Template	B-TASK
filling	I-TASK
is	O
an	O
IE	B-TASK
task	O
where	O
the	O
goal	O
is	O
to	O
populate	O
the	O
fields	O
of	O
a	O
target	O
relation	O
,	O
for	O
example	O
to	O
extract	O
the	O
attributes	O
of	O
a	O
job	O
posting	O
or	O
to	O
recover	O
the	O
details	O
of	O
a	O
corporate	O
acquisition	O
event	O
from	O
a	O
news	O
story	O
)	O
.	O

use	O
relationships	O
learned	O
between	O
people	O
,	O
organizations	O
,	O
and	O
locations	O
from	O
Wikipedia	O
to	O
aid	O
in	O
toponym	B-TASK
resolution	I-TASK
when	O
such	O
named	O
entities	O
are	O
present	O
,	O
but	O
do	O
not	O
exploit	O
any	O
other	O
textual	O
context	O
.	O

On	O
the	O
other	O
hand	O
,	O
the	O
impact	O
of	O
normalization	O
or	O
NSW	B-TASK
detection	I-TASK
on	O
NER	B-TASK
has	O
not	O
been	O
well	O
studied	O
in	O
social	O
media	O
domain	O
.	O

To	O
answer	O
this	O
question	O
,	O
we	O
focus	O
on	O
two	O
broad	O
-	O
coverage	O
lexical	O
resources	O
of	O
a	O
different	O
nature	O
:	O
Word	B-DATASET
-	I-DATASET
Net	I-DATASET
,	O
as	O
a	O
de	O
-	O
facto	O
standard	O
used	O
in	O
Word	B-TASK
Sense	I-TASK
Disambiguation	I-TASK
experiments	O
;	O
and	O
Wikipedia	O
,	O
as	O
a	O
large	O
coverage	O
,	O
updated	O
encyclopaedic	O
resource	O
which	O
may	O
have	O
a	O
better	O
coverage	O
of	O
relevant	O
senses	O
in	O
Web	O
pages	O
.	O

Chinese	B-TASK
Word	I-TASK
segmentation	I-TASK
is	O
a	O
necessary	O
step	O
in	O
Chinese	B-TASK
-	I-TASK
English	I-TASK
statistical	I-TASK
machine	I-TASK
translation	I-TASK
(	I-TASK
SMT	I-TASK
)	I-TASK
because	O
Chinese	O
sentences	O
do	O
not	O
delimit	O
words	O
by	O
spaces	O
.	O

Maximum	O
matching	O
word	B-TASK
segmentation	I-TASK
is	O
used	O
with	O
a	O
large	O
word	O
vocabulary	O
V	O
extracted	O
from	O
web	O
data	O
provided	O
by	O
(	O
)	O
.	O

To	O
evaluate	O
cross	O
-	O
lingual	O
setting	O
a	O
,	O
the	O
ES	O
training	O
set	O
is	O
translated	O
into	O
English	O
(	O
see	O
Section	O
4	O
)	O
,	O
and	O
an	O
English	O
classifier	O
is	O
trained	O
on	O
the	O
translated	O
data	O
and	O
evaluated	O
on	O
the	O
EN	B-DATASET
test	I-DATASET
set	I-DATASET
(	O
1	O
CL	O
a	O
)	O
.	O

By	O
incorporating	O
a	O
mixture	O
of	O
labeled	O
and	O
unlabeled	O
data	O
,	O
we	O
are	O
able	O
to	O
improve	O
relation	B-TASK
classification	I-TASK
accuracy	B-METRIC
,	O
reduce	O
the	O
need	O
for	O
annotated	O
data	O
,	O
while	O
still	O
retaining	O
the	O
capacity	O
to	O
use	O
labeled	O
data	O
to	O
ensure	O
that	O
specific	O
desired	O
relations	O
are	O
learned	O
.	O

Learning	O
to	O
temporally	O
order	O
events	O
in	O
clinical	O
text	O
is	O
fundamental	O
to	O
understanding	O
patient	O
narratives	O
and	O
key	O
to	O
applications	O
such	O
as	O
longitudinal	O
studies	O
,	O
question	B-TASK
answering	I-TASK
,	O
document	B-TASK
summarization	I-TASK
and	O
information	B-TASK
retrieval	I-TASK
with	O
temporal	O
constraints	O
.	O

One	O
of	O
the	O
challenges	O
for	O
automatic	B-TASK
argumentation	I-TASK
analysis	I-TASK
is	O
that	O
suitable	O
annotated	O
corpora	O
are	O
still	O
very	O
rare	O
,	O
in	O
spite	O
of	O
work	O
by	O
many	O
researchers	O
.	O

The	O
script	O
is	O
based	O
on	O
and	O
produces	O
identical	O
scores	O
to	O
eval06	B-DATASET
.	I-DATASET
pl	I-DATASET
,	O
the	O
official	O
evaluation	O
for	O
the	O
CoNLL	B-TASK
-	I-TASK
X	I-TASK
Shared	I-TASK
Task	I-TASK
on	I-TASK
Multilingual	I-TASK
Dependency	I-TASK
Parsing	I-TASK
(	O
)	O
.	O

Internet	O
forums	O
,	O
blogs	O
,	O
wikis	O
,	O
podcasts	O
,	O
instant	O
messaging	O
,	O
and	O
social	O
networking	O
.	O

Unsupervised	O
Segmentation	O
We	O
compare	O
the	O
phonetic	O
boundaries	O
proposed	O
by	O
our	O
model	O
to	O
the	O
manual	O
labels	O
provided	O
in	O
the	O
TIMIT	B-DATASET
dataset	I-DATASET
.	O

Then	O
,	O
we	O
test	O
our	O
RE	O
system	O
on	O
the	O
ACE	B-DATASET
2005	I-DATASET
data	I-DATASET
,	O
which	O
exploits	O
kernels	O
,	O
structures	O
and	O
similarities	O
for	O
domain	O
adaptation	O
.	O

The	O
word	B-TASK
segmentation	I-TASK
was	O
done	O
by	O
BaseSeg	O
(	O
)	O
for	O
Chinese	O
and	O
Mecab	O
2	O
for	O
Japanese	O
.	O

Table	O
5	O
:	O
Translation	B-TASK
performance	O
on	O
Arabic	B-TASK
to	I-TASK
English	I-TASK
translation	I-TASK
,	O
showing	O
BLEU	B-METRIC
%	O
.	O

We	O
propose	O
an	O
approach	O
to	O
cross	B-TASK
-	I-TASK
lingual	I-TASK
named	I-TASK
entity	I-TASK
recognition	I-TASK
model	I-TASK
transfer	I-TASK
without	O
the	O
use	O
of	O
parallel	O
corpora	O
.	O

In	O
this	O
paper	O
we	O
present	O
an	O
analysis	O
of	O
interruption	O
and	O
resumption	O
behaviour	O
in	O
human	O
-	O
human	O
in	O
-	O
vehicle	O
dialogues	O
and	O
also	O
propose	O
some	O
implications	O
for	O
resumption	O
strategies	O
in	O
an	O
in	O
-	O
vehicle	O
dialogue	O
system	O
.	O
.	O

All	O
experiments	O
were	O
done	O
on	O
UrduEnglish	O
and	O
we	O
evaluate	O
reordering	O
in	O
two	O
ways	O
:	O
Firstly	O
,	O
we	O
evaluate	O
reordering	O
performance	O
directly	O
by	O
comparing	O
the	O
reordered	O
source	O
sentence	O
in	O
Urdu	O
with	O
a	O
reference	O
reordering	O
obtained	O
from	O
the	O
manual	O
word	O
alignments	O
using	O
BLEU	B-METRIC
)	O
(	O
we	O
call	O
this	O
measure	O
monolingual	O
BLEU	O
or	O
mBLEU	O
)	O
.	O

Both	O
Spanish	O
/	O
English	O
sides	O
of	O
TRAIN	O
are	O
used	O
for	O
parallel	O
MT	B-TASK
training	O
,	O
whereas	O
decipherment	O
uses	O
only	O
monolingual	O
English	O
data	O
for	O
training	O
LMs	O
.	O

The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
summarized	O
as	O
follows	O
:	O
โข	O
We	O
propose	O
a	O
novel	O
framework	O
for	O
new	O
word	B-TASK
detection	I-TASK
from	O
large	O
-	O
scale	O
user	O
-	O
generated	O
data	O
.	O

Our	O
first	O
group	O
of	O
experiments	O
is	O
to	O
investigate	O
whether	O
our	O
proposed	O
label	B-TASK
propagation	I-TASK
model	O
with	O
both	O
bilingual	O
and	O
sentimental	O
information	O
can	O
improve	O
emotion	B-TASK
detection	I-TASK
in	I-TASK
code	I-TASK
-	I-TASK
switching	I-TASK
texts	I-TASK
.	O

Discovery	O
of	O
Topically	O
Coherent	O
Sentences	O
for	O
Extractive	B-TASK
Summarization	I-TASK

In	O
statistical	B-TASK
machine	I-TASK
translation	I-TASK
(	I-TASK
SMT	I-TASK
)	I-TASK
,	O
it	O
is	O
known	O
that	O
translation	O
with	O
models	O
trained	O
on	O
larger	O
parallel	O
corpora	O
can	O
achieve	O
greater	O
accuracy	B-METRIC
.	O

We	O
will	O
focus	O
first	O
on	O
producing	O
CCG	O
labeled	O
predicate	O
-	O
argument	O
dependencies	O
for	O
English	O
and	O
Chinese	O
and	O
will	O
then	O
apply	O
our	O
best	O
settings	O
to	O
produce	O
a	O
comparison	O
with	O
the	O
tree	O
structures	O
of	O
the	O
languages	O
of	O
the	O
PASCAL	O
Shared	O
Task	O
.	O

This	O
paper	O
describes	O
a	O
method	O
for	O
automatically	O
extracting	O
information	O
about	O
typical	O
durations	O
for	O
events	O
from	O
tweets	O
posted	O
to	O
the	O
Twitter	O
microblogging	O
site	O
.	O

This	O
is	O
the	O
problem	O
we	O
are	O
facing	O
when	O
we	O
perform	O
word	B-TASK
segmentation	I-TASK
on	O
Chinese	O
patent	O
data	O
.	O

It	O
is	O
well	O
known	O
that	O
parsing	B-TASK
accuracy	B-METRIC
suffers	O
when	O
a	O
model	O
is	O
applied	O
to	O
out	O
-	O
of	O
-	O
domain	O
data	O
.	O

We	O
describe	O
the	O
rules	O
specific	O
for	O
Spanish	O
language	O
constructions	O
and	O
their	O
implementation	O
in	O
EXTRHECH	O
,	O
an	O
Open	O
IE	O
system	O
for	O
Spanish	O
.	O

Open	O
-	O
Source	O
Tools	O
for	O
Morphology	O
,	O
Lemmatization	O
,	O
POS	B-TASK
Tagging	I-TASK
and	O
Named	B-TASK
Entity	I-TASK
Recognition	I-TASK

The	O
Excitement	O
Open	O
Platform	O
for	O
Textual	B-TASK
Inferences	I-TASK

WoSIT	B-DATASET
:	O
A	O
Word	O
Sense	O
Induction	O
Toolkit	O
for	O
Search	B-TASK
Result	I-TASK
Clustering	I-TASK
and	I-TASK
Diversification	I-TASK

A	O
Rule	O
-	O
Augmented	O
Statistical	B-TASK
Phrase	I-TASK
-	I-TASK
based	I-TASK
Translation	I-TASK
System	O

FAdR	B-DATASET
:	O
A	O
System	O
for	O
Recognizing	B-TASK
False	I-TASK
Online	I-TASK
Advertisements	I-TASK

Simplified	O
Dependency	O
Annotations	O
with	O
GFL	O
-	O
Web	O
Cross	O
-	O
Lingual	O
Information	O
to	O
the	O
Rescue	O
in	O
Keyword	O
Extraction	O

Experiments	O
confirmed	O
the	O
effectiveness	O
of	O
our	O
method	O
for	O
Japanese	O
-	O
English	O
and	O
Chinese	B-TASK
-	I-TASK
English	I-TASK
translation	I-TASK
,	O
using	O
NTCIR	B-DATASET
-	I-DATASET
9	I-DATASET
Patent	I-DATASET
Machine	I-DATASET
Translation	I-DATASET
Task	I-DATASET
data	I-DATASET
sets	I-DATASET
)	O
.	O

To	O
obtain	O
manually	O
corrected	O
sentences	O
for	O
evaluation	O
,	O
the	O
test	O
and	O
evaluation	O
set	O
sentences	O
and	O
were	O
put	O
on	O
Amazon	B-DATASET
Mechanical	I-DATASET
Turk	I-DATASET
as	O
a	O
correction	O
task	O
.	O

We	O
compare	O
this	O
approach	O
to	O
self	O
-	O
training	O
on	O
a	O
normal	O
newswire	O
corpus	O
and	O
show	O
that	O
IR	O
can	O
provide	O
a	O
better	O
corpus	O
for	O
bootstrapping	O
and	O
that	O
global	O
inference	O
can	O
further	O
improve	O
instance	O
selection	O
.	O

MODEST	O
will	O
provide	O
enterprises	O
with	O
the	O
services	O
of	O
retrieving	O
news	O
from	O
websites	O
,	O
extracting	O
commercial	O
information	O
,	O
exploring	O
customers	O
'	O
opinions	O
,	O
and	O
analyzing	O
collaborative	O
/	O
competitive	O
social	O
networks	O
.	O

Table	O
3	O
:	O
Minutes	O
used	O
for	O
alignment	B-TASK
and	O
phase	B-TASK
pair	I-TASK
extraction	I-TASK
in	O
the	O
FBIS	B-DATASET
data	I-DATASET
set	I-DATASET
.	O

These	O
drafts	O
include	O
lab	O
reports	O
,	O
data	O
analysis	O
,	O
argumentative	O
essays	O
,	O
and	O
article	O
summaries	O
.	O

compares	O
our	O
accuracies	B-METRIC
with	O
those	O
reported	O
in	O
(	O
)	O
for	O
Bulgarian	O
and	O
Spanish	O
.	O

Abstract	B-TASK
Meaning	I-TASK
Representation	I-TASK
(	I-TASK
AMR	I-TASK
)	I-TASK
(	O
)	O
is	O
a	O
semantic	O
formalism	O
that	O
expresses	O
the	O
logical	O
meanings	O
of	O
English	O
sentences	O
in	O
the	O
form	O
of	O
a	O
directed	O
,	O
acyclic	O
graph	O
.	O

Existing	O
studies	O
have	O
utilized	O
Wikipedia	O
for	O
various	O
knowledge	B-TASK
acquisition	I-TASK
tasks	O
.	O

We	O
tackle	O
the	O
previously	O
unaddressed	O
problem	O
of	O
unsupervised	O
determination	O
of	O
the	O
optimal	O
morphological	O
segmentation	O
for	O
statistical	B-TASK
machine	I-TASK
translation	I-TASK
(	I-TASK
SMT	I-TASK
)	I-TASK
and	O
propose	O
a	O
segmentation	O
metric	O
that	O
takes	O
into	O
account	O
both	O
sides	O
of	O
the	O
SMT	B-TASK
training	O
corpus	O
.	O

The	O
NIST	B-DATASET
"	I-DATASET
03	I-DATASET
test	I-DATASET
set	I-DATASET
is	O
used	O
as	O
our	O
development	O
corpus	O
and	O
the	O
NIST	B-DATASET
"	I-DATASET
05	I-DATASET
and	O
NIST	B-DATASET
"	I-DATASET
08	I-DATASET
test	I-DATASET
sets	I-DATASET
are	O
our	O
test	O
sets	O
.	O

Finally	O
,	O
we	O
report	O
accuracy	B-METRIC
and	O
F1	B-METRIC
for	O
temporal	O
types	O
,	O
as	O
defined	O
in	O
Section	O
2	O
,	O
for	O
the	O
TempEval	B-DATASET
dataset	I-DATASET
(	O
WikiWars	O
does	O
not	O
include	O
type	O
labels	O
)	O
.	O

Moreover	O
,	O
the	O
tree	O
/	O
forest	O
-	O
string	O
structure	O
is	O
more	O
widely	O
used	O
than	O
the	O
tree	O
-	O
tree	O
structure	O
,	O
presumably	O
because	O
using	O
two	O
parsers	O
on	O
the	O
source	O
and	O
target	O
languages	O
is	O
subject	O
to	O
more	O
problems	O
than	O
making	O
use	O
of	O
a	O
parser	O
on	O
one	O
language	O
,	O
such	O
as	O
the	O
shortage	O
of	O
high	O
precision	O
/	O
recall	O
parsers	O
for	O
languages	O
other	O
than	O
English	O
,	O
compound	O
parse	O
error	O
rates	O
,	O
and	O
inconsistency	O
of	O
errors	O
.	O

Large	O
-	O
scale	O
knowledge	O
bases	O
are	O
an	O
essential	O
component	O
of	O
many	O
approaches	O
in	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
.	O

Developing	O
a	O
supervised	O
or	O
semi	O
-	O
supervised	O
model	O
of	O
discourse	B-TASK
segmentation	I-TASK
would	O
require	O
ground	O
truth	O
annotated	O
based	O
on	O
a	O
well	O
-	O
established	O
representation	O
scheme	O
,	O
but	O
as	O
of	O
right	O
now	O
no	O
such	O
annotation	O
exists	O
for	O
Chinese	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
.	O

In	O
order	O
to	O
overcome	O
this	O
acquisition	O
bottleneck	O
(	O
sense	O
-	O
tagged	O
corpora	O
are	O
scarce	O
for	O
languages	O
other	O
than	O
English	O
)	O
,	O
we	O
decided	O
to	O
take	O
a	O
multilingual	O
approach	O
to	O
WSD	B-TASK
,	O
that	O
builds	O
up	O
the	O
sense	O
inventory	O
on	O
the	O
basis	O
of	O
the	O
Europarl	B-DATASET
parallel	I-DATASET
corpus	I-DATASET
(	O
.	O

We	O
report	O
the	O
results	O
that	O
the	O
SSWE	O
feature	O
performs	O
comparably	O
with	O
hand	O
-	O
crafted	O
features	O
in	O
the	O
top	O
-	O
performed	O
system	O
in	O
SemEval	O
2013	O
;	O
โข	O
We	O
release	O
the	O
sentiment	O
-	O
specific	O
word	O
embedding	O
learned	O
from	O
10	O
million	O
tweets	O
,	O
which	O
can	O
be	O
adopted	O
off	O
-	O
the	O
-	O
shell	O
in	O
other	O
sentiment	B-TASK
analysis	I-TASK
tasks	O
.	O

and	O
Rapp	O
(	O
1999	O
)	O
adopted	O
VSM	O
for	O
the	O
application	O
of	O
extracting	O
translation	O
pairs	O
from	O
comparable	O
or	O
even	O
unrelated	O
corpora	O
.	O

The	O
reported	O
measures	O
are	O
Adjusted	B-METRIC
Rand	I-METRIC
Index	I-METRIC
(	I-METRIC
ARI	I-METRIC
)	I-METRIC
,	O
Jaccard	B-METRIC
Index	I-METRIC
(	I-METRIC
JI	I-METRIC
)	I-METRIC
and	O
F1	B-METRIC
.	O

We	O
present	O
Code	O
-	O
Switched	O
LDA	O
(	O
csLDA	O
)	O
,	O
which	O
infers	O
language	O
specific	O
topic	O
distributions	O
based	O
on	O
code	O
-	O
switched	O
documents	O
to	O
facilitate	O
multilingual	B-TASK
corpus	I-TASK
analysis	I-TASK
.	O

Evaluated	O
in	O
French	O
by	O
10	O
-	O
fold	O
-	O
cross	O
validation	O
,	O
the	O
system	O
achieves	O
a	O
9	O
.	O
3	O
%	O
Word	B-METRIC
Error	I-METRIC
Rate	I-METRIC
and	O
a	O
0	O
.	O
83	O
BLEU	B-METRIC
score	O
.	O
.	O

We	O
selected	O
to	O
build	O
our	O
dataset	O
in	O
the	O
Consumer	O
Health	O
domain	O
,	O
a	O
popular	O
domain	O
in	O
the	O
web	O
providing	O
medical	O
information	O
at	O
various	O
levels	O
of	O
complexity	O
,	O
ranging	O
from	O
layman	O
and	O
up	O
to	O
expert	O
information	O
,	O
because	O
consumer	O
health	O
illustrates	O
the	O
need	O
for	O
exploratory	O
search	O
.	O

In	O
the	O
past	O
decades	O
,	O
significant	O
efforts	O
have	O
been	O
put	O
on	O
constructing	O
biomedical	O
knowledge	O
bases	O
)	O
and	O
developing	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
tools	O
,	O
such	O
as	O
MetaMap	O
,	O
to	O
utilize	O
the	O
information	O
from	O
the	O
knowledge	O
bases	O
)	O
.	O

Table	O
1	O
:	O
Results	O
of	O
SP	B-TASK
2	I-TASK
estimation	I-TASK
on	O
the	O
Samala	B-DATASET
corpus	I-DATASET
.	O

We	O
use	O
Dirichlet	O
multinomial	O
regression	O
(	O
Mimno	O
and	O
McCallum	O
,	O
2012	O
)	O
to	O
learn	O
a	O
mapping	O
between	O
cipher	O
text	O
and	O
plaintext	O
word	O
embeddings	O
from	O
non	O
-	O
parallel	O
data	O
.	O

Table	O
4	O
:	O
Multi	O
-	O
Span	O
-	O
HMM	O
has	O
a	O
much	O
smaller	O
drop	O
-	O
off	O
in	O
F1	B-METRIC
than	O
comparable	O
systems	O
on	O
out	O
-	O
of	O
-	O
domain	O
test	O
data	O
vs	O
in	O
-	O
domain	O
test	O
data	O
.	O

Our	O
experiments	O
in	O
English	O
-	O
Chinese	O
and	O
English	B-TASK
-	I-TASK
Japanese	I-TASK
translations	I-TASK
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
approach	O
:	O
we	O
observe	O
consistent	O
and	O
significant	O
improvement	O
in	O
translation	O
quality	O
across	O
multiple	O
test	O
sets	O
in	O
both	O
language	O
pairs	O
judged	O
by	O
both	O
humans	O
and	O
automatic	O
metric	O
.	O
.	O

Translation	O
quality	O
is	O
measured	O
with	O
the	O
BLEU	B-METRIC
metric	I-METRIC
(	O
)	O
on	O
the	O
news	B-DATASET
test2014	I-DATASET
test	I-DATASET
set	I-DATASET
(	O
which	O
has	O
3003	O
sentences	O
)	O
.	O

We	O
modified	O
Joshua	O
to	O
optionally	O
use	O
our	O
LM	O
implementations	O
during	O
decoding	O
,	O
and	O
measured	O
the	O
time	O
required	O
to	O
decode	O
all	O
2051	B-DATASET
sentences	I-DATASET
of	I-DATASET
the	I-DATASET
2008	I-DATASET
News	I-DATASET
test	I-DATASET
set	I-DATASET
.	O

There	O
has	O
been	O
considerable	O
work	O
on	O
coreference	B-TASK
resolution	I-TASK
in	O
written	O
text	O
,	O
but	O
comparatively	O
little	O
work	O
on	O
spoken	O
text	O
,	O
with	O
a	O
few	O
exceptions	O
of	O
systems	O
for	O
pronoun	B-TASK
resolution	I-TASK
in	O
transcripts	O
of	O
spoken	O
text	O
e	O
.	O
g	O
.	O
,	O
.	O

Take	O
reachability	B-TASK
indexing	I-TASK
for	O
example	O
,	O
hop	O
-	O
based	O
papers	O
try	O
to	O
get	O
the	O
"	O
optimum	O
labeling	O
"	O
by	O
finding	O
the	O
"	O
densest	O
intermediate	O
hops	O
"	O
to	O
encode	O
reachability	O
information	O
captured	O
by	O
an	O
intermediate	O
data	O
structure	O
called	O
"	O
transitive	O
closure	O
contour	O
"	O
.	O

In	O
English	B-DATASET
Penn	I-DATASET
Treebank	I-DATASET
experiments	O
,	O
our	O
parser	O
achieves	O
an	O
F1	B-METRIC
score	I-METRIC
of	O
91	O
.	O
1	O
on	O
test	O
set	O
at	O
a	O
speed	O
of	O
13	O
.	O
6	O
sentences	O
per	O
second	O
.	O

Table	O
2	O
:	O
Summarization	B-TASK
results	O
on	O
TAC	B-DATASET
'	I-DATASET
09	I-DATASET
data	I-DATASET
(	O
initial	O
summaries	O
)	O
.	O

Table	O
2	O
:	O
Mean	B-METRIC
system	I-METRIC
level	I-METRIC
correlations	I-METRIC
over	O
all	O
translation	B-TASK
tasks	I-TASK
into	O
English	O
for	O
variants	O
of	O
mNCD	B-DATASET
and	O
NCD	O
.	O

Furthermore	O
we	O
use	O
our	O
algorithm	O
to	O
solve	O
large	O
vocabulary	O
substitution	O
ciphers	O
and	O
improve	O
the	O
best	O
published	O
decipherment	O
error	O
rate	O
based	O
on	O
the	O
Gigaword	B-DATASET
corpus	I-DATASET
of	O
7	O
.	O
8	O
%	O
to	O
6	O
.	O
0	O
%	O
error	O
rate	O
.	O
